<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mysql关闭update safe mode]]></title>
    <url>%2F2019%2F03%2F11%2Fmysql%E5%85%B3%E9%97%ADupdate-safe-mode%2F</url>
    <content type="text"><![CDATA[SET SQL_SAFE_UPDATES = 0;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-保持fork的项目与上游同步]]></title>
    <url>%2F2019%2F02%2F26%2Fgit-%E4%BF%9D%E6%8C%81fork%E7%9A%84%E9%A1%B9%E7%9B%AE%E4%B8%8E%E4%B8%8A%E6%B8%B8%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[添加上游仓库： git remote add upstream [upstream_url] fetch 之： git fetch upstream 切换到本地master分支： git checkout master 将upstream/master merge到 本地master分支： git merge upstream/master //可能会报错，如果报错就执行：git pull 同时push到自己的github仓库： git push origin master]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解Go regexp包中 ReplaceAllString 的用法]]></title>
    <url>%2F2019%2F02%2F01%2F%E8%AF%A6%E8%A7%A3Go-regexp%E5%8C%85%E4%B8%AD-ReplaceAllString-%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[昨天有同事在看k8s源码，突然问了一个看似很简单的问题，https://golang.org/pkg/regexp/#Regexp.ReplaceAllString 官方文档中ReplaceAllString的解释，到底是什么意思？到底怎么用？ 官方英文原文： func (re *Regexp) ReplaceAllString(src, repl string) string 12ReplaceAllString returns a copy of src, replacing matches of the Regexp with the replacement string repl. Inside repl, $ signs are interpreted as in Expand, so for instance $1 represents the text of the first submatch. 中文文档： 1ReplaceAllLiteral返回src的一个拷贝，将src中所有re的匹配结果都替换为repl。在替换时，repl中的&apos;$&apos;符号会按照Expand方法的规则进行解释和替换，例如$1会被替换为第一个分组匹配结果。 看上去一脸懵逼，还是不理解这个函数到底怎么用。 又去看官方的示例： 12345678910111213Example：re := regexp.MustCompile("a(x*)b")fmt.Println(re.ReplaceAllString("-ab-axxb-", "T"))fmt.Println(re.ReplaceAllString("-ab-axxb-", "$1"))fmt.Println(re.ReplaceAllString("-ab-axxb-", "$1W"))fmt.Println(re.ReplaceAllString("-ab-axxb-", "$&#123;1&#125;W"))Output:-T-T---xx-----W-xxW- 第一个替换勉强能看明白，是用T去替换-ab-axxb-中符合正则表达式匹配的部分；第二个中的$是什么意思？$1看起来像是匹配正则表达式分组中第一部分，那$1W呢？${1}W呢？带着这些问题，开始深入研究这个函数到底怎么用。 首先，$符号在Expand函数中有解释过： 123456789func (re *Regexp) Expand(dst []byte, template []byte, src []byte, match []int) []byteExpand返回新生成的将template添加到dst后面的切片。在添加时，Expand会将template中的变量替换为从src匹配的结果。match应该是被FindSubmatchIndex返回的匹配结果起止位置索引。（通常就是匹配src，除非你要将匹配得到的位置用于另一个[]byte）在template参数里，一个变量表示为格式如：$name或$&#123;name&#125;的字符串，其中name是长度&gt;0的字母、数字和下划线的序列。一个单纯的数字字符名如$1会作为捕获分组的数字索引；其他的名字对应(?P&lt;name&gt;...)语法产生的命名捕获分组的名字。超出范围的数字索引、索引对应的分组未匹配到文本、正则表达式中未出现的分组名，都会被替换为空切片。$name格式的变量名，name会尽可能取最长序列：$1x等价于$&#123;1x&#125;而非$&#123;1&#125;x，$10等价于$&#123;10&#125;而非$&#123;1&#125;0。因此$name适用在后跟空格/换行等字符的情况，$&#123;name&#125;适用所有情况。如果要在输出中插入一个字面值&apos;$&apos;，在template里可以使用$$。 说了这么多，其实最终要的部分可以概括为三点： $后面只有数字，则代表正则表达式的分组索引，关于正则表达式的分组解释： 捕获组可以通过从左到右计算其开括号来编号 。例如，在表达式 (A)(B(C)) 中，存在四个这样的组： 0 (A)(B(C)) 1 (A) 2 (B(C)) 3 (C) 组零始终代表整个表达式 之所以这样命名捕获组是因为在匹配中，保存了与这些组匹配的输入序列的每个子序列。捕获的子序列稍后可以通过 Back 引用（反向引用） 在表达式中使用，也可以在匹配操作完成后从匹配器检索。 匹配正则表达式的$1部分，保留该部分，去掉其余部分； $后面是字符串，即$name,代表匹配对应(?P…)语法产生的命名捕获分组的名字 ${数字}字符串,即${1}xxx，意思是匹配正则表达式的分组1，src中匹配分组1的保留，并删除src剩余部分，追加xxx，后面会有代码示例解释这部分，也是最难理解的部分 最简单的情况，参数repl是字符串，将src中所有re的匹配结果都替换为repl 下面用代码来解释以上几种情况： 1234567891011121314151617181920212223242526272829303132333435package mainimport ("fmt""regexp")func main() &#123; s := "Hello World, 123 Go!" //定义一个正则表达式reg，匹配Hello或者Go reg := regexp.MustCompile(`(Hell|G)o`) s2 := "2019-12-01,test" //定义一个正则表达式reg2,匹配 YYYY-MM-DD 的日期格式 reg2 := regexp.MustCompile(`(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)`) //最简单的情况，用“T替换”"-ab-axxb-"中符合正则"a(x*)b"的部分 reg3 := regexp.MustCompile("a(x*)b") fmt.Println(re.ReplaceAllString("-ab-axxb-", "T")) //$&#123;1&#125;匹配"Hello World, 123 Go!"中符合正则`(Hell|G)`的部分并保留，去掉"Hello"与"Go"中的'o'并用"ddd"追加 rep1 := "$&#123;1&#125;ddd" fmt.Printf("%q\n", reg.ReplaceAllString(s, rep1)) //首先，"2019-12-01,test"中符合正则表达式`(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)`的部分是"2019-12-01",将该部分匹配'(\d&#123;4&#125;)'的'2019'保留，去掉剩余部分 rep2 := "$&#123;1&#125;" fmt.Printf("%q\n", reg2.ReplaceAllString(s2,rep2)) //首先，"2019-12-01,test"中符合正则表达式`(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)`的部分是"2019-12-01",将该部分匹配'(\d&#123;2&#125;)'的'12'保留，去掉剩余部分 rep3 := "$&#123;2&#125;" fmt.Printf("%q\n", reg2.ReplaceAllString(s2,rep3)) //首先，"2019-12-01,test"中符合正则表达式`(\d&#123;4&#125;)-(\d&#123;2&#125;)-(\d&#123;2&#125;)`的部分是"2019-12-01",将该部分匹配'(\d&#123;2&#125;)'的'01'保留，去掉剩余部分,并追加"13:30:12" rep4 := "$&#123;3&#125;:13:30:12" fmt.Printf("%q\n", reg2.ReplaceAllString(s2,rep4)) &#125; 上面代码输出依次是： 123456$ go run main.go-T-T-"Hellddd World, 123 Gddd!""2019,test""12,test""01:13:30:12,test" 总结Goregexp包中的ReplaceAllString设计有些许反人类，理解和使用上感觉不方便，如果你有更好的理解或者示例代码，Call me!]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言坑之for range]]></title>
    <url>%2F2019%2F01%2F31%2Fgo%E8%AF%AD%E8%A8%80%E5%9D%91%E4%B9%8Bfor-range%2F</url>
    <content type="text"><![CDATA[go语言坑之for range 这篇文章简单清晰地解释了之前遍历struct切片时遇到的一些怪异现象，这个问题当时也写了一篇文章来讨论，文章地址，但是没有切中要点。昨天无意中看到这篇博客，豁然开朗。 go只提供了一种循环方式，即for循环，在使用时可以像c那样使用，也可以通过for range方式遍历容器类型如数组、切片和映射。但是在使用for range时，如果使用不当，就会出现一些问题，导致程序运行行为不如预期。比如，下面的示例程序将遍历一个切片，并将切片的值当成映射的键和值存入，切片类型是一个int型，映射的类型是键为int型，值为*int，即值是一个地址。 1234567891011121314151617181920package mainimport &quot;fmt&quot;func main() &#123; slice := []int&#123;0, 1, 2, 3&#125; myMap := make(map[int]*int) for index, value := range slice &#123; myMap[index] = &amp;value &#125; fmt.Println(&quot;=====new map=====&quot;) prtMap(myMap)&#125;func prtMap(myMap map[int]*int) &#123; for key, value := range myMap &#123; fmt.Printf(&quot;map[%v]=%v\n&quot;, key, *value) &#125;&#125; 运行程序输出如下： 12345=====new map=====map[3]=3map[0]=3map[1]=3map[2]=3 由输出可以知道，不是我们预期的输出，正确输出应该如下： 123456=====new map=====map[0]=0map[1]=1map[2]=2map[3]=3（无序输出，但是值是0,1,2,3） 但是由输出可以知道，映射的值都相同且都是3。其实可以猜测映射的值都是同一个地址，遍历到切片的最后一个元素3时，将3写入了该地址，所以导致映射所有值都相同。其实真实原因也是如此，因为for range创建了每个元素的副本，而不是直接返回每个元素的引用，如果使用该值变量的地址作为指向每个元素的指针，就会导致错误，在迭代时，返回的变量是一个迭代过程中根据切片依次赋值的新变量，所以值的地址总是相同的，导致结果不如预期。 修正后程序如下： 123456789101112131415161718192021package mainimport &quot;fmt&quot;func main() &#123; slice := []int&#123;0, 1, 2, 3&#125; myMap := make(map[int]*int) for index, value := range slice &#123; num := value myMap[index] = &amp;num &#125; fmt.Println(&quot;=====new map=====&quot;) prtMap(myMap)&#125;func prtMap(myMap map[int]*int) &#123; for key, value := range myMap &#123; fmt.Printf(&quot;map[%v]=%v\n&quot;, key, *value) &#125;&#125; 运行程序输出如下： 12345=====new map=====map[2]=2map[3]=3map[0]=0map[1]=1 引用声明：该博客来自于这里.]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记第一个Vue项目台前幕后的经历]]></title>
    <url>%2F2019%2F01%2F28%2F%E8%AE%B0%E7%AC%AC%E4%B8%80%E4%B8%AAVue%E9%A1%B9%E7%9B%AE%E5%8F%B0%E5%89%8D%E5%B9%95%E5%90%8E%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[0前端开发经验，初次接触Vue，从后端到前端，从开发、打包到部署，完整的历程。 首先粗略通读了一遍官方文档，动手用webpack搭建了一个简单的demo。 看了Echarts的官方demo，了解了几种数据图表的数据结构。因为我要做的项目就是要将后端接口的数据拿到，然后图形化的形式展示出来。 对接后端，进行axios二次开发在构建应用时需要访问一个 API 并展示其数据，调研Vue的多种方式后选择了官方推荐的axiox。 从ajax到fetch、axios前端是个发展迅速的领域，前端请求自然也发展迅速，从原生的XHR到jquery ajax，再到现在的axios和fetch。 jquery ajax123456789$.ajax(&#123; type: &apos;POST&apos;, url: url, data: data, dataType: dataType, success: function() &#123;&#125;, error: function() &#123;&#125;&#125;)复制代码 它是对原生XHR的封装，还支持JSONP，非常方便；真的是用过的都说好。但是随着react，vue等前端框架的兴起，jquery早已不复当年之勇。很多情况下我们只需要使用ajax，但是却需要引入整个jquery，这非常的不合理，于是便有了fetch的解决方案。 fetchfetch号称是ajax的替代品，它的API是基于Promise设计的，旧版本的浏览器不支持Promise，需要使用polyfill es6-promise 举个例子： 12345678910111213141516171819// 原生XHRvar xhr = new XMLHttpRequest();xhr.open(&apos;GET&apos;, url);xhr.onreadystatechange = function() &#123; if (xhr.readyState === 4 &amp;&amp; xhr.status === 200) &#123; console.log(xhr.responseText) // 从服务器获取数据 &#125;&#125;xhr.send()// fetchfetch(url) .then(response =&gt; &#123; if (response.ok) &#123; response.json() &#125; &#125;) .then(data =&gt; console.log(data)) .catch(err =&gt; console.log(err))复制代码 看起来好像是方便点，then链就像之前熟悉的callback。 在MDN上，讲到它跟jquery ajax的区别，这也是fetch很奇怪的地方： 当接收到一个代表错误的 HTTP 状态码时，从 fetch()返回的 Promise 不会被标记为 reject， 即使该 HTTP 响应的状态码是 404 或 500。相反，它会将 Promise 状态标记为 resolve （但是会将 resolve 的返回值的 ok 属性设置为 false ）， 仅当网络故障时或请求被阻止时，才会标记为 reject。 默认情况下, fetch 不会从服务端发送或接收任何 cookies, 如果站点依赖于用户 session，则会导致未经认证的请求（要发送 cookies，必须设置 credentials 选项）. 突然感觉这还不如jquery ajax好用呢？别急，再搭配上async/await将会让我们的异步代码更加优雅： 123456async function test() &#123; let response = await fetch(url); let data = await response.json(); console.log(data)&#125;复制代码 看起来是不是像同步代码一样？简直完美！好吧，其实并不完美，async/await是ES7的API，目前还在试验阶段，还需要我们使用babel进行转译成ES5代码。 还要提一下的是，fetch是比较底层的API，很多情况下都需要我们再次封装。 比如： 12345678910// jquery ajax$.post(url, &#123;name: &apos;test&apos;&#125;)// fetchfetch(url, &#123; method: &apos;POST&apos;, body: Object.keys(&#123;name: &apos;test&apos;&#125;).map((key) =&gt; &#123; return encodeURIComponent(key) + &apos;=&apos; + encodeURIComponent(params[key]); &#125;).join(&apos;&amp;&apos;)&#125;)复制代码 由于fetch是比较底层的API，所以需要我们手动将参数拼接成’name=test’的格式，而jquery ajax已经封装好了。所以fetch并不是开箱即用的。 另外，fetch还不支持超时控制。 哎呀，感觉fetch好垃圾啊，，还需要继续成长。。 axiosaxios是尤雨溪大神推荐使用的，它也是对原生XHR的封装。它有以下几大特性： 可以在node.js中使用 提供了并发请求的接口 支持Promise API 简单使用 123456axios(&#123; method: &apos;GET&apos;, url: url,&#125;).then(res =&gt; &#123;console.log(res)&#125;).catch(err =&gt; &#123;console.log(err)&#125;) 并发请求,官方的并发例子： 123456789101112function getUserAccount() &#123; return axios.get(&apos;/user/12345&apos;);&#125;function getUserPermissions() &#123; return axios.get(&apos;/user/12345/permissions&apos;);&#125;axios.all([getUserAccount(), getUserPermissions()]) .then(axios.spread(function (acct, perms) &#123; // Both requests are now complete &#125;)); axios体积比较小，也没有上面fetch的各种问题，我认为是当前最好的请求方式 详情参考官方文档 #二次封装axios 首先创建一个request.js,内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import axios from 'axios';import Qs from 'qs';function checkStatus(err) &#123; let msg = "", level = "error"; switch (err.response.status) &#123; case 401: msg = "您还没有登陆"; break; case 403: msg = "您没有该项权限"; break; case 404: msg = "资源不存在"; break; case 500: msg = "服务器发生了点意外"; break; &#125; try &#123; msg = res.data.msg; &#125; catch (err) &#123; &#125; finally &#123; if (msg !== "" &amp;&amp; msg !== undefined &amp;&amp; msg !== null) &#123; store.dispatch('showSnackBar', &#123;text: msg, level: level&#125;); &#125; &#125; return err.response; &#125; function checkCode(res) &#123; if ((res.status &gt;= 200 &amp;&amp; res.status &lt; 400) &amp;&amp; (res.data.status &gt;= 200 &amp;&amp; res.data.status &lt; 400)) &#123; let msg = "", level = "success"; switch (res.data.status) &#123; case 201: msg = "创建成功"; break; case 204: msg = "删除成功"; break; &#125; try &#123; msg = res.data.success; &#125; catch (err) &#123; &#125; finally &#123; &#125; return res; &#125; return res; &#125;//这里封装axios的get,post,put,delete等方法export default &#123; get(url, params) &#123; return axios.get( url, params, ).then(checkCode).catch((error)=&gt;&#123;console.log(error)&#125;); &#125;, post(url, data) &#123; return axios.post( url, Qs.stringify(data), ).then(checkCode).catch(checkStatus); &#125;, put(url, data) &#123; return axios.put( url, Qs.stringify(data), ).then(checkCode).catch(checkStatus); &#125;, delete(url, data) &#123; return axios.delete( url, &#123;data: Qs.stringify(data)&#125;, ).then(checkCode).catch(checkStatus); &#125;, patch(url, data) &#123; return axios.patch( url, data, ).then(checkCode).catch(checkStatus); &#125;, &#125;; 创建一个api.js,存放后端的接口： 12345678910//导入上面的request模块import request from './request';//声明后端接口export const urlUserPrefix = '/v1/users';export const urlProductPrefix = '/v1/products';//使用前面封装好的方法，调用后端接口export const getUserslInfoLast = data =&gt; request.get(`$&#123;urlUserPrefix&#125;`, data);export const getProductsInfo = data =&gt; request.get(`$&#123;urlProductPrefix&#125;`, data); 在.vue文件中使用定义的方法，获取后端接口的数据： 1234567891011121314151617181920212223242526272829303132333435363738394041424344export default &#123; components: &#123; chart: ECharts, &#125;, store, name: 'ResourceTypeLine', data: () =&gt;(&#123; seconds: -1, //define dataset apiResponse:&#123;&#125;, initOptions: &#123; renderer: options.renderer || 'canvas' &#125;, mounted:function() &#123; this.fTimeArray = this.getFormatTime()//调用method里面的方法this.getUserInfo() &#125;, methods: &#123;//异步方式调用后端接口 async getUserInfo() &#123; const resThis = await urlUserPrefix(&#123; params: &#123; //get的参数在这里添加 beginTime: this.fTimeArray[0], endTime: this.fTimeArray[1], &#125; &#125;); this.apiResponseThisMonth = resThis.data try &#123; &#125; catch (err) &#123; console.log(err); &#125; &#125;, 开发环境配置跨域为了更方便地与后台联调，需要在用vue脚手架创建地项目中，在config目录地index.js设置proxytable来实现跨域请求，具体代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647module.exports = &#123; build: &#123; env: require('./prod.env'), index: path.resolve(__dirname, '../dist/index.html'), assetsRoot: path.resolve(__dirname, '../dist'), assetsSubDirectory: 'static', assetsPublicPath: '.', productionSourceMap: false, // Gzip off by default as many popular static hosts such as // Surge or Netlify already gzip all static assets for you. // Before setting to `true`, make sure to: // npm install --save-dev compression-webpack-plugin productionGzip: false, productionGzipExtensions: ['js', 'css'], // Run the build command with an extra argument to // View the bundle analyzer report after build finishes: // `npm run build --report` // Set to `true` or `false` to always turn it on or off bundleAnalyzerReport: process.env.npm_config_report &#125;, dev: &#123; env: require('./dev.env'), port: 8080, // hosts:"0.0.0.0", autoOpenBrowser: true, assetsSubDirectory: 'static', assetsPublicPath: '/', //配置跨域请求,注意配置完之后需要重启编译该项目 proxyTable: &#123; //请求名字变量可以自己定义 '/api': &#123; target: 'http://test.com', // 请求的接口域名或IP地址，开头是http或https // secure: false, // 如果是https接口，需要配置这个参数 changeOrigin: true,// 是否跨域，如果接口跨域，需要进行这个参数配置 pathRewrite: &#123; '^/api':""//表示需要rewrite重写路径 &#125; &#125; &#125;, // CSS Sourcemaps off by default because relative paths are "buggy" // with this option, according to the CSS-Loader README // (https://github.com/webpack/css-loader#sourcemaps) // In our experience, they generally work as expected, // just be aware of this issue when enabling this option. cssSourceMap: false &#125;&#125; vue 项目打包部署，通过nginx 解决跨域问题​ 最近将公司vue 项目打包部署服务器时，产生了一点小插曲，开发环境中配置的跨域在将项目打包为静态文件时是没有用的 ，就想到了用 nginx 通过反向代理的方式解决这个问题，但是其中有一个巨大的坑，后面会讲到。 前提条件liunx 下 nginx 安装配置（将不做多的阐述，请自行百度） 配置nginx 通过 Xshell 连接 liunx 服务器 ，打开 nginx.conf 配置文件，或通过 WinSCP 直接打开并编辑nginx.conf文件 ，这里我选择后者 。（具体配置文件的路径根据你安装时决定） 在配置文件中新增一个server 123456789101112131415161718192021222324# 新增的服务 # 新增的服务 server &#123; listen 8086; # 监听的端口 location / &#123; root /var/www; # vue 打包后静态文件存放的地址 index index.html; # 默认主页地址 &#125; location /v1 &#123; proxy_pass http://47.106.184.89:9010/v1; # 代理接口地址 &#125; location /testApi &#123; proxy_pass http://40.106.197.89:9086/testApi; # 代理接口地址 &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;复制代码 解释说明 /var/www是我当前将vue 文件打包后存放在 liunx下的路径 ， 当我们启动 nginx 后 就可以通过http://ip地址:8086/访问到vue 打包的静态文件。 2.location /v1 指拦截以v1开头的请求，http请求格式为http://ip地址:8086/v1/***`,这里有一个坑！一定要按照上面的配置文件**：proxy_pass http://47.106.184.89:9010/v1; # 代理接口地址，如果你像我一开始写的proxy_pass http://47.106.184.89:9010/; # 代理接口地址**，你永远也匹配不到对应的接口！。 proxy_pass http://47.106.197.89:9093/v1;` 当拦截到需要处理的请求时，将拦截请求代理到的 接口地址。 webpack打包下面是config/index.js配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// see http://vuejs-templates.github.io/webpack for documentation.var path = require(&apos;path&apos;)module.exports = &#123; build: &#123; env: require(&apos;./prod.env&apos;), index: path.resolve(__dirname, &apos;../dist/index.html&apos;), assetsRoot: path.resolve(__dirname, &apos;../dist&apos;), assetsSubDirectory: &apos;static&apos;, assetsPublicPath: &apos;.&apos;, productionSourceMap: false, // Gzip off by default as many popular static hosts such as // Surge or Netlify already gzip all static assets for you. // Before setting to `true`, make sure to: // npm install --save-dev compression-webpack-plugin productionGzip: false, productionGzipExtensions: [&apos;js&apos;, &apos;css&apos;], // Run the build command with an extra argument to // View the bundle analyzer report after build finishes: // `npm run build --report` // Set to `true` or `false` to always turn it on or off bundleAnalyzerReport: process.env.npm_config_report &#125;, dev: &#123; env: require(&apos;./dev.env&apos;), port: 8080, // hosts:&quot;0.0.0.0&quot;, autoOpenBrowser: true, assetsSubDirectory: &apos;static&apos;, assetsPublicPath: &apos;/&apos;, //配置跨域请求,注意配置完之后需要重启编译该项目 proxyTable: &#123; //请求名字变量可以自己定义 &apos;/api&apos;: &#123; target: &apos;http://billing.hybrid.cloud.ctripcorp.com&apos;, // 请求的接口域名或IP地址，开头是http或https // secure: false, // 如果是https接口，需要配置这个参数 changeOrigin: true,// 是否跨域，如果接口跨域，需要进行这个参数配置 pathRewrite: &#123; &apos;^/api&apos;:&quot;&quot;//表示需要rewrite重写路径 &#125; &#125; &#125;, // CSS Sourcemaps off by default because relative paths are &quot;buggy&quot; // with this option, according to the CSS-Loader README // (https://github.com/webpack/css-loader#sourcemaps) // In our experience, they generally work as expected, // just be aware of this issue when enabling this option. cssSourceMap: false &#125;&#125; Dockerfile打包Docker镜像 123456789101112FROM Nginx:baseMAINTAINER author &lt;hantmac@outlook.com&gt;WORKDIR /opt/workDirRUN mkdir /var/log/workDirCOPY dist /var/wwwADD nginx/default.conf /etc/nginx/conf.d/default.confENTRYPOINT nginx -g "daemon off;" 后记这是首次接触前端的第一个项目，期间经历了从后端接口开发，前端框架选型（一度想要用react，后来还是放弃），熟悉Vue，到组件开发，webpack构建，Nginx部署，Docker发布的完整过程。虽然页面比较简单，但是期间的采坑无数，后面还要继续努力！]]></content>
      <categories>
        <category>Frontend</category>
      </categories>
      <tags>
        <tag>Vue</tag>
        <tag>Frontend</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20181202-Postmortem-debugging-Go-services-with-Delve[翻译]]]></title>
    <url>%2F2019%2F01%2F20%2F20181202-Postmortem-debugging-Go-services-with-Delve-%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[使用Delve 调试Go服务的一次经历 Vladimir Varankin 写于 2018/12/02 某天，我们生产服务上的几个实例突然不能处理外部进入的流量，HTTP请求成功通过负载均衡到达实例，但是之后却hang住了。接下来记录的是一次调试在线Go服务的惊心动魄的经历。 正是下面逐步演示的操作，帮助我们定位了问题的根本原因。 简单起见，我们将起一个Go写的HTTP服务作为调试使用，这个服务实现的细节暂时不做深究（之后我们将深入分析代码）。一个真实的生产应用可能包含很多组件，这些组件实现了业务罗和服务的基础架构。我们可以确信，这些应用已经在生产环境“身经百战” :)。 源代码以及配置细节可以查看GitHub仓库。为了完成接下来的工作，你需要一台Linux系统的虚机，这里我使用vagrant-hostmanager插件。Vagrantfile在GitHub仓库的根目录，可以查看更多细节。 让我们开启虚机，构建HTTP服务并且运行起来，可以看到下面的输出： 12345678910$ vagrant upBringing machine 'server-test-1' up with 'virtualbox' provider...$ vagrant ssh server-test-1Welcome to Ubuntu 18.04.1 LTS (GNU/Linux 4.15.0-33-generic x86_64)···vagrant@server-test-1:~$ cd /vagrant/example/servervagrant@server-test-1:/vagrant/example/server$ go buildvagrant@server-test-1:/vagrant/example/server$ ./server --addr=:10080server listening addr=:10080 通过curl发送请求到所起的HTTP服务，可以判断其是否处于工作状态，新开一个terminal并执行下面的命令： 12$ curl 'http://server-test-1:10080'OK 为了模拟失败的情况，我们需要发送大量请求到HTTP服务，这里我们使用HTTP benchmark测试工具wrk进行模拟。我的MacBook是4核的，所以使用4个线程运行wrk，能够产生1000个连接，基本能够满足需求。 1234$ wrk -d1m -t4 -c1000 'http://server-test-1:10080'Running 1m test @ http://server-test-1:10080 4 threads and 1000 connections ··· 一会的时间，服务器hang住了。甚至等wrk跑完之后，服务器已经不能处理任何请求： 12$ curl --max-time 5 'http://server-test-1:10080/'curl: (28) Operation timed out after 5001 milliseconds with 0 bytes received 我们遇到麻烦了！让我们分析一下。 在我们生产服务的真实场景中，服务器起来以后，goroutines的数量由于请求的增多而迅速增加，之后便失去响应。对pprof调试句柄的请求变得非常非常慢，看起来就像服务器“死掉了”。同样，我们也尝试使用SIGQUIT命令杀掉进程以释放所运行goroutines堆栈，但是收不到任何效果。 GDB和Coredump我们可以使用GDB（GNU Debugger）尝试进入正在运行的服务内部。 在生产环境运行调试器可能需要额外的权限，所以与你的团队提前沟通是很明智的。 在虚机上再开启一个SSH会话，找到服务器的进程id并使用调试器连接到该进程： 123456789$ vagrant ssh server-test-1Welcome to Ubuntu 18.04.1 LTS (GNU/Linux 4.15.0-33-generic x86_64)···vagrant@server-test-1:~$ pgrep server1628vagrant@server-test-1:~$ cd /vagrantvagrant@server-test-1:/vagrant$ sudo gdb --pid=1628 example/server/serverGNU gdb (Ubuntu 8.1-0ubuntu3) 8.1.0.20180409-git··· 调试器连接到服务器进程之后，我们可以运行GDB的bt命令（aka backtrace）来检查当前线程的堆栈信息： 12345678910(gdb) bt#0 runtime.futex () at /usr/local/go/src/runtime/sys_linux_amd64.s:532#1 0x000000000042b08b in runtime.futexsleep (addr=0xa9a160 &lt;runtime.m0+320&gt;, ns=-1, val=0) at /usr/local/go/src/runtime/os_linux.go:46#2 0x000000000040c382 in runtime.notesleep (n=0xa9a160 &lt;runtime.m0+320&gt;) at /usr/local/go/src/runtime/lock_futex.go:151#3 0x0000000000433b4a in runtime.stoplockedm () at /usr/local/go/src/runtime/proc.go:2165#4 0x0000000000435279 in runtime.schedule () at /usr/local/go/src/runtime/proc.go:2565#5 0x00000000004353fe in runtime.park_m (gp=0xc000066d80) at /usr/local/go/src/runtime/proc.go:2676#6 0x000000000045ae1b in runtime.mcall () at /usr/local/go/src/runtime/asm_amd64.s:299#7 0x000000000045ad39 in runtime.rt0_go () at /usr/local/go/src/runtime/asm_amd64.s:201#8 0x0000000000000000 in ?? () 说实话我并不是GDB的专家，但是显而易见Go运行时似乎使线程进入睡眠状态了，为什么呢？ 调试一个正在运行的进程是不明智的，不如将该线程的coredump保存下来，进行离线分析。我们可以使用GDB的gcore命令，该命令将core文件保存在当前工作目录并命名为core.&lt;process_id&gt;。 123456789(gdb) gcoreSaved corefile core.1628(gdb) quitA debugging session is active. Inferior 1 [process 1628] will be detached.Quit anyway? (y or n) yDetaching from program: /vagrant/example/server/server, process 1628 core文件保存后，服务器没必要继续运行，使用kill -9结束它。 我们能够注意到，即使是一个简单的服务器，core文件依然会很大（我这一份是1.2G）,对于生产的服务来说，可能会更加巨大。 如果需要了解更多使用GDB调试的技巧，可以继续阅读使用GDB调试Go代码。 使用Delve调试器Delve是一个针对Go程序的调试器。它类似于GDB，但是更关注Go的运行时、数据结构以及其他内部的机制。 如果你对Delve的内部实现机制很感兴趣，那么我十分推荐你阅读Alessandro Arzilli在GopherCon EU 2018所作的演讲，[Internal Architecture of Delve, a Debugger For Go]。 Delve是用Go写的，所以安装起来非常简单： 1$ go get -u github.com/derekparker/delve/cmd/dlv Delve安装以后，我们就可以通过运行dlv core &lt;path to service binary&gt; &lt;core file&gt;来分析core文件。我们先列出执行coredump时正在运行的所有goroutines。Delve的goroutines命令如下： 1234567$ dlv core example/server/server core.1628(dlv) goroutines ··· Goroutine 4611 - User: /vagrant/example/server/metrics.go:113 main.(*Metrics).CountS (0x703948) Goroutine 4612 - User: /vagrant/example/server/metrics.go:113 main.(*Metrics).CountS (0x703948) Goroutine 4613 - User: /vagrant/example/server/metrics.go:113 main.(*Metrics).CountS (0x703948) 不幸的是，在真实生产环境下，这个列表可能会很长，甚至会超出terminal的缓冲区。由于服务器为每一个请求都生成一个对应的goroutine，所以goroutines命令生成的列表可能会有百万条。我们假设现在已经遇到这个问题，并想一个方法来解决它。 Delve支持”headless”模式，并且能够通过JSON-RPC API与调试器交互。 运行dlv core命令，指定想要启动的Delve API server： 123$ dlv core example/server/server core.1628 --listen :44441 --headless --logAPI server listening at: [::]:44441INFO[0000] opening core file core.1628 (executable example/server/server) layer=debugger 调试服务器运行后，我们可以发送命令到其TCP端口并将返回结果以原生JSON的格式存储。我们以上面相同的方式得到正在运行的goroutines，不同的是我们将结果存储到文件中： 1$ echo -n '&#123;"method":"RPCServer.ListGoroutines","params":[],"id":2&#125;' | nc -w 1 localhost 44441 &gt; server-test-1_dlv-rpc-list_goroutines.json 现在我们拥有了一个（比较大的）JSON文件，里面存储大量原始信息。推荐使用jq命令进一步了解JSON数据的原貌，举例：这里我获取JSON数据的result字段的前三个对象： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657$ jq '.result[0:3]' server-test-1_dlv-rpc-list_goroutines.json[ &#123; "id": 1, "currentLoc": &#123; "pc": 4380603, "file": "/usr/local/go/src/runtime/proc.go", "line": 303, "function": &#123; "name": "runtime.gopark", "value": 4380368, "type": 0, "goType": 0, "optimized": true &#125; &#125;, "userCurrentLoc": &#123; "pc": 6438159, "file": "/vagrant/example/server/main.go", "line": 52, "function": &#123; "name": "main.run", "value": 6437408, "type": 0, "goType": 0, "optimized": true &#125; &#125;, "goStatementLoc": &#123; "pc": 4547433, "file": "/usr/local/go/src/runtime/asm_amd64.s", "line": 201, "function": &#123; "name": "runtime.rt0_go", "value": 4547136, "type": 0, "goType": 0, "optimized": true &#125; &#125;, "startLoc": &#123; "pc": 4379072, "file": "/usr/local/go/src/runtime/proc.go", "line": 110, "function": &#123; "name": "runtime.main", "value": 4379072, "type": 0, "goType": 0, "optimized": true &#125; &#125;, "threadID": 0, "unreadable": "" &#125;, ···] JSON数据中的每个对象都代表了一个goroutine。通过命令手册 可知，goroutines命令可以获得每一个goroutines的信息。通过手册我们能够分析出userCurrentLoc字段是服务器源码中goroutines最后出现的地方。 为了能够了解当core file创建的时候，goroutines正在做什么，我们需要收集JSON文件中包含userCurrentLoc字段的函数名字以及其行号： 123456789$ jq -c '.result[] | [.userCurrentLoc.function.name, .userCurrentLoc.line]' server-test-1_dlv-rpc-list_goroutines.json | sort | uniq -c 1 ["internal/poll.runtime_pollWait",173]1000 ["main.(*Metrics).CountS",95] 1 ["main.(*Metrics).SetM",105] 1 ["main.(*Metrics).startOutChannelConsumer",179] 1 ["main.run",52] 1 ["os/signal.signal_recv",139] 6 ["runtime.gopark",303] 大量的goroutines(上面是1000个)在函数main.(*Metrics).CoutS的95行被阻塞。现在我们回头看一下我们服务器的源码。 在main包中找到Metrics结构体并且找到它的CountS方法（example/server/metrics.go）。 1234// CountS increments counter per second.func (m *Metrics) CountS(key string) &#123; m.inChannel &lt;- NewCountMetric(key, 1, second)&#125; 我们的服务器在往inChannel通道发送的时候阻塞住了。让我们找出谁负责从这个通道读取数据，深入研究代码之后我们找到了下面的函数： 123456// starts a consumer for inChannelfunc (m *Metrics) startInChannelConsumer() &#123; for inMetrics := range m.inChannel &#123; // ··· &#125;&#125; 这个函数逐个地从通道中读取数据并加以处理，那么什么情况下发送到这个通道的任务会被阻塞呢？ 当处理通道的时候，根据Dave Cheney的通道准则，只有四种情况可能导致通道有问题： 向一个nil通道发送 从一个nil通道接收 向一个已关闭的通道发送 从一个已关闭的通道接收并立即返回零值 第一眼就看到了“向一个nil通道发送”，这看起来像是问题的原因。但是反复检查代码后，inChannel是由Metrics初始化的，不可能为nil。 n你可能会注意到，使用jq命令获取到的信息中，没有startInChannelConsumer方法。会不会是因为在main.(*Metrics).startInChannelConsumer的某个地方阻塞而导致这个（可缓冲）通道满了？ Delve能够提供从开始位置到userCurrentLoc字段之间的初始位置信息，这个信息存储到startLoc字段中。使用下面的jq命令可以查询出所有goroutines,其初始位置都在函数startInChannelConsumer中： 123456789101112131415161718192021222324252627282930313233343536373839404142$ jq '.result[] | select(.startLoc.function.name | test("startInChannelConsumer$"))' server-test-1_dlv-rpc-list_goroutines.json&#123; "id": 20, "currentLoc": &#123; "pc": 4380603, "file": "/usr/local/go/src/runtime/proc.go", "line": 303, "function": &#123; "name": "runtime.gopark", "value": 4380368, "type": 0, "goType": 0, "optimized": true &#125; &#125;, "userCurrentLoc": &#123; "pc": 6440847, "file": "/vagrant/example/server/metrics.go", "line": 105, "function": &#123; "name": "main.(*Metrics).SetM", "value": 6440672, "type": 0, "goType": 0, "optimized": true &#125; &#125;, "startLoc": &#123; "pc": 6440880, "file": "/vagrant/example/server/metrics.go", "line": 109, "function": &#123; "name": "main.(*Metrics).startInChannelConsumer", "value": 6440880, "type": 0, "goType": 0, "optimized": true &#125; &#125;, ···&#125; 结果中有一条信息非常振奋人心！ 在main.(*Metrics).startInChannelConsumer，109行（看结果中的startLoc字段），有一个id为20的goroutines阻塞住了！ 拿到goroutines的id能够大大降低我们搜索的范围（并且我们再也不用深入庞大的JSON文件了）。使用Delve的goroutines命令我们能够将当前goroutines切换到目标goroutines，然后可以使用stack命令打印该goroutines的堆栈信息： 123456789101112131415161718192021222324252627282930313233$ dlv core example/server/server core.1628(dlv) goroutine 20Switched from 0 to 20 (thread 1628)(dlv) stack -full0 0x000000000042d7bb in runtime.gopark at /usr/local/go/src/runtime/proc.go:303 lock = unsafe.Pointer(0xc000104058) reason = waitReasonChanSend···3 0x00000000004066a5 in runtime.chansend1 at /usr/local/go/src/runtime/chan.go:125 c = (unreadable empty OP stack) elem = (unreadable empty OP stack)4 0x000000000062478f in main.(*Metrics).SetM at /vagrant/example/server/metrics.go:105 key = (unreadable empty OP stack) m = (unreadable empty OP stack) value = (unreadable empty OP stack)5 0x0000000000624e64 in main.(*Metrics).sendMetricsToOutChannel at /vagrant/example/server/metrics.go:146 m = (*main.Metrics)(0xc000056040) scope = 0 updateInterval = (unreadable could not find loclist entry at 0x89f76 for address 0x624e63)6 0x0000000000624a2f in main.(*Metrics).startInChannelConsumer at /vagrant/example/server/metrics.go:127 m = (*main.Metrics)(0xc000056040) inMetrics = main.Metric &#123;Type: TypeCount, Scope: 0, Key: "server.req-incoming",...+2 more&#125; nextUpdate = (unreadable could not find loclist entry at 0x89e86 for address 0x624a2e) 从下往上分析： （6）一个来自通道的新inMetrics值在main.(*Metrics).startInChannelConsumer中被接收 （5）我们调用main.(*Metrics).sendMetricsToOutChannel并且在example/server/metrics.go的146行进行处理 （4）然后main.(*Metrics).SetM被调用 一直运行到runtime.gopark中的waitReasonChanSend阻塞！ 一切的一切都明朗了！ 单个goroutines中，一个从缓冲通道读取数据的函数，同时也在往通道中发送数据。当进入通道的值达到通道的容量时，消费函数继续往已满的通道中发送数据就会造成自身的死锁。由于单个通道的消费者死锁，那么每一个尝试往通道中发送数据的请求都会被阻塞。 这就是我们的故事，使用上述调试技术帮助我们发现了问题的根源。那些代码是很多年前写的，甚至从没有人看过这些代码，也万万没有想到会导致这么大的问题。 如你所见，并不是所有问题都能由工具解决，但是工具能够帮助你更好地工作。我希望，通过此文能够激励你多多尝试这些工具。我非常乐意倾听你们处理类似问题的其它解决方案。 Vladimir是一个后端开发工程师，目前就职于adjust.com. @tvii on Twitter, @narqo on Github via: https://blog.gopheracademy.com/advent-2018/postmortem-debugging-delve/ 作者：Vladimir Varankin译者：hantmac]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动化脚本实现go安装与升级]]></title>
    <url>%2F2019%2F01%2F12%2F%E8%87%AA%E5%8A%A8%E5%8C%96%E8%84%9A%E6%9C%AC%E5%AE%9E%E7%8E%B0go%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[源码安装： 下载对应的操作系统的最新的 Golang 版本：https://golang.org/dl/ 在 home 目录下建立 installGo目录，然后在该目录下新建升级与部署文件以及下载最新的 golang 源码包： 以下是 installOrUpdate.sh 具体内容： 1234567891011121314151617# !/bin/bashif [ -z "$1" ]; then​ echo "usage: ./install.sh go-package.tar.gz"​ exitfiif [ -d "/usr/local/go" ]; then​ echo "Uninstalling old go version..."​ sudo rm -rf /usr/local/gofiecho "Installing..."sudo tar -C /usr/local -xzf $1echo export GOPATH=/go" &gt;&gt; /etc/profileecho export GOROOT=/usr/local/go &gt;&gt; /etc/profileecho export PATH=$PATH:$GOROOT/bin:$GOPATH/bin1 &gt;&gt; /etc/profilesource /etc/profilerm -rf $1echo "Done" 然后运行： sudo sh install.sh go1.10.linux-amd64.tar.gz 或者手动设置好GOPATH，GOROOT 编辑 /etc/profile 在文件尾部加入： 12345export GOPATH=/goexport GOROOT=/usr/local/goexport PATH=$PATH:$GOROOT/bin:$GOPATH/bin1运行 source /etc/profile 让环境变量生效 至此，Go 已安装成功 升级 如果需要升级的话只需要将最新的源码包下载到第一步的 installGo 文件夹下，然后运行sudo sh install.sh go1.xx.linux-amd64.tar.gz 即可。 shell脚本更新地址github]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[beego注解路由中@Param的参数解释]]></title>
    <url>%2F2019%2F01%2F03%2Fbeego%E6%B3%A8%E8%A7%A3%E8%B7%AF%E7%94%B1%E4%B8%AD-Param%E7%9A%84%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A%2F</url>
    <content type="text"><![CDATA[beego注解路由的注释，我们可以把我们的注释分为以下类别： @Title 接口的标题，用来标示唯一性，唯一，可选 格式：之后跟一个描述字符串 @Description 接口的作用，用来描述接口的用途，唯一，可选 格式：之后跟一个描述字符串 @Param 请求的参数，用来描述接受的参数，多个，可选 格式：变量名 传输类型 类型 是否必须 描述 传输类型：paht or body 类型： 变量名和描述是一个字符串 是否必须：true 或者false string int int64 对象，这个地方大家写的时候需要注意，需要是相对于当前项目的路径.对象，例如models.Object表示models目录下的Object对象，这样bee在生成文档的时候会去扫描改对象并显示给用户改对象。 query 表示带在url串里面?aa=bb&amp;cc=dd form 表示使用表单递交数据 path 表示URL串中得字符，例如/user/{uid} 那么uid就是一个path类型的参数 body 表示使用raw body进行数据的传输 header 表示通过header进行数据的传输 @Success 成功返回的code和对象或者信息 格式：code 对象类型 信息或者对象路径 code：表示HTTP的标准status code，200 201等 对象类型：{object}表示对象，其他默认都认为是字符类型，会显示第三个参数给用户，如果是{object}类型，那么就会去扫描改对象，并显示给用户 对象路径和上面Param中得对象类型一样，使用路径.对象的方式来描述 @Failure 错误返回的信息， 格式： code 信息 code:同上Success 错误信息：字符串描述信息 @router 上面已经描述过支持两个参数，第一个是路由，第二个表示支持的HTTP方法]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>beego</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang use reflect to judge type of variable]]></title>
    <url>%2F2018%2F12%2F25%2Fgolang-use-reflect-to-judge-type-of-variable%2F</url>
    <content type="text"><![CDATA[众所周知，golang中可以使用空接口即interface{}代表任何类型的数据，那么在使用的时候，我们有时需要获取返回值的具体类型 场景：beego框架中的orm.Params类型，实际上是map[string]interface{},在使用values接口的时候，需要从返回Map中获取数据，需要这样获取：Id:m[&quot;Id&quot;].(string),这时m[“Id”]实际上是String类型，我们可以用reflect模块来获取实际的类型 12reflect.TypeOf(m["Id"])//返回为String 1234567891011package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func main() &#123; var x int32 = 20 fmt.Println(&quot;type:&quot;, reflect.TypeOf(x))&#125;]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql add primary key auto_increment]]></title>
    <url>%2F2018%2F12%2F25%2Fmysql-add-primary-key-auto-increment%2F</url>
    <content type="text"><![CDATA[添加字段id,并将其设置为主键自增 alter table TABLE_NAME add id int not null primary key Auto_increment 如果想添加已经有了一列为主键，可以用： alter table TABLE_NAME add primary key(COL_NAME); 如果想修改一列为主键，则需要先删除原来的主键： alter table TABLE_NAME drop primary key; 再重新添加主键： alter table TABLE_NAME add primary key(COL_NAME);]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go关于time包的解析与使用]]></title>
    <url>%2F2018%2F12%2F16%2FGo%E5%85%B3%E4%BA%8Etime%E5%8C%85%E7%9A%84%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Go关于时间与日期的处理关于time的数据类型 time包依赖的数据类型有：time.Time,time.Month,time.WeekDay,time.Duration,time.Location. 详细介绍以上几种数据类型 time.Time /usr/local/go/src/time/time.go 定义如下: 12345type Time struct &#123; sec int64 // 从1年1月1日 00:00:00 UTC 至今过去的秒数 nsec int32 // 最近一秒到下一秒过去的纳秒数 loc *Location // 时区&#125; time.Time会返回纳秒时间精度的时间 1234var ti time.Timeti = time.Now()fmt.Printf("时间: %v, 时区: %v, 时间类型: %T\n", t, t.Location(), t)//时间: 2018-12-15 09:06:05.816187261 +0800 CST, 时区: Local, 时间类型: time.Time time.Month, go中自己重新定义了month的类型，与time.year和time.day不同。 12345678910111213141516type Month intconst ( January Month = 1 + iota February March April May June July August September October November December) iota是golang语言的常量计数器,只能在常量的表达式中使用。 iota在const关键字出现时将被重置为0(const内部的第一行之前)，const中每新增一行常量声明将使iota计数一次(iota可理解为const语句块中的行索引)。 使用iota能简化定义，在定义枚举时很有用。 time.WeekDay,代表一周之中的星期几（当然是按照西方的规则，他们把周日当做是一周的开始） 1234567891011type WeekDay intconst ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday) time.Duration,代表两个时间点之间的纳秒差值。 12345678910type Duration int64const ( Nanosecond Duration = 1 Microsecond = 1000 * Nanosecond Millisecond = 1000 * Microsecond Second = 1000 * Millisecond Minute = 60 * Second Hour = 60 * Minute) time.Location,时区信息 123456789type Location struct &#123; name string zone []zone tx []zoneTrans cacheStart int64 cacheEnd int64 cacheZone *zone&#125;//北京时间：Asia/Shanghai 以上类型receiver的实现方法 time.Time相关方法 func Now() Time {} // 当前本地时间 func Unix(sec int64, nsec int64) Time {} // 根据时间戳返回本地时间 func Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time {} // 返回指定时间 1234567891011/ 当前本地时间t = time.Now()fmt.Println("'time.Now': ", t)// 根据时间戳返回本地时间t_by_unix := time.Unix(1487780010, 0)fmt.Println("'time.Unix': ", t_by_unix)// 返回指定时间t_by_date := time.Date(2017, time.Month(2), 23, 1, 30, 30, 0, l)fmt.Println("'time.Date': ", t_by_date) 按照时区信息显示时间 func (t Time) UTC() Time {} // 获取指定时间在UTC 时区的时间表示 func (t Time) Local() Time {} // 以本地时区表示 func (t Time) In(loc *Location) Time {} // 时间在指定时区的表示 func (t Time) Format(layout string) string {} // 按指定格式显示时间 1234567891011121314// 获取指定时间在UTC 时区的时间表示t_by_utc := t.UTC()fmt.Println("'t.UTC': ", t_by_utc)// 获取本地时间表示t_by_local := t.Local()fmt.Println("'t.Local': ", t_by_local)// 时间在指定时区的表示t_in := t.In(time.UTC)fmt.Println("'t.In': ", t_in)// Formatfmt.Println("t.Format", t.Format(time.RFC3339)) 获取年月日等信息 func (t Time) Date() (year int, month Month, day int) {} // 返回时间的日期信息 func (t Time) Year() int {} // 返回年 func (t Time) Month() Month {} // 月 func (t Time) Day() int {} // 日 func (t Time) Weekday() Weekday {} // 星期 func (t Time) ISOWeek() (year, week int) {} // 返回年，星期范围编号 func (t Time) Clock() (hour, min, sec int) {} // 返回时间的时分秒 func (t Time) Hour() int {} // 返回小时 func (t Time) Minute() int {} // 分钟 func (t Time) Second() int {} // 秒 func (t Time) Nanosecond() int {} // 纳秒 func (t Time) YearDay() int {} // 一年中对应的天 func (t Time) Location() *Location {} // 时间的时区 func (t Time) Zone() (name string, offset int) {} // 时间所在时区的规范名和想对UTC 时间偏移量 func (t Time) Unix() int64 {} // 时间转为时间戳 func (t Time) UnixNano() int64 {} // 时间转为时间戳（纳秒） 123456789101112131415// 返回时间的日期信息year, month, day := t.Date()fmt.Println("'t.Date': ", year, month, day)// 星期week := t.Weekday()fmt.Println("'t.Weekday': ", week)// 返回年，星期范围编号year, week_int := t.ISOWeek()fmt.Println("'t.ISOWeek': ", year, week_int)// 返回时间的时分秒hour, min, sec := t.Clock()fmt.Println("'t.Clock': ", hour, min, sec) 时间运算 func (t Time) IsZero() bool {} // 是否是零时时间 func (t Time) After(u Time) bool {} // 时间在u 之前 func (t Time) Before(u Time) bool {} // 时间在u 之后 func (t Time) Equal(u Time) bool {} // 时间与u 相同 func (t Time) Add(d Duration) Time {} // 返回t +d 的时间点 func (t Time) Sub(u Time) Duration {} // 返回 t-u func (t Time) AddDate(years int, months int, days int) Time {} 返回增加了给出的年份、月份和天数的时间点Time 1234567// 返回增加了给出的年份、月份和天数的时间点Timet_new := t.AddDate(0, 1, 1)fmt.Println(&quot;&apos;t.AddDate&apos;: &quot;, t_new)// 时间在u 之前is_after := t.After(t_new)fmt.Println(&quot;&apos;t.After&apos;: &quot;, is_after) time.Duration的类型receiver实现的方法 func (d Duration) String() string // 格式化输出 Duration func (d Duration) Nanoseconds() int64 // 将时间段表示为纳秒 func (d Duration) Seconds() float64 // 将时间段表示为秒 func (d Duration) Minutes() float64 // 将时间段表示为分钟 func (d Duration) Hours() float64 // 将时间段表示为小时 1234567// time.Duration 时间段fmt.Println("time.Duration 时间段")d = time.Duration(10000000000000)//输入参数为int64类型fmt.Printf("'String: %v', 'Nanoseconds: %v', 'Seconds: %v', 'Minutes: %v', 'Hours: %v'\n", d.String(), d.Nanoseconds(), d.Seconds(), d.Minutes(), d.Hours())// 'String: 2h46m40s', 'Nanoseconds: 10000000000000', 'Seconds: 10000', 'Minutes: 166.66666666666666', 'Hours: 2.7777777777777777' time.Location的receiver实现的方法 func (l *Location) String() string // 输出时区名 func FixedZone(name string, offset int) *Location // FixedZone 使用给定的地点名name和时间偏移量offset（单位秒）创建并返回一个Location func LoadLocation(name string) (*Location, error) // LoadLocation 使用给定的名字创建Location func Sleep(d Duration) // Sleep阻塞当前go程至少d代表的时间段。d&lt;=0时，Sleep会立刻返回 12d_second := time.Secondtime.Sleep(d_second) 一些常用的技巧与代码示例 string与time.Time互转 12345678const ( date = "2006-01-02" datetime = "2006-01-02 15:04:02")timeStamp := time.Now().Format(date) //将当前时间，即time.Time类型转为stringbillTimeStamp, err := time.Parse(date,timeStamp)//将String类型的时间转为time.Time类型 unix time与String互转 1234567891011121314151617181920212223242526272829303132333435363738endTime := time.Unix(time.Now().Unix(), 0)//此时endTime是time.Time类型endStr := endTime.Format(datetime)//将unix time 转为了String，再根据上面的例子，可转为time.Timepackage mainimport ("fmt""time")func main() &#123;//获取时间戳timestamp := time.Now().Unix()fmt.Println(timestamp)//格式化为字符串,tm为Time类型tm := time.Unix(timestamp, 0)fmt.Println(tm.Format("2006-01-02 03:04:05 PM"))fmt.Println(tm.Format("02/01/2006 15:04:05 PM")) //从字符串转为时间戳，第一个参数是格式，第二个是要转换的时间字符串tm2, _ := time.Parse("01/02/2006", "02/08/2018")fmt.Println(tm2.Unix())&#125; 相关参考pkg/time中文翻译 pkg/time英文]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从冒泡排序优化到Go基准测试]]></title>
    <url>%2F2018%2F12%2F15%2F%E4%BB%8E%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96%E5%88%B0Go%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[Go的测试单元测试 测试文件命名：文件命名使用 xx_test.go 保存在项目目录里即可，也可以新建个test目录，TestAll； 测试函数命名：单元测试函数名Test开头，接收一个指针型参数（*testing.T）； 运行测试程序：go run test -v -run=”函数名”，其中-v意思是输出详细的测试信息； 基准测试 测试文件命名：测试文件命名：文件命名使用 xx_test.go 保存在项目目录里即可，也可以新建个test目录，TestAll； 测试函数命名：基准测试以Benchmark开头，接收一个指针型参数（*testing.B）； 运行测试程序：go test -v -bench=”函数名”； 还有一个参数是 -benchmem, -benchmem 表示分配内存的次数和字节数，-benchtime=”3s” 表示持续3秒 冒泡排序及其简单优化冒泡排序前几天看一个公众号，说是有个人去美团面试，被要求手写冒泡排序算法，这人心想这还不简单的，分分钟写下了下面的代码，可以说是非常标准的冒泡排序了 123456789101112func BubbleSort(array []int) &#123; i := 0 for i = 0; i&lt;len(array)-1;i++&#123; for j :=0;j&lt;len(array)-i-1;j++&#123; if array[j]&gt;array[j+1]&#123; swap(j, j+1) &#125; &#125; &#125;&#125; 但是随之，面试官说让他优化一下这个算法，问他有没有可优化的地方，这人就懵逼了。其实冒泡排序可优化的地方很多，最简单的一种就是加一个标志位，检查是否已经排序完毕，排序已经完成的话就没有必要再比较下去，浪费时间。上面的代码添加几行，那人就很可能拿到offer了。 123456789101112131415func BubbleSort(array []int) &#123; i := 0 for i = 0; i&lt;len(array)-1;i++&#123; exchanged := false for j :=0;j&lt;len(array)-i-1;j++&#123; if array[j]&gt;array[j+1]&#123; swap(j, j+1) exchanged = true &#125; &#125; if exchanged == false &#123; return &#125; &#125;&#125; 那么，如何更直观的看出，优化过的代码确实有效呢，我们就可以使用go自带的基准测试，测试一下两段代码的性能，优化与否就一目了然。 基准测试冒泡排序 首先我们创建一个存放测试文件的文件夹 1mkdir testAll 然后创建基准测试文件 1touch benchmark_test.go 编写基准测试代码 1234567var sortArray = []int&#123;41, 24, 76, 11, 45, 64, 21, 69, 19, 36&#125;func BenchmarkBubbleSort(b *testing.B) &#123; for i:=0;i&lt;b.N;i++ &#123; BubbleSort(sortArray) &#125;&#125; 测试基本冒泡排序 我们首先测试最原始的冒泡排序 在testAll文件夹下执行 1go test -v -bench=&quot;BubbleSort&quot; 基准测试结果如图所示，解释一下几个关键参数， 81.2ns/op 表示每次操作耗时81.2纳秒，1.725s表示程序运行的时间。 测试优化的冒泡排序 执行 1go test -v -bench=&quot;BubbleSort&quot; 可以看到优化过的代码，执行时间为1.2s,而且每次操作的耗时为23.0纳秒，足足降低了60%多。可见一个很简单的优化就可以使代码提升这么多，在以后的工作中，对于代码的设计与优化还是要重视。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>技术周刊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[postman 接口测试神器]]></title>
    <url>%2F2018%2F12%2F08%2Fpostman-%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E7%A5%9E%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Postman 接口测试神器Postman 是一个接口测试和 http 请求的神器，非常好用。 官方 github 地址: https://github.com/postmanlabs Postman 的优点： 支持各种的请求类型: get、post、put、patch、delete 等 支持在线存储数据，通过账号就可以进行迁移数据 很方便的支持请求 header 和请求参数的设置 支持不同的认证机制，包括 Basic Auth，Digest Auth，OAuth 1.0，OAuth 2.0 等 响应数据是自动按照语法格式高亮的，包括 HTML，JSON 和 XML 以下内容主要参考： Github: api_tool_postman 安装Postman 可以单独作为一个应用安装，也可以作为 chrome 的一个插件安装。 chrome 插件安装, Postman 插件地址 单独应用安装下载 下面主要介绍下载安装独立版本app 软件的 Postman 的过程： 去主页Postman 官网找到：Postman | Apps 去下载自己平台的版本： Mac Windows（x86/x64） Linux（x86/x64） 即可。 快速入门，总体使用方略安装成功后，打开软件。 新建接口对应的Request：New -&gt; Request 或，在右边的 Tab 页面中点击加号+： 即可看到新建的 Tab 页： 设置 HTTP 请求的方法设置 HTTP 的 Method 方法和输入 api 的地址 设置相关请求头信息 设置相关 GET 或 POST 等的参数 发送请求都填写好之后，点击 Send 去发送请求 Request： 查看响应 Response的信息 然后可以重复上述修改 Request 的参数，点击 Send 去发送请求的过程，以便调试到 API 接口正常工作为止。 保存接口配置待整个接口都调试完毕后，记得点击 Save 去保存接口信息： 去保存当前 API 接口，然后需要填写相关的接口信息： Request Name: 请求的名字 我一般习惯用保存为 接口的最后的字段名，比如http://{{server_address}}/ucows/login/login中的/login/login Request Description: 接口的描述 可选 最好写上该接口的要实现的基本功能和相关注意事项 支持 Markdown 语法 Select a collection or folder to save: 选择要保存到哪个分组（或文件夹） 往往保存到某个 API 接口到所属的该项目名的分组 填写好内容，选择好分组，再点击保存： 此时，Tab 的右上角的黄色点（表示没有保存）消失了，表示已保存。 且对应的分组中可以看到对应的接口了： [warning] 默认不保存返回的 Response 数据 直接点击 Save 去保存，只能保存 API 本身（的 Request 请求），不会保存 Response 的数据 想要保存 Response 数据，需要用后面要介绍的 多个 Example Request 的多参数操作详解自动解析多个参数 Params比如，对于一个 GET 的请求的 url 是： http://openapi.youdao.com/api?q=纠删码(EC)的学习&amp;from=zh_CHS&amp;to=EN&amp;appKey=152e0e77723a0026&amp;salt=4&amp;sign=6BE15F1868019AD71C442E6399DB1FE4 对应着其实是?key=value形式中包含多个 Http 的 GET 的 query string=query parameters Postman 可以自动帮我们解析出对应参数，可以点击 Params： 看到展开的多个参数： 如此就可以很方便的修改，增删对应的参数了。 临时禁用参数且还支持，在不删除某参数的情况下，如果想要暂时不传参数，可以方便的通过不勾选的方式去实现： 批量编辑 GET 的多个参数当然，如果想要批量的编辑参数，可以点击右上角的Bulk Edit，去实现批量编辑。 接口描述与自动生成文档API 的描述中，也支持 Markdown，官方的接口说明文档：Intro to API documentation。 所以，可以很方便的添加有条理的接口描述，尤其是参数解释了： 描述支持 markdown 语法 而对于要解释的参数，可以通过之前的Param -&gt; Bulk Edit的内容： 拷贝过来，再继续去编辑： 以及添加更多解释信息： 点击 Update 后，即可保存。 发布接口并生成 markdown 的描述文件去发布后： 对应的效果：有道翻译 Response 深入Response 数据显示模式Postman 对于返回的 Response 数据，支持三种显示模式。 默认格式化后的 Pretty 模式 Raw 原始模式 点击Raw，可以查看到返回的没有格式化之前的原始数据： Preview 预览模式 以及 Preview，是对应 Raw 原始格式的预览模式： Preview 这种模式的显示效果，好像是对于返回的是 html 页面这类，才比较有效果。 Response 的 Cookies很多时候普通的 API 调用，倒是没有 Cookie 的： Response 的 Headers 头信息举例，此处返回的是有 Headers 头信息的： 可以从中看到服务器是 Nginx 的。 保存多个 Example之前想要实现，让导出的 API 文档中能看到接口返回的 Response 数据。后来发现是Example这个功能去实现此效果的。 如何添加 Example 继续点击Save Example： 保存后，就能看到Example(1)了： 单个 Example 在导出的 API 文档中的效果然后再去导出文档，导出文档中的确能看到返回数据的例子： 多个 Example 在导出的 API 文档中的效果 其他好用的功能及工具分组 Collection在刚开始一个项目时，为了后续便于组织和管理，把同属该项目的多个 API，放在一组里 所以要先去新建一个 Collection: New -&gt; Collection 使用了段时间后，建了多个分组的效果： 单个分组展开后的效果： 历史记录 HistoryPostman 支持 history 历史记录，显示出最近使用过的 API： 用环境变量实现多服务器版本现存问题在测试 API 期间，往往存在多种环境，对应 IP 地址（或域名也不同） 比如： Prod: 1http://116.62.25.57/ucows 用于开发完成发布到生产环境 Dev: 1http://123.206.191.125/ucows 用于开发期间的线上的 Development 的测试环境 LocalTest: 1http://192.168.0.140:80/ucows 用于开发期间配合后台开发人员的本地局域网内的本地环境，用于联合调试 API 接口 而在测试 API 期间，往往需要手动去修改 API 的地址： 效率比较低，且地址更换后之前地址就没法保留了。 另外，且根据不同 IP 地址（或者域名）也不容易识别是哪套环境。 Postman 支持用 Environment 环境变量去实现多服务器版本后来发现 Postman 中，有 Environment 和 Global Variable，用于解决这个问题，实现不同环境的管理： 很明显，就可以用来实现不用手动修改 url 中的服务器地址，从而动态的实现，支持不同服务器环境: Production 生产环境 Development 开发环境 Local 本地局域网环境 如何使用 Enviroment 实现多服务器版本 或者： Environments are a group of variables &amp; values, that allow you to quickly switch the context for your requests and collections. Learn more about environments You can declare a variable in an environment and give it a starting value, then use it in a request by putting the variable name within curly-braces. Create an environment to get started. 输入 Key 和 value： 点击 Add 后： [info] 环境变量可以使用的地方 URL URL params Header values form-data/url-encoded values Raw body content Helper fields 写 test 测试脚本中 通过 postman 的接口，获取或设置环境变量的值。 此处把之前的在 url 中的 IP 地址（或域名）换成环境变量： 鼠标移动到环境变量上，可以动态显示出具体的值： 再去添加另外一个开发环境： 则可添加完 2 个环境变量，表示两个服务器地址，两个版本： 然后就可以切换不同服务器环境了： 可以看到，同样的变量 server_address，在切换后对应 IP 地址就变成希望的开发环境的 IP 了： Postman 导出 API 文档中多个环境变量的效果顺带也去看看，导出为 API 文档后，带了这种 Environment 的变量的接口，文档长什么样子： 发现是在发布之前，需要选择对应的环境的： 发布后的文档，可以看到所选环境和对应服务器的 IP 的： 当然发布文档后，也可以实时切换环境： 环境变量的好处当更换服务器时，直接修改变量的 IP 地址： 即可实时更新，当鼠标移动到变量上即可看到效果： 代码生成工具查看当前请求的 HTTP 原始内容对于当前的请求，还可以通过点击 Code 去查看对应的符合 HTTP 协议的原始的内容： 各种语言的示例代码Code Generation Tools比如： Swift 语言 Java 语言 其他各种语言 还支持其他各种语言： 目前支持的语言有： HTTP C (LibCurl) cURL C#(RestSharp) Go Java OK HTTP Unirest Javascript NodeJS Objective-C(NSURL) OCaml(Cohttp) PHP Python Ruby(NET::Http) Shell Swift(NSURL) 代码生成工具的好处是：在写调用此 API 的代码时，就可以参考对应代码，甚至拷贝粘贴对应代码，即可。 测试接口选中某个分组后，点击 Runner 选中某个分组后点击 Run 即可看到测试结果： 关于此功能的介绍可参考Postman 官网的git 图 MockServer直接参考官网。 功能界面多 Tab 分页Postman 支持多 tab 页，于此对比之前有些 API 调试工具就不支持多 Tab 页，比如Advanced Rest Client 多 tab 的好处： 方便在一个 tab 中测试，得到结果后，复制粘贴到另外的 tab 中，继续测试其它接口 比如此处 tab1 中，测试了获取验证码接口后，拷贝手机号和验证码，粘贴到 tab2 中，继续测试注册的接口 界面查看模式Postman 的默认的 Request 和 Response 是上下布局： 此处点击右下角的Two pane view，就变成左右的了： [info] 左右布局的用途 对于数据量很大，又想要同时看到请求和返回的数据的时候，应该比较有用。 多颜色主题Posman 支持两种主题： 深色主题 当前是深色主题，效果很不错： 浅色主题 可以切换到 浅色主题： API 文档生成在服务端后台的开发人员测试好了接口后，打算把接口的各种信息发给使用此 API 的前端的移动端人员时，往往会遇到： 要么是用复制粘贴 -&gt; 格式不友好 要么是用 Postman 中截图 -&gt; 方便看，但是不方便获得 API 接口和字段等文字内容 要么是用 Postman 中导出为 JSON -&gt; json 文件中信息太繁杂，不利于找到所需要的信息 要么是用文档，比如去编写 Markdown 文档 -&gt; 但后续 API 的变更需要实时同步修改文档，也会很麻烦 这都会导致别人查看和使用 API 时很不方便。 -&gt; 对此，Postman 提供了发布 API 预览和发布 API 文档 下面介绍 Postman 中如何预览和发布 API 文档。 简要概述步骤 Collection 鼠标移动到某个 Collection，点击 三个点 Publish Docs Publish 得到 Public URL 别人打开这个 Public URL，即可查看 API 文档 预览 API 文档点击分组右边的大于号&gt; 如果只是预览，比如后台开发员自己查看 API 文档的话，可以选择：View in web 等价于点击Publish Docs去发布： View in Web 后，有 Publish 的选项（见后面的截图） View in Web 后，会打开预览页面： 比如： 奶牛云 1https://documenter.getpostman.com/collection/view/669382-42273840-6237-dbae-5455-26b16f45e2b9 而右边的示例代码，也可以从默认的 cURL 换成其他的： 发布 API 文档如果想要让其他人能看到这个文档，则点击 Publish： 然后会打开类似于这样的地址： Postman Documenter 1https://documenter.getpostman.com/collection/publish?meta=Y29sbGVjdGlvbl9pZD00MjI3Mzg0MC02MjM3LWRiYWUtNTQ1NS0yNmIxNmY0NWUyYjkmb3duZXI9NjY5MzgyJmNvbGxlY3Rpb25fbmFtZT0lRTUlQTUlQjYlRTclODklOUIlRTQlQkElOTE= 点击 Publish 后，可以生成对应的公开的网页地址： 打开 API 接口文档地址： 1https://documenter.getpostman.com/view/669382/collection/77fd4RM 即可看到（和前面预览一样效果的 API 文档了）： 如此，别人即可查看对应的 API 接口文档。 已发布的 API 文档支持自动更新后续如果自己的 API 接口修改后： 比如： （后来发现，不用再去进入此预览和发布的流程，去更新文档，而是 Postman 自动支持） 别人去刷新该文档的页面： 1https://documenter.getpostman.com/view/669382/collection/77fd4RM 即可看到更新后的内容： 参考资料 主要参考：Github: api_tool_postman Manage environments postman-变量/环境/过滤等 - 简书 Postman 使用手册 3——环境变量 - 简书 postman 使用之四：切换环境和设置读取变量 - 乔叶叶 - 博客园]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>postman</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之influxDB使用入门]]></title>
    <url>%2F2018%2F12%2F08%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8BinfluxDB%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[前言InfluxDB是一个用于存储和分析时间序列数据的开源数据库。 主要特性有： 内置HTTP接口，使用方便 数据可以打标记，查让查询可以很灵活 类SQL的查询语句 安装管理很简单，并且读写数据很高效 能够实时查询，数据在写入时被索引后就能够被立即查出 …… 在最新的DB-ENGINES给出的时间序列数据库的排名中，InfluxDB高居第一位，可以预见，InfluxDB会越来越得到广泛的使用。 influxDB使用go语言编写，采用了SQL like的语法，非常灵活高效，如果你的数据是与时间相关的，那么使用influxDB做数据可视化是最合适不过的，尤其是influxDB自身就提供数据库CRUD所需要的API，虽然不是RESTFul的，但是也省去了编写后端接口的力气。 下面从influxDB的安装、使用CLI的influxdb基本操作、使用API对influxdb操作及golang代码实现、经历的坑，几个方面分享influxDB的入门经历。 安装 本次安装的环境是： CentOS 7 内核版本：4.4.135-1.el7.elrepo.x86_64 直接使用yum安装 123456789cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/influxdb.repo # 输入influxDB的repoURL地址等信息[influxdb] name = InfluxDB Repository - RHEL \$releasever baseurl = https://repos.influxdata.com/rhel/\$releasever/\$basearch/stable enabled = 1 gpgcheck = 1 gpgkey = https://repos.influxdata.com/influxdb.key EOF #EOF是文本的结束符 1sudo yum install influxdb influxd config 安装完成后使用该命令查看influxDB的配置内容，default的config文件路径在：/etc/influxdb/influxdb.conf 启动influxDB 12345[root@k8s-m1 ~]# influxConnected to http://localhost:8086 version 1.7.1InfluxDB shell version: 1.7.1Enter an InfluxQL query&gt; 到此完成了influxDB的安装，接下来我们做基本的配置。 配置 用户管理 12345678910-- 创建一个管理员用户CREATE USER "admin" WITH PASSWORD 'xxxx' WITH ALL PRIVILEGES-- 创建一个普通用户CREATE USER "user" WITH PASSWORD 'xxxxx'-- 为用户授权读权限GRANT READ ON [database] to "user"-- 为用户授权写权限GRANT WRITE ON [database] to "user"--------------------- # 需要修改InfluxDB的配置文件/etc/influxdb/influxdb.conf，设置http下的auth-enabled = true，重启后，使用influx命令登录数据库就需要用户名和密码了。（Influx命令实际上也是使用API来操作InfluxDB的，InfluxDB只提供了API接口） 查看用户 123456&gt; show usersuser admin---- -----admin truesjhan true&gt; influxDB的配置项目有很多，剩下的可以根据自己的需求继续研究，这里就不展开了。 在进行数据库基本操作之前我们必须了解一下infuxDB的一些基本概念 influxDB基本概念 influxDB里面最基本的概念就是，measurement，tags，fields，points。我们可以类比于MySQL来理解这几个字段： measurement类似于SQL中的table； tags类似SQL中的被索引的列； fields类似于SQL中没有被索引的列； points对应SQL的table中的每行数据。 知道了这几个概念，便可以继续往下进行，如需更加详细的文档，英文版文档猛戳这里，当然也有中文版，猛戳这里。不知为何中文版我只有番蔷才能访问。 influxDB基本操作 首先，跟MySQL一样，我们需要创建一个数据库 12345-- 创建数据库，默认设置CREATE DATABASE &quot;first_db&quot;-- 创建数据库，同时创建一个Retention Policy，数据保留时间描述-- Retention Policy各部分描述：DURATION为数据存储时长，下面的1d即只存1天的数据；REPLICATION为数据副本，一般在使用集群的时候才会设置为&gt;1；SHARD DURATION为分区间隔，InfluxDB默认对数据分区，填写30m即对数据每隔30分钟做一个新的分区；Name是RP的名字。CREATE DATABASE &quot;first_db&quot; WITH DURATION 1d REPLICATION 1 SHARD DURATION 30m NAME &quot;myrp&quot; 我们创建了一个influxDB的数据库，名字为first_db, 数据存储时间为一天，一个副本，每30分钟做一个新的分区。 influxDB插入数据 influx -username admin -password 我们插入一条数据到刚刚创建的数据库中 1insert product,productName=disk,usageType=pay,creator=zhangsan,appId=105 cost=3421.6 我们分析一下这条插入语句，其中product字段是influxDB中的measurement,前面讲基本概念的时候已经解释过，类似于MySQL中的table，“productName=disk,usageType=pay,creator=zhangsan,appId=105”，这一坨在influxDB中叫做tag set,可以理解为tag的一个集合，tag的类型只能是字符串的K-V，还有需要注意的是tag set与前面的measurement之间只有一个逗号，并没有空格！，一开始不知道这回事，怎么插入都是失败。“cost=3421.6”这个叫做filed set，filed的类型可以是float、boolean、integer。这样插入的一条数据，influxDB中叫做一个point。 查询操作 查询之前要选择你想查询的数据库 1use first_db 1select * from product 可以看到influxDB自动为我们的这个point加了一个timestamp，这个是数据的UNIX时间格式的时间精度，我们在启动数据库时可以定义这个precision，像下面这样 1influx --precision rfc3339 influxDB规定了很多时间精度，具体可以在命令行输出help查看 12precision &lt;format&gt; specifies the format of the timestamp: rfc3339, h, m, s, ms, u or ns# 可指定的时间精度 使用influxDB内置CLI执行查询操作 还是查询我们刚刚插入的那条数据,在命令行中输入以下命令 1curl -G 'http://localhost:8086/query?pretty=true' --data-urlencode "db=first_db" --data-urlencode "q=SELECT \"cost\" FROM \"product\" WHERE \"productName\"='disk'" 得到输出为json结构的查询结果 influxDB内置的API很大程度简化了后端的开发，使各种项目可以快速上线。 插入操作的API 在命令行中输入 12curl -i -XPOST 'http://localhost:8086/write?db=first_db' --data-binary 'weather,location=us-midwes temperature=125'# 插入一条数据，measurement=weather，tag=location，filed=temperature,时间戳为当地服务器时间 我们使用postman测试这个插入接口，以确定该接口的header，body等，为接下来使用go编写请求代码做好准备。通过分析URL，我们可知请求的param是db=first_db，–dat-binary这个参数，意味着你的request body必须是raw,而且header的content-Type=”text”,具体的postman设置参照下图： 点击Send之后，可以在下面看到response的statusCode是204，在http协议中，这个状态码意思是返回体中没有内容。 我们回到influxDB的terminal中查看一下，可以看到这条数据已经插入成功了。 GO操作influxDB的API实现插入数据 可以利用这样方便的API，编写代码，实现数据的批量采集、管理、展示，这里我用GO对插入数据的操作简单实现。 1234567891011func main() &#123; reqBody := "weather,location=us-midwes temperature=521 1475839730100400200" rb := []byte(reqBody) headers := map[string]string&#123; "Content-type": "text", &#125; resp, _,err := simpleHttpClient.DoRequest("POST","http://10.18.5.30:8086/write?db=first_db",headers,rb,10) if err != nil &#123; panic(err) &#125; fmt.Println(string(resp)) 使用的DoRequest方法来自这里，这个库对golang的http操作进行简单的封装，而且加入了错误处理，timeout异常检测等。 当然也可以使用Go自带的net/http包中的POST方法 12345678reqBody := "weather,location=us-midwes temperature=521 1475839730100400200" //rb := []byte(reqBody) rb := io.NewReader(reqBody) resp, err := http.Post("http://10.18.5.30:8086/write?db=first_db","text",rb) if err != nil &#123; panic(err) &#125; fmt.Println(string(resp)) 需要注意的是对request body的类型处理，net/http.post方法要求该参数的类型是io.reader，所以要使用io.NewReader()进行转换。 总结 以上就是对influxDB的入门介绍，包括基本概念，安装，配置，基本操作（CLI，API）以及使用GO编写操作数据库的代码。但influxDB的奥秘远不止这些，如需更加深入的研究可参阅官方文档。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>技术周刊</tag>
        <tag>influxDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(转载)golang语言并发与并行——goroutine和channel的详细理解(2)]]></title>
    <url>%2F2018%2F12%2F07%2F%E8%BD%AC%E8%BD%BD-golang%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C%E2%80%94%E2%80%94goroutine%E5%92%8Cchannel%E7%9A%84%E8%AF%A6%E7%BB%86%E7%90%86%E8%A7%A3-2%2F</url>
    <content type="text"><![CDATA[本文转载自，版权属于原作者。 Go语言的并发和并行不知道你有没有注意到一个现象，还是这段代码，如果我跑在两个goroutines里面的话: 12345678910111213141516171819var quit chan int = make(chan int)func loop() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, i) &#125; quit &lt;- 0&#125;func main() &#123; // 开两个goroutine跑函数loop, loop函数负责打印10个数 go loop() go loop() for i := 0; i &lt; 2; i++ &#123; &lt;- quit &#125;&#125; 我们观察下输出: 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 这是不是有什么问题？? 以前我们用线程去做类似任务的时候，系统的线程会抢占式地输出， 表现出来的是乱序地输出。而goroutine为什么是这样输出的呢？ goroutine是在并行吗？我们找个例子测试下: 1234567891011121314151617181920212223242526package mainimport &quot;fmt&quot;import &quot;time&quot;var quit chan intfunc foo(id int) &#123; fmt.Println(id) time.Sleep(time.Second) // 停顿一秒 quit &lt;- 0 // 发消息：我执行完啦！&#125;func main() &#123; count := 1000 quit = make(chan int, count) // 缓冲1000个数据 for i := 0; i &lt; count; i++ &#123; //开1000个goroutine go foo(i) &#125; for i :=0 ; i &lt; count; i++ &#123; // 等待所有完成消息发送完毕。 &lt;- quit &#125;&#125; 让我们跑一下这个程序(之所以先编译再运行，是为了让程序跑的尽量快,测试结果更好): 123go build test.gotime ./test./test 0.01s user 0.01s system 1% cpu 1.016 total 我们看到，总计用时接近一秒。 貌似并行了！ 我们需要首先考虑下什么是并发, 什么是并行 并行和并发从概念上讲，并发和并行是不同的, 简单来说看这个图片(原图来自这里) 两个队列，一个Coffee机器，那是并发 两个队列，两个Coffee机器，那是并行 更多的资料： 并发不是并行, 当然Google上有更多关于并行和并发的区别。 那么回到一开始的疑问上，从上面的两个例子执行后的表现来看，多个goroutine跑loop函数会挨个goroutine去进行，而sleep则是一起执行的。 这是为什么？ 默认地， Go所有的goroutines只能在一个线程里跑 。 也就是说， 以上两个代码都不是并行的，但是都是是并发的。 如果当前goroutine不发生阻塞，它是不会让出CPU给其他goroutine的, 所以例子一中的输出会是一个一个goroutine进行的，而sleep函数则阻塞掉了 当前goroutine, 当前goroutine主动让其他goroutine执行, 所以形成了逻辑上的并行, 也就是并发。 真正的并行为了达到真正的并行，我们需要告诉Go我们允许同时最多使用多个核。 回到起初的例子，我们设置最大开2个原生线程, 我们需要用到runtime包(runtime包是goroutine的调度器): 123456789101112131415161718192021222324import ( &quot;fmt&quot; &quot;runtime&quot;)var quit chan int = make(chan int)func loop() &#123; for i := 0; i &lt; 100; i++ &#123; //为了观察，跑多些 fmt.Printf(&quot;%d &quot;, i) &#125; quit &lt;- 0&#125;func main() &#123; runtime.GOMAXPROCS(2) // 最多使用2个核 go loop() go loop() for i := 0; i &lt; 2; i++ &#123; &lt;- quit &#125;&#125; 这下会看到两个goroutine会抢占式地输出数据了。 我们还可以这样显式地让出CPU时间： 123456789101112131415161718func loop() &#123; for i := 0; i &lt; 10; i++ &#123; runtime.Gosched() // 显式地让出CPU时间给其他goroutine fmt.Printf(&quot;%d &quot;, i) &#125; quit &lt;- 0&#125;func main() &#123; go loop() go loop() for i := 0; i &lt; 2; i++ &#123; &lt;- quit &#125;&#125; 观察下结果会看到这样有规律的输出: 10 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 其实，这种主动让出CPU时间的方式仍然是在单核里跑。但手工地切换goroutine导致了看上去的“并行”。 其实作为一个Python程序员，goroutine让我更多地想到的是gevent的协程，而不是原生线程。 关于runtime包对goroutine的调度，在stackoverflow上有一个不错的答案:http://stackoverflow.com/questions/13107958/what-exactly-does-runtime-gosched-do 一个小问题我在Segmentfault看到了这个问题: http://segmentfault.com/q/1010000000207474 题目说，如下的程序，按照理解应该打印下5次 &quot;world&quot;呀，可是为什么什么也没有打印 1234567891011121314151617package mainimport ( &quot;fmt&quot;)func say(s string) &#123; for i := 0; i &lt; 5; i++ &#123; fmt.Println(s) &#125;&#125;func main() &#123; go say(&quot;world&quot;) //开一个新的Goroutines执行 for &#123; &#125;&#125; 楼下的答案已经很棒了，这里Go仍然在使用单核，for死循环占据了单核CPU所有的资源，而main线和say两个goroutine都在一个线程里面， 所以say没有机会执行。解决方案还是两个： 允许Go使用多核(runtime.GOMAXPROCS) 手动显式调动(runtime.Gosched) runtime调度器runtime调度器是个很神奇的东西，但是我真是但愿它不存在，我希望显式调度能更为自然些，多核处理默认开启。 关于runtime包几个函数: Gosched 让出cpu NumCPU 返回当前系统的CPU核数量 GOMAXPROCS 设置最大的可同时使用的CPU核数 Goexit 退出当前goroutine(但是defer语句会照常执行) 总结我们从例子中可以看到，默认的, 所有goroutine会在一个原生线程里跑，也就是只使用了一个CPU核。 在同一个原生线程里，如果当前goroutine不发生阻塞，它是不会让出CPU时间给其他同线程的goroutines的，这是Go运行时对goroutine的调度，我们也可以使用runtime包来手工调度。 本文开头的两个例子都是限制在单核CPU里执行的，所有的goroutines跑在一个线程里面，分析如下: 对于代码例子一（loop函数的那个），每个goroutine没有发生堵塞(直到quit流入数据), 所以在quit之前每个goroutine不会主动让出CPU，也就发生了串行打印 对于代码例子二（time的那个），每个goroutine在sleep被调用的时候会阻塞，让出CPU, 所以例子二并发执行。 那么关于我们开启多核的时候呢？Go语言对goroutine的调度行为又是怎么样的？ 我们可以在Golang官方网站的这里 找到一句话: When a coroutine blocks, such as by calling a blocking system call, the run-time automatically moves other coroutines on the same operating system thread to a different, runnable thread so they won’t be blocked. 也就是说: 当一个goroutine发生阻塞，Go会自动地把与该goroutine处于同一系统线程的其他goroutines转移到另一个系统线程上去，以使这些goroutines不阻塞 开启多核的实验仍然需要做一个实验，来测试下多核支持下goroutines的对原生线程的分配, 也验证下我们所得到的结论“goroutine不阻塞不放开CPU”。 实验代码如下: 123456789101112131415161718192021222324252627package mainimport ( &quot;fmt&quot; &quot;runtime&quot;)var quit chan int = make(chan int)func loop(id int) &#123; // id: 该goroutine的标号 for i := 0; i &lt; 10; i++ &#123; //打印10次该goroutine的标号 fmt.Printf(&quot;%d &quot;, id) &#125; quit &lt;- 0&#125;func main() &#123; runtime.GOMAXPROCS(2) // 最多同时使用2个核 for i := 0; i &lt; 3; i++ &#123; //开三个goroutine go loop(i) &#125; for i := 0; i &lt; 3; i++ &#123; &lt;- quit &#125;&#125; 多跑几次会看到类似这些输出(不同机器环境不一样): 123450 0 0 0 0 1 1 0 0 1 0 0 1 0 1 2 1 2 1 2 1 2 1 2 1 2 2 2 2 20 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 20 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 1 2 1 2 1 2 2 2 2 2 2 2 20 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 2 0 2 0 2 2 2 2 2 2 2 20 0 0 0 0 0 0 1 0 0 1 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 2 2 执行它我们会发现以下现象: 有时会发生抢占式输出(说明Go开了不止一个原生线程，达到了真正的并行) 有时会顺序输出, 打印完0再打印1, 再打印2(说明Go开一个原生线程，单线程上的goroutine不阻塞不松开CPU) 那么，我们还会观察到一个现象，无论是抢占地输出还是顺序的输出，都会有那么两个数字表现出这样的现象: 一个数字的所有输出都会在另一个数字的所有输出之前 原因是， 3个goroutine分配到至多2个线程上，就会至少两个goroutine分配到同一个线程里，单线程里的goroutine 不阻塞不放开CPU, 也就发生了顺序输出。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(转载)golang语言并发与并行——goroutine和channel的详细理解(1)]]></title>
    <url>%2F2018%2F12%2F07%2F%E8%BD%AC%E8%BD%BD-golang%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C%E2%80%94%E2%80%94goroutine%E5%92%8Cchannel%E7%9A%84%E8%AF%A6%E7%BB%86%E7%90%86%E8%A7%A3-1%2F</url>
    <content type="text"><![CDATA[本篇博文转载自go语言中文网，版权属原作者所有。 如果不是我对真正并行的线程的追求，就不会认识到Go有多么的迷人。 Go语言从语言层面上就支持了并发，这与其他语言大不一样，不像以前我们要用Thread库 来新建线程，还要用线程安全的队列库来共享数据。 以下是我入门的学习笔记。 Go语言的goroutines、信道和死锁goroutineGo语言中有个概念叫做goroutine, 这类似我们熟知的线程，但是更轻。 以下的程序，我们串行地去执行两次loop函数: 1234567891011func loop() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, i) &#125;&#125;func main() &#123; loop() loop()&#125; 毫无疑问，输出会是这样的: 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 下面我们把一个loop放在一个goroutine里跑，我们可以使用关键字go来定义并启动一个goroutine: 1234func main() &#123; go loop() // 启动一个goroutine loop()&#125; 这次的输出变成了: 10 1 2 3 4 5 6 7 8 9 可是为什么只输出了一趟呢？明明我们主线跑了一趟，也开了一个goroutine来跑一趟啊。 原来，在goroutine还没来得及跑loop的时候，主函数已经退出了。 main函数退出地太快了，我们要想办法阻止它过早地退出，一个办法是让main等待一下: 12345func main() &#123; go loop() loop() time.Sleep(time.Second) // 停顿一秒&#125; 这次确实输出了两趟，目的达到了。 可是采用等待的办法并不好，如果goroutine在结束的时候，告诉下主线说“Hey, 我要跑完了！”就好了， 即所谓阻塞主线的办法，回忆下我们Python里面等待所有线程执行完毕的写法: 12for thread in threads: thread.join() 是的，我们也需要一个类似join的东西来阻塞住主线。那就是信道 信道信道是什么？简单说，是goroutine之间互相通讯的东西。类似我们Unix上的管道（可以在进程间传递消息）， 用来goroutine之间发消息和接收消息。其实，就是在做goroutine之间的内存共享。 使用make来建立一个信道: 123var channel chan int = make(chan int)// 或channel := make(chan int) 那如何向信道存消息和取消息呢？ 一个例子: 12345678func main() &#123; var messages chan string = make(chan string) go func(message string) &#123; messages &lt;- message // 存消息 &#125;(&quot;Ping!&quot;) fmt.Println(&lt;-messages) // 取消息&#125; 默认的，信道的存消息和取消息都是阻塞的 (叫做无缓冲的信道，不过缓冲这个概念稍后了解，先说阻塞的问题)。 也就是说, 无缓冲的信道在取消息和存消息的时候都会挂起当前的goroutine，除非另一端已经准备好。 比如以下的main函数和foo函数: 12345678910var ch chan int = make(chan int)func foo() &#123; ch &lt;- 0 // 向ch中加数据，如果没有其他goroutine来取走这个数据，那么挂起foo, 直到main函数把0这个数据拿走&#125;func main() &#123; go foo() &lt;- ch // 从ch取数据，如果ch中还没放数据，那就挂起main线，直到foo函数中放数据为止&#125; 那既然信道可以阻塞当前的goroutine, 那么回到上一部分「goroutine」所遇到的问题「如何让goroutine告诉主线我执行完毕了」 的问题来, 使用一个信道来告诉主线即可: 123456789101112131415var complete chan int = make(chan int)func loop() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, i) &#125; complete &lt;- 0 // 执行完毕了，发个消息&#125;func main() &#123; go loop() &lt;- complete // 直到线程跑完, 取到消息. main在此阻塞住&#125; 如果不用信道来阻塞主线的话，主线就会过早跑完，loop线都没有机会执行、、、 其实，无缓冲的信道永远不会存储数据，只负责数据的流通，为什么这么讲呢？ 从无缓冲信道取数据，必须要有数据流进来才可以，否则当前线阻塞 数据流入无缓冲信道, 如果没有其他goroutine来拿走这个数据，那么当前线阻塞 所以，你可以测试下，无论如何，我们测试到的无缓冲信道的大小都是0 (len(channel)) 如果信道正有数据在流动，我们还要加入数据，或者信道干涩，我们一直向无数据流入的空信道取数据呢？ 就会引起死锁 死锁一个死锁的例子: 1234func main() &#123; ch := make(chan int) &lt;- ch // 阻塞main goroutine, 信道c被锁&#125; 执行这个程序你会看到Go报这样的错误: 1fatal error: all goroutines are asleep - deadlock! 何谓死锁? 操作系统有讲过的，所有的线程或进程都在等待资源的释放。如上的程序中, 只有一个goroutine, 所以当你向里面加数据或者存数据的话，都会锁死信道， 并且阻塞当前 goroutine, 也就是所有的goroutine(其实就main线一个)都在等待信道的开放(没人拿走数据信道是不会开放的)，也就是死锁咯。 我发现死锁是一个很有意思的话题，这里有几个死锁的例子: 只在单一的goroutine里操作无缓冲信道，一定死锁。比如你只在main函数里操作信道: 12345func main() &#123; ch := make(chan int) ch &lt;- 1 // 1流入信道，堵塞当前线, 没人取走数据信道不会打开 fmt.Println(&quot;This line code wont run&quot;) //在此行执行之前Go就会报死锁&#125; 如下也是一个死锁的例子: 123456789101112var ch1 chan int = make(chan int)var ch2 chan int = make(chan int)func say(s string) &#123; fmt.Println(s) ch1 &lt;- &lt;- ch2 // ch1 等待 ch2流出的数据&#125;func main() &#123; go say(&quot;hello&quot;) &lt;- ch1 // 堵塞主线&#125; 其中主线等ch1中的数据流出，ch1等ch2的数据流出，但是ch2等待数据流入，两个goroutine都在等，也就是死锁。 其实，总结来看，为什么会死锁？非缓冲信道上如果发生了流入无流出，或者流出无流入，也就导致了死锁。或者这样理解 Go启动的所有goroutine里的非缓冲信道一定要一个线里存数据，一个线里取数据，要成对才行 。所以下面的示例一定死锁: 12345678c, quit := make(chan int), make(chan int)go func() &#123; c &lt;- 1 // c通道的数据没有被其他goroutine读取走，堵塞当前goroutine quit &lt;- 0 // quit始终没有办法写入数据&#125;()&lt;- quit // quit 等待数据的写 仔细分析的话，是由于：主线等待quit信道的数据流出，quit等待数据写入，而func被c通道堵塞，所有goroutine都在等，所以死锁。 简单来看的话，一共两个线，func线中流入c通道的数据并没有在main线中流出，肯定死锁。 但是，是否果真 所有不成对向信道存取数据的情况都是死锁? 如下是个反例: 1234567func main() &#123; c := make(chan int) go func() &#123; c &lt;- 1 &#125;()&#125; 程序正常退出了，很简单，并不是我们那个总结不起作用了，还是因为一个让人很囧的原因，main又没等待其它goroutine，自己先跑完了， 所以没有数据流入c信道，一共执行了一个goroutine, 并且没有发生阻塞，所以没有死锁错误。 那么死锁的解决办法呢？ 最简单的，把没取走的数据取走，没放入的数据放入， 因为无缓冲信道不能承载数据，那么就赶紧拿走！ 具体来讲，就死锁例子3中的情况，可以这么避免死锁: 123456789c, quit := make(chan int), make(chan int)go func() &#123; c &lt;- 1 quit &lt;- 0&#125;()&lt;- c // 取走c的数据！&lt;-quit 另一个解决办法是缓冲信道, 即设置c有一个数据的缓冲大小: 1c := make(chan int, 1) 这样的话，c可以缓存一个数据。也就是说，放入一个数据，c并不会挂起当前线, 再放一个才会挂起当前线直到第一个数据被其他goroutine取走, 也就是只阻塞在容量一定的时候，不达容量不阻塞。 这十分类似我们Python中的队列Queue不是吗？ 无缓冲信道的数据进出顺序我们已经知道，无缓冲信道从不存储数据，流入的数据必须要流出才可以。 观察以下的程序: 1234567891011121314151617var ch chan int = make(chan int)func foo(id int) &#123; //id: 这个routine的标号 ch &lt;- id&#125;func main() &#123; // 开启5个routine for i := 0; i &lt; 5; i++ &#123; go foo(i) &#125; // 取出信道中的数据 for i := 0; i &lt; 5; i++ &#123; fmt.Print(&lt;- ch) &#125;&#125; 我们开了5个goroutine，然后又依次取数据。其实整个的执行过程细分的话，5个线的数据 依次流过信道ch, main打印之, 而宏观上我们看到的即 无缓冲信道的数据是先到先出，但是 无缓冲信道并不存储数据，只负责数据的流通 缓冲信道终于到了这个话题了, 其实缓存信道用英文来讲更为达意: buffered channel. 缓冲这个词意思是，缓冲信道不仅可以流通数据，还可以缓存数据。它是有容量的，存入一个数据的话 , 可以先放在信道里，不必阻塞当前线而等待该数据取走。 当缓冲信道达到满的状态的时候，就会表现出阻塞了，因为这时再也不能承载更多的数据了，「你们必须把 数据拿走，才可以流入数据」。 在声明一个信道的时候，我们给make以第二个参数来指明它的容量(默认为0，即无缓冲): 1var ch chan int = make(chan int, 2) // 写入2个元素都不会阻塞当前goroutine, 存储个数达到2的时候会阻塞 如下的例子，缓冲信道ch可以无缓冲的流入3个元素: 123456func main() &#123; ch := make(chan int, 3) ch &lt;- 1 ch &lt;- 2 ch &lt;- 3&#125; 如果你再试图流入一个数据的话，信道ch会阻塞main线, 报死锁。 也就是说，缓冲信道会在满容量的时候加锁。 其实，缓冲信道是先进先出的，我们可以把缓冲信道看作为一个线程安全的队列： 12345678910func main() &#123; ch := make(chan int, 3) ch &lt;- 1 ch &lt;- 2 ch &lt;- 3 fmt.Println(&lt;-ch) // 1 fmt.Println(&lt;-ch) // 2 fmt.Println(&lt;-ch) // 3&#125; 信道数据读取和信道关闭你也许发现，上面的代码一个一个地去读取信道简直太费事了，Go语言允许我们使用range来读取信道: 12345678910func main() &#123; ch := make(chan int, 3) ch &lt;- 1 ch &lt;- 2 ch &lt;- 3 for v := range ch &#123; fmt.Println(v) &#125;&#125; 如果你执行了上面的代码，会报死锁错误的，原因是range不等到信道关闭是不会结束读取的。也就是如果 缓冲信道干涸了，那么range就会阻塞当前goroutine, 所以死锁咯。 那么，我们试着避免这种情况，比较容易想到的是读到信道为空的时候就结束读取: 12345678910ch := make(chan int, 3)ch &lt;- 1ch &lt;- 2ch &lt;- 3for v := range ch &#123; fmt.Println(v) if len(ch) &lt;= 0 &#123; // 如果现有数据量为0，跳出循环 break &#125;&#125; 以上的方法是可以正常输出的，但是注意检查信道大小的方法不能在信道存取都在发生的时候用于取出所有数据，这个例子 是因为我们只在ch中存了数据，现在一个一个往外取，信道大小是递减的。 另一个方式是显式地关闭信道: 1234567891011ch := make(chan int, 3)ch &lt;- 1ch &lt;- 2ch &lt;- 3// 显式地关闭信道close(ch)for v := range ch &#123; fmt.Println(v)&#125; 被关闭的信道会禁止数据流入, 是只读的。我们仍然可以从关闭的信道中取出数据，但是不能再写入数据了。 等待多gorountine的方案那好，我们回到最初的一个问题，使用信道堵塞主线，等待开出去的所有goroutine跑完。 这是一个模型，开出很多小goroutine, 它们各自跑各自的，最后跑完了向主线报告。 我们讨论如下2个版本的方案: 只使用单个无缓冲信道阻塞主线 使用容量为goroutines数量的缓冲信道 对于方案1, 示例的代码大概会是这个样子: 12345678910111213141516171819var quit chan int // 只开一个信道func foo(id int) &#123; fmt.Println(id) quit &lt;- 0 // ok, finished&#125;func main() &#123; count := 1000 quit = make(chan int) // 无缓冲 for i := 0; i &lt; count; i++ &#123; go foo(i) &#125; for i := 0; i &lt; count; i++ &#123; &lt;- quit &#125;&#125; 对于方案2, 把信道换成缓冲1000的: 1quit = make(chan int, count) // 容量1000 其实区别仅仅在于一个是缓冲的，一个是非缓冲的。 对于这个场景而言，两者都能完成任务, 都是可以的。 无缓冲的信道是一批数据一个一个的「流进流出」 缓冲信道则是一个一个存储，然后一起流出去]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql中字段名与保留字冲突]]></title>
    <url>%2F2018%2F12%2F04%2Fmysql%E4%B8%AD%E5%AD%97%E6%AE%B5%E5%90%8D%E4%B8%8E%E4%BF%9D%E7%95%99%E5%AD%97%E5%86%B2%E7%AA%81%2F</url>
    <content type="text"><![CDATA[在设计数据库的时候不小心将数据库的字段设置成了其内置的保留字，例如下面的这段： 123456CREATE TABLE IF NOT EXISTS `test_billing` (`vendor` varchar(255),`cn` varchar(255),`current_date` varchar(255),`cost` varchar(255)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 这样你在执行类似下面的查询时： 1select cn, cost from test_billing where current_date like&quot;2018-10%&quot;; 返回值中什么都没有，还带了一个warning： 1Empty set, 1 warning (0.00 sec) 原因就是字段current_date与MySQL内置的保留字冲突了，那么这时候你还急需查看这些数据，比较快的方法就是：在冲突字段上加反引号 current_date,即 1select cn, cost from test_billing where `current_date` like&quot;2018-10%&quot;; 就可以解决了。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用操作]]></title>
    <url>%2F2018%2F12%2F02%2Fgit%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[首先来一遍从fork到pull request这个过程的基础流程首先，fork 一个repository，实际上是复制了一份 repository 到自己的 GitHub 账户下，然后就可以从 GitHub 将它 clone 到你的电脑上，命令如下： git clone 连接到原始的Repository，因为如果原始的Repository内容有所改变时，我们希望能够pull这些变化，所以新增一个远端链接，并把它命名为’upstream’，命令如下： git remote add upstream 新增branch分支，并选用新增分支。避免与主分支master造成冲突，当我们在新增分支上完成了自己的功能后再合并到主分支，命令如下： git branch git checkout git checkout -b –创建新的分支并切换到新的分支上记录，在我们自己的分支上修改后，需要记录下来。 git status –查看当前状态git add -A –记录修改文件，加上 -A，會將新增檔案跟刪除檔案的動作一起記錄下來git commit -m “add a file” –提交全部修改git checkout master –第二天开始工作前，切换到master分支git pull origin master –从master的远程分支拉取代码git checkout –切换到task所在的本地分支git rebase -i master –将master上的最新的代码合并到当前分支上，这里的-i的作用是将我们 当前分支之前的commit压缩成为一个commit，这样做的好处在于当我们之后创建pull request并进行相应的code review的时候，代码的改动会集中在一个commit，使得code review更直观方便git push –set-upstream origin –最后，当task的所有编码完成之后，将代码push到远程分支先获取远端，再提交，每次提交代码前，都需要先获取最新代码，防止覆盖他人代码 git fetch –dry-run –检查远端是否有变动git pull –从远端分支更新最新代码建立Pull Requests，进入你的github项目页，一般情况下 GitHub会检测到你有了新的推送，会主动提示你，点击Create pull request，写上说明，再按Send pull request就完成了，如果 Pull Request 沒有问题的话，很快就會被自动合并 merged 了哦！ 本地合并分支，并删除分支，将分支合并到主分支上，并删除之 git checkout master –首先切换到主分支中git merge –合并另一个分支进来git branch -d –删掉刚刚合并的分支git push –delete –也可以把合并分支从GitHub上的副本repository中刪除其他常用命令git init –将一个文件夹初始化为git仓库git status –检查当前repository中的修改git diff –查看对文件的修改git add –准备提交对于一个文件的修改git add . –准备提交对所有文件的修改git commit -m ““ –提交你所准备好的修改，并附上简短说明git config –global user.username –配置github账号git remote add –新增远端链接git remote set-url –对一个远端设定地址git remote add –新增带地址的远端链接git remote -v –查看所有远端git pull –从一个远端收取更新（默认为主分支）git push –提交代码到指定远端（默认为主分支）git branch -M –修改当前分支名字git branch –列出所有分支]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ionic project-Could not find module @angular-devkit/build-angular from XXX]]></title>
    <url>%2F2018%2F11%2F30%2Fionic-project-Could-not-find-module-angular-devkit-build-angular-from-XXX%2F</url>
    <content type="text"><![CDATA[从GitHub上找了一个ionic的demo，准备运行一下，报错：Could not find module @angular-devkit/build-angular from XXX 操作步骤： git clone https://github.com/ionic-team/ionic-conference-app.git ionic serve 报错： 1Could not find module &quot;@angular-devkit/build-angular&quot; from 解决方案： npm install –save @angular-devkit/build-angular]]></content>
      <categories>
        <category>frontEnd</category>
      </categories>
      <tags>
        <tag>angular</tag>
        <tag>ionic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快排之golang实现]]></title>
    <url>%2F2018%2F11%2F18%2F%E5%BF%AB%E6%8E%92%E4%B9%8Bgolang%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[快速排序由C. A. R. Hoare在1962年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 利用分治法可将快速排序的分为三步： 在数据集之中，选择一个元素作为”基准”（pivot）。 所有小于”基准”的元素，都移到”基准”的左边；所有大于”基准”的元素，都移到”基准”的右边。这个操作称为分区 (partition) 操作，分区操作结束后，基准元素所处的位置就是最终排序后它的位置。 对”基准”左边和右边的两个子集，不断重复第一步和第二步，直到所有子集只剩下一个元素为止。 快速排序平均时间复杂度为O(n log n),最坏情况为O(n2)，不稳定排序。 这里实现了两种方式的快排，第一种是单路的，实现代码如下： 123456789101112131415func partition(sortArray []int, left, right int) int &#123; key := sortArray[right] i := left - 1 for j := left; j &lt; right; j++ &#123; if sortArray[j] &lt;= key &#123; i++ swap(i, j) &#125; &#125; swap(i+1, right) return i + 1&#125; 第二种是双路的： 123456789101112131415161718192021222324252627unc partition2(arr []int,left,right int)(p int) &#123; if left &gt; right &#123; return &#125; i,j,pivot := left,right ,arr[left] for i&lt;j &#123; for i &lt; j &amp;&amp; arr[j] &gt;pivot &#123; j-- &#125; for i &lt; j &amp;&amp; arr[i] &lt;= pivot &#123; i++ &#125; if i &lt; j &#123; arr[i] ,arr[j] = arr[j],arr[i] &#125; &#125; arr[i],arr[left] = arr[left],arr[i] return i 测试代码如下： 12345678910111213141516171819202122import ("fmt")const MAX = 10var sortArray = []int&#123;41, 24, 76, 11, 45, 64, 21, 69, 19, 36&#125;func main() &#123; fmt.Println("before sort：") quickSort(sortArray, 0, MAX-1) fmt.Println("after sort:")&#125;func quickSort(sortArray []int, left, right int) &#123; if left &lt; right &#123; pos := partition2(sortArray, left, right)//修改此处测试不同的实现方式 quickSort(sortArray, left, pos-1) quickSort(sortArray, pos+1, right) &#125;&#125; BUT! 要表达快排的思想，还是使用Python比较透彻： 123456789def quickSort(array): if len(array) &lt; 2: return array else: pivot = array[0] less = [i for i in array[1:] if i &lt;= pivot] greater = [i for i in array[1:] if i &gt; pivot] return quickSort(less) + [pivot] + quickSort(greater) 是不是将快排的分治思想表达地淋漓尽致，简洁美观。 ​ ​ End！]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>go 数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git如何找回被删除的分支]]></title>
    <url>%2F2018%2F11%2F15%2Fgit%E5%A6%82%E4%BD%95%E6%89%BE%E5%9B%9E%E8%A2%AB%E5%88%A0%E9%99%A4%E7%9A%84%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[在使用git的过程中，因为人为因素造成分支（commit)被删除，可以使用以下步骤进行恢复。 首先用以下步骤创建一个新分支，修改一些文件后删除，以便进行恢复。1.创建分支 abc git branch abc1 2.查看分支列表 git branch -a abc developremotes/origin-dev/develop1234 3.切换到abc分支，随便修改一下东西后 commit 切换分支git checkout abcSwitched to branch ‘abc’ 创建一个文件echo ‘abc’ &gt; test.txt commitgit add .git commit -m ‘add test.txt’[abc 3eac14d] add test.txt 1 file changed, 1 insertion(+) create mode 100644 test.txt12345678910111213 4.删除分支abc git branch -D abcDeleted branch abc (was 3eac14d).12 5.查看分支列表，abc分支已不存在 git branch -a developremotes/origin-dev/develop123 恢复步骤如下：1.使用git log -g 找回之前提交的commitcommit 3eac14d05bc1264cda54a7c21f04c3892f32406aReflog: HEAD@{1} (fdipzone &#102;&#x64;&#105;&#x70;&#x7a;&#x6f;&#x6e;&#x65;&#x40;&#x73;&#x69;&#110;&#x61;&#46;&#x63;&#111;&#x6d;)Reflog message: commit: add test.txtAuthor: fdipzone &#x66;&#100;&#105;&#x70;&#x7a;&#x6f;&#x6e;&#x65;&#x40;&#x73;&#x69;&#110;&#x61;&#x2e;&#99;&#x6f;&#x6d;Date: Sun Jan 31 22:26:33 2016 +0800 add test.txt 123456789 2.使用git branch recover_branch[新分支] commit_id命令用这个commit创建一个分支git branch recover_branch_abc 3eac14d05bc1264cda54a7c21f04c3892f32406a git branch -a developrecover_branch_abcremotes/origin-dev/develop123456可以见到recover_branch_abc已创建 3.切换到recover_branch_abc分支，检查文件是否存在git checkout recover_branch_abcSwitched to branch ‘recover_branch_abc’ ls -lttotal 8-rw-r–r– 1 fdipzone staff 4 1 31 22:38 test.txt123456 这样就可以恢复被误删的分支了原文：https://blog.csdn.net/fdipzone/article/details/50616386版权声明：本文为博主原创文章，转载请附上博文链接！]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang读取命令行传来的参数]]></title>
    <url>%2F2018%2F11%2F06%2Fgolang%E8%AF%BB%E5%8F%96%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BC%A0%E6%9D%A5%E7%9A%84%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Golang-使用命令行参数Golang有两个标准包中都有获得命令行参数的方法： 12[*]os/Args可以简单地获得一个类似Ｃ语言中的argv结构[*]flag则提供了一个更为复杂的标志与值的方法 os.Argsos.Args返回一个字符串数组[] string. 使用方法很简单：package main 12345678import ( &quot;fmt&quot; &quot;os&quot;)func main() &#123; fmt.Println(os.Args)&#125; 使用命令：go run test.go arg1 arg2 可见返回了一个三个元素的数组，第０个元素是程序的名字包括路径，os.Args就第一个参数，os.Args就是第二个参数。 flag包flag包提供的功能非常复杂。 它将命令行参数分为非标志类参数(nonflag arguments)和Flags，标志参数是这样的-flagname=x，比如说-baudrate=1200。 非标志类参数为arg1 arg2。 flag参数处理流程由于标志类参数是参数的一部分，但又特殊，为了将标志类参数区别处理 flag包有两类方法，一类是flag处理方法，另一类是正常的参数处理方法。 正常的参数处理方法正常参数处理方法与os.Args差不多，这里是一个方法，flag.Args()，返回也是[]string. 1234567891011121314package mainimport ( &quot;fmt&quot;/* &quot;os/exec&quot; &quot;bytes&quot;*/ &quot;flag&quot;)func main() &#123; flag.Parse() fmt.Println(flag.Args())&#125; go run test.go arg1 arg2 如果有标志类参数呢？ 1go run test.go arg1 arg2 -baudrate=1200 这里充分证明了标志类参数也是参数。 标志类参数Parse前定义如果使用标志类参数，要提前定义,定义之后再调用Parse才能解析出来： 12345678910111213141516package mainimport ( &quot;fmt&quot; &quot;flag&quot;)func main() &#123; baudrate:=flag.Int(&quot;baudrate&quot;,1200, &quot;help message for flagname&quot;) databits:=flag.Int(&quot;databits&quot;,10,&quot;number of data bits&quot;) flag.Parse() fmt.Println(*baudrate) fmt.Println(*databits) fmt.Println(flag.Args())&#125;go run test.go -baudrate=9600 -databits=8 arg1 arg2 标志类参数必须在Parse之定义，否则会出错： 123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;flag&quot;)func main() &#123; flag.Parse() baudrate:=flag.Int(&quot;baudrate&quot;,1200, &quot;help message for flagname&quot;) databits:=flag.Int(&quot;databits&quot;,10,&quot;number of data bits&quot;) fmt.Println(*baudrate) fmt.Println(*databits) fmt.Println(flag.Args())&#125;go run test.go -baudrate=9600 -databits=8 arg1 arg2flag provided but not defined: -baudrateUsage of /tmp/go-build944578075/command-line-arguments/_obj/a.out:exit status 2 flag.Int返回的是地址 需要注意的是这里flag.Int返回的值为一个地址，你可以随时到这个地址里去取值 但在Parse之前取值，取到的是默认值，Parse之后去随值，取到的才是真正的值： 1234567891011121314151617package mainimport ( &quot;fmt&quot; &quot;flag&quot;)func main() &#123; baudrate:=flag.Int(&quot;baudrate&quot;,1200, &quot;help message for flagname&quot;) databits:=flag.Int(&quot;databits&quot;,10,&quot;number of data bits&quot;) fmt.Println(*baudrate) fmt.Println(*databits) flag.Parse() fmt.Println(flag.Args())&#125;go run test.go -baudrate=9600 -databits=8 arg1 arg2 标志类参数顺序 标志类参数之间的前后顺序可以改变，但是似乎标志类参数非要放到非标志类参数之前才能正确解析。 12345678910111213141516package mainimport ( &quot;fmt&quot; &quot;flag&quot;)func main() &#123; databits:=flag.Int(&quot;databits&quot;,10,&quot;number of data bits&quot;) baudrate:=flag.Int(&quot;baudrate&quot;,1200, &quot;help message for flagname&quot;) flag.Parse() fmt.Println(*baudrate) fmt.Println(*databits) fmt.Println(flag.Args())&#125;go run test.go -baudrate=9600 -databits=8 arg1 arg2 上面的命令正确解析了，调换了baudrate和databits的顺序 1go run test.go arg1 -baudrate=9600 -databits=8 arg2 上前这里没能正确解析，可以baudrate和databits得到的还是默认值，而非标志类参数获取到了所有的参数。 –help flag.Int的最后一个参数是help信息： 123456go run test.go --helpUsage of /tmp/go-build327358548/command-line-arguments/_obj/a.out: -baudrate=1200: help message for flagname -databits=10: number of data bitsexit status 2 flag.String传入的参数显然不能都是数字，实际go语言提供的类型都支持，与flag.Int类似，所有其他函数都有： 1flag.String flag.Uint flag.Float64.... flag.IntVarflag.Int返回的是指针，用起来可以有点不太好，flag.IntVar可能用起来更好的些： 1234var baudrate intflag.IntVar(&amp;baudrate,&quot;baudrate&quot;,1200,&quot;baudrate of serial port&quot;)flag.Parse()fmt.Println(baudrate) 当前你一样可以用flag.UintVar flag.Float64Var flag.StringVar 参数个数参数个数也分为标志类参数的非标志类参数，两个方法为NArg和NFlag, 123456789101112131415161718package mainimport ( "fmt" "flag")func main() &#123; databits:=flag.Int("databits",10,"number of data bits") baudrate:=flag.Int("baudrate",1200, "help message for flagname") flag.Parse() fmt.Println(*baudrate) fmt.Println(*databits) fmt.Println(flag.Args()) fmt.Println(flag.NArg()) fmt.Println(flag.NFlag())&#125;go run test.go -baudrate=9600 -databits=8 arg1 arg2 以上代码的执行的过程以及执行结果是： 从上到下打印出的参数含义分别是： 1111：指定的标志类参数baudrate，默认值是1200，可随意更改； 1011： 指定的标志类参数databits，默认值是10，可随意更改； [la, la]:非标志类参数为arg1 arg2； 2：非标志类参数的数量 2：标志类参数的数量 ​ The End!]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL使用group by分组后对每组操作]]></title>
    <url>%2F2018%2F11%2F05%2FMySQL%E4%BD%BF%E7%94%A8group-by%E5%88%86%E7%BB%84%E5%90%8E%E5%AF%B9%E6%AF%8F%E7%BB%84%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[group by 操作 分组能够将数据分成几个逻辑组，然后对其进行聚集操作 前几天开发的时候遇到这样的一个问题，有一个vender-cost表： mysql&gt; select * from vendor-cost;+———+————–+————–+———–+————+———-+———-+ vendor host vendor_id start_date cost +———+————–+————–+———–+————+———-+———-+| Tencent | ins-m9faipc4 | 100014390 | 2018-10 | 0.015456 || ——- | ———— | ——— | ——- | ——– || | | | | || Tencent | ins-r76jxurv | 100015923 | 2018-10 | 0.284697 || ——- | ———— | ——— | ——- | ——– || | | | | || Tencent | ins-ramdkuqz | 100015923 | 2018-10 | 0.021175 || ——- | ———— | ——— | ——- | ——– || | | | | || Tencent | ins-q7o1dhsa | 100014390 | 2018-10 | 0.113501 || ——- | ———— | ——— | ——- | ——– || | | | | || Tencent | ins-5xxrgd65 | 100015923 | 2018-10 | 0.058623 || ——- | ———— | ——— | ——- | ——– || | | | | || Tencent | ins-79g28kn6 | 100015923 | 2018-10 | 0.03808 || ——- | ———— | ——— | ——- | ——- || | | | | || Tencent | ins-rw54ka4k | 100015923 | 2018-10 | 0.150595 || ——- | ———— | ——— | ——- | ——– || | | | | || Tencent | ins-ggxrtm1v | 100015923 | 2018-10 | 0.068281 || ——- | ———— | ——— | ——- | ——– || | | | | |为了统计出每个vendor_id的cost，就需要使用分组语句，将同一个vendor_id的cost求和： select vendor_id, sum(cost) from vendor_cost group by vendor_id; 得出的结果就是每个vendor_id的总cost。 还有一种group by的用法：GROUP BY X, Y意思是将所有具有相同X字段值和Y字段值的记录放到一个分组里。 举个栗子： 现在有表格 Table: Subject_Selection Subject Semester AttendeeITB001 1 JohnITB001 1 BobITB001 1 MickeyITB001 2 JennyITB001 2 JamesMKB114 1 JohnMKB114 1 Erica 我们下面再接着要求统计出每门学科每个学期有多少人选择，应用如下SQL 123SELECT Subject, Semester, Count(*)FROM Subject_SelectionGROUP BY Subject, Semester 得到的结果是： 得到的结果是：12345Subject Semester Count------------------------------ITB001 1 3ITB001 2 2MKB114 1 2 从表中的记录我们可以看出这个分组结果是正确的有3个学生在第一学期选择了ITB001, 2个学生在第二学期选择了ITB001,还有两个学生在第一学期选择了MKB114, 没人在第二学期选择MKB114。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang xorm 操作指南]]></title>
    <url>%2F2018%2F10%2F31%2Fgolang-xorm-%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[https://www.kancloud.cn/xormplus/xorm/167077]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之golang中修改struct的slice的值]]></title>
    <url>%2F2018%2F10%2F27%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8Bgolang%E4%B8%AD%E4%BF%AE%E6%94%B9struct%E7%9A%84slice%E7%9A%84%E5%80%BC%2F</url>
    <content type="text"><![CDATA[前言 前段时间写go的时候遇到一个问题，需要修改由struct构成的slice中struct的某个字段值，类似于下面的需求： 1234567891011121314151617181920type Docker struct &#123; Ip string ID string&#125;docker1 := Docker&#123; Ip: "222", ID: "aaa", &#125; docker2 := Docker&#123; Ip: "111", ID: "bbb", &#125; var tmpDocker []Docker tmpDocker = append(tmpDocker, docker1) tmpDocker = append(tmpDocker, docker2) 现在需要修改tmpDocker中，Ip这个字段的值, 你可以先自己尝试修改一下，然后再往下看 由这个问题我查阅很多资料，我们先从语言中经典的传值、传引用说起来 对于一门语言，我们关心传递参数的过程中，是传值还是传引用，其实对于传值和传引用是一个比较古老的问题，在大学入门的时候，你可能就接触过这样的C语言代码： 12345678910111213141516171819//以下哪个函数能实现交换两个数？#include&lt;iostream&gt;using namespace std; void swap1(int p,int q)&#123; int temp; temp=p; p=q; q=temp;&#125; void swap2(int *p,int *q)&#123; int *temp; *temp=*p; *p=*q; *q=*temp;&#125; 其实对于C语言来说，并没有传引用的概念，看似传引用的操控，实际上传的是指针的地址，也算是一种传值，先看一下传值，传引用，传指针的概念： 传值：可能很多人都听说，传值无非就是实参拷贝传递给形参。这句话没有错，但是理解起来还是有点抽象。一句话，传值就是把实参赋值给形参，赋值完毕后实参就和形参没有任何联系，对形参的修改就不会影响到实参。 传地址：为什么说传地址也是一种传值呢？因为传地址是把实参地址的拷贝传递给形参。还是一句话，传地址就是把实参的地址复制给形参。复制完毕后实参的地址和形参的地址没有任何联系，对实参形参地址的修改不会影响到实参, 但是对形参地址所指向对象的修改却直接反应在实参中，因为形参指向的对象就是形参的对象。 传引用：传引用本质没有任何实参的拷贝，一句话，就是让另外一个变量也执行该实参。就是两个变量指向同一个对象。这是对形参的修改，必然反映到实参上。 那么对于go语言来说，是没有引用传递的，go作为云计算时代的C语言，采用的都是值传递，即使是指针，也是将指针的地址即指针的指针，拷贝一份传递，可以参考这篇博文的讲解：Go语言参数传递是传值还是传引用 回到正题 了解基本的知识背景之后，让我们回到文章开头的代码，即要修改slice中struct某字段的值。 123456789101112131415161718type Docker struct &#123; Ip string ID string&#125;docker1 := Docker&#123; Ip: &quot;222&quot;, ID: &quot;aaa&quot;, &#125; docker2 := Docker&#123; Ip: &quot;111&quot;, ID: &quot;bbb&quot;, &#125; var tmpDocker []Docker tmpDocker = append(tmpDocker, docker1) tmpDocker = append(tmpDocker, docker2) 先将我最初的代码实现贴出来： 12345 for _, dockerInfo := range tmpDocker &#123; dockerInfo.Ip = "192.168,.1.1"&#125;fmt.Println(tmpDocker) 让我们看一下运行结果： 发现struct中Ip字段的值并没有改变，是为什么呢？ 原因就是：range的过程中产生了一个新的对象，即dockerInfo是temDocker中每个元素的一个副本，所以你改变的只是副本中Ip字段的值，并没有改变真实的。那么如何解决呢? 这里我提出两种解决的方法，代码如下： 1234567//方法1：赋给一个新的对象newTmpDocker := []Docker&#123;&#125;//新的对象for _, dockerInfo := range tmpDocker &#123; dockerInfo.Ip = "192.168.1.1" newTmpDocker = append(newTmpDocker, dockerInfo)&#125;fmt.Println(newTmpDocker) 可以看到最终输出的struct的slice中我们想要改变的字段已经修改成功。 第二种方法是将副本修改后赋值 123456方法2：修改副本后，将副本赋值给原来的for i, dockerInfo := range tmpDocker&#123; dockerInfo.Ip = "192.168.1.1" tmpDocker[i] = dockerInfo&#125;fmt.Println(tmpDocker) 运行结果： 可以看到同样修改成功。 总结，在go中，所有传参都是传值，都是一个副本，即一个拷贝，因为拷贝的内容有时候是非引用类型（int、string、struct等这些），这样就在函数中就无法修改原内容数据；有的是引用类型（指针、map、slice、chan等这些），这样就可以修改原内容数据。是否可以修改原内容数据，和传值、传引用没有必然的关系。在C++中，传引用肯定是可以修改原内容数据的，在Go语言里，虽然只有传值，但是我们也可以修改原内容数据，因为参数是引用类型。 这里也要记住，引用类型和传引用是两个概念。 再记住，Go里只有传值（值传递）。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>技术周刊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang中string,rune,byte的关系]]></title>
    <url>%2F2018%2F10%2F25%2Fgolang%E4%B8%ADstring-rune-byte%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[golang中String的底层是使用byte[]数组存储的，不可改变 12str := "Golang 测试"fmt.Println(len(str)) 这段代码按道理应该输出6+1+2. 实际运行之后输出却是13， 原因是中文字符在utf-8编码的系统中是3个字节存储的，在Unicode中是2个字节存储的，go的默认编码格式是utf-8，so。。 这时候，我们使用下标访问字符串中的中文字符是不行的，想要使用下标访问，就需要rune出马。 在官方文档中，rune的定义是： 123456 rune is an alias for int32 and is equivalent to int32 in all ways. It is used, by convention, to distinguish character values from integer values.int32的别名，几乎在所有方面等同于int32它用来区分字符值和整数值type rune int32 那么我们想要得到预期字符串的长度，就要使用rune切片来实现。 1fmt.Println("rune:", len([]rune(str))) 就会输出预期的rune: 9. 这时我们也可以按照下标去访问str中的字符了。即[7]rune(str) = “测”。 3.总结 string的底层是byte，byte与rune的不同之处是： byte 等同于int8，常用来处理ascii字符rune 等同于int32,常用来处理unicode或utf-8字符 或者可以这样说： rune 能操作任何字符byte 不支持中文的操作 ​ END]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[上海QCon之Go专家David Cheney关于GO最佳实践的演讲]]></title>
    <url>%2F2018%2F10%2F21%2F%E4%B8%8A%E6%B5%B7QCon%E4%B9%8BGo%E4%B8%93%E5%AE%B6David-Cheney%E5%85%B3%E4%BA%8EGO%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%E7%9A%84%E6%BC%94%E8%AE%B2%2F</url>
    <content type="text"><![CDATA[本周六有幸参加了2018QCon上海的会议，听了David关于GO最佳实践的一些建议，下面贴出的就是David的演讲稿，内容相对来说比较基础，但是又是编程中不可避免的一些问题，希望可以给大家带来一些启发。 Table of Contents Introduction \1. Guiding principles 1.1. Simplicity 1.2. Readability 1.3. Productivity \2. Identiers 2.1. Choose identiers for clarity, not brevity 2.2. Identier length 2.3. Don’t name your variables for their types 2.4. Use a consistent naming style 2.5. Use a consistent declaration style 2.6. Be a team player \3. Comments 3.1. Comments on variables and constants should describe their contents not their purpose 3.2. Always document public symbols \4. Package Design 4.1. A good package starts with its name 4.2. Avoid package names like base , common , or util 4.3. Return early rather than nesting deeply 4.4. Make the zero value useful 4.5. Avoid package level state \5. Project Structure 5.1. Consider fewer, larger packages 5.2. Keep package main small as small as possible \6. API Design 6.1. Design APIs that are hard to misuse. 6.2. Design APIs for their default use case 6.3. Let functions dene the behaviour they requires \7. Error handling 7.1. Eliminate error handling by eliminating errors 7.2. Only handle an error once \8. Concurrency 8.1. Keep yourself busy or do the work yourself 8.2. Leave concurrency to the caller 8.3. Never start a goroutine without when it will stop. Introduction Hello, My goal over the next two sessions is to give you my advice for best practices writing Go code. https://dave.cheney.net/practical-go/presentations/qcon-china.html 1/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs This is a workshop style presentation, I’m going to dispense with the usual slide deck and we’ll work directly from the document which you can take away with you today. TIP You can find the latest version of this presentation at https://dave.cheney.net/practical-go/presentations/qcon-china.html \1. Guiding principles If I’m going to talk about best practices in any programming language I need some way to define what I mean by best. If you came to my keynote yesterday you would have seen this quote from the Go team lead, Russ Cox: “Software engineering is what happens to programming when you add time and other programmers. — Russ Cox Russ is making the distinction between software programming and software engineering. The former is a program you write for yourself. The latter is a product that many people will work on over time. Engineers will come and go, teams will grow and shrink over time, requirements will change, features will be added and bugs fixed. This is the nature of software engineering. I’m possibly one of the earliest users of Go in this room, but to argue that my seniority gives my views more weight is false. Instead, the advice I’m going to present today is informed by what I believe to be the guiding principles underlying Go itself. They are: \1. Simplicity \2. Readability 3. Productivity NOTE You’ll note that I didn’t say performance, or concurrency. There are languages which are a bit faster than Go, but they’re certainly not as simple as Go. There are languages which make concurrency their highest goal, but they are not as readable, nor as productive. Performance and concurrency are important attributes, but not as important as simplicity, readability, and productivity. 1.1. Simplicity Why should we strive for simplicity? Why is important that Go programs be simple? We’ve all been in a situation where you say “I can’t understand this code”, yes? We’ve all worked on programs where you’re scared to make a change because you’re worried it’ll break another part of the program; a part you don’t understand and don’t know how to fix. This is complexity. Complexity turns reliable software in unreliable software. Complexity is what kills software projects. Simplicity is the highest goal of Go. Whatever programs we write, we should be able to agree that they are simple. 1.2. Readability “https://dave.cheney.net/practical-go/presentations/qcon-china.html 2/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs “Readability is essential for maintainability. — Mark Reinhold JVM language summit 2018 Why is it important that Go code be readable? Why should we strive for readability? “Programs must be written for people to read, and only incidentally for machines to execute. — Hal Abelson and Gerald Sussman Structure and Interpretation of Computer Programs Readability is important because all software, not just Go programs, is written by humans to be read by other humans. The fact that software is also consumed by machines is secondary. Code is read many more times than it is written. A single piece of code will, over its lifetime, be read hundreds, maybe thousands of times. “The most important skill for a programmer is the ability to effectively communicate ideas. — Gastón Jorquera [1] Readability is key to being able to understand what the program is doing. If you can’t understand what a program is doing, how can you hope to maintain it? If software cannot be maintained, then it will be rewritten; and that could be the last time your company will invest in Go. If you’re writing a program for yourself, maybe it only has to run once, or you’re the only person who’ll ever see it, then do what ever works for you. But if this is a piece of software that more than one person will contribute to, or that will be used by people over a long enough time that requirements, features, or the environment it runs in changes, then your goal must be for your program to be maintainable. The first step towards writing maintainable code is making sure the code is readable. “1.3. Productivity Design is the art of arranging code to work today, and be changeable forever. — Sandi Metz The last underlying principle I want to highlight is productivity. Developer productivity is a sprawling topic but it boils down to this; how much time do you spend doing useful work verses waiting for your tools or hopelessly lost in a foreign code-base. Go programmers should feel that they can get a lot done with Go. The joke goes that Go was designed while waiting for a C++ program to compile. Fast compilation is a key feature of Go and a key recruiting tool to attract new developers. While compilation speed remains a constant battleground, it is fair to say that compilations which take minutes in other languages, take seconds in Go. This helps Go developers feel as productive as their counterparts working in dynamic languages without the reliability issues inherent in those languages. More fundamental to the question of developer productivity, Go programmers realise that code is written to be read and so place the act of reading code above the act of writing it. Go goes so far as to enforce, via tooling and custom, that all code be formatted in a specific style. This removes the friction of learning a project specific dialect and helps spot mistakes because they just look incorrect. Go programmers don’t spend days debugging inscrutable compile errors. They don’t waste days with complicated build scripts or deploying code to production. And most importantly they don’t spend their time trying to understand what their coworker wrote. https://dave.cheney.net/practical-go/presentations/qcon-china.html 3/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Productivity is what the Go team talk about when they say the language must scale. 2. Identiers The first topic we’re going to discuss is identifiers. An identifier is a fancy word for a name; the name of a variable, the name of a function, the name of a method, the name of a type, the name of a package, and so on. “Poor naming is symptomatic of poor design. — Dave Cheney Given the limited syntax of Go, the names we choose for things in our programs have an oversized impact on the readability of our programs. Readability is the defining quality of good code thus choosing good names is crucial to the readability of Go code. “2.1. Choose identiers for clarity, not brevity Obvious code is important. What you can do in one line you should do in three. — Ukiah Smith Go is not a language that optimises for clever one liners. Go is not a language which optimises for the least number of lines in a program. We’re not optimising for the size of the source code on disk, nor how long it takes to type. “Good naming is like a good joke. If you have to explain it, it’s not funny. — Dave Cheney Key to this clarity is the names we choose for identifies in Go programs. Let’s talk about the qualities of a good name: A good name is concise. A good name need not be the shortest it can possibly be, but a good name should waste no space on things which are extraneous. Good names have a high signal to noise ratio. A good name is descriptive. A good name should describe the application of a variable or constant, not their contents. A good name should describe the result of a function, or behaviour of a method, not their operation. A good name should describe the purpose of a package, not its contents. The more accurately a name describes the thing it identifies, the better the name. A good name is should be predictable. You should be able to infer the way a name will be used from its name alone. This is a function of choosing descriptive names, but it also about following tradition. This is what Go programmers talk about when they say idiomatic. Let’s talk about each of these properties in depth. 2.2. Identier length Sometimes people criticise the Go style for recommending short variable names. As Rob Pike said, “Go programmers want the right length identifiers”. [1] Andrew Gerrand suggests that by using longer identifies for some things we indicate to the reader that they are of higher importance. “The greater the distance between a name’s declaration and its uses, the longer the name should be. — Andrew Gerrand [2] From this we can draw some guidelines: https://dave.cheney.net/practical-go/presentations/qcon-china.html 4/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Short variable names work well when the distance between their declaration and last use is short. Long variable names need to justify themselves; the longer they are the more value they need to provide. Lengthy bureaucratic names carry a low amount of signal compared to their weight on the page. Don’t include the name of your type in the name of your variable. Constants should describe the value they hold, not how that value is used. Single letter variables for loops and branches, single words for parameters and return values, multiple words for functions and package level declarations Single words for methods, interfaces, and packages. Remember that the name of a package is part of the name the caller uses to to refer to it, so make use of that. Let’s look at an example to 12type Person struct &#123; Name string Age int } 1234// AverageAge returns the average age of people.func AverageAge(people []Person) int &#123; if len(people) == 0 &#123; return 0 } 12var count, sum intfor _, p := range people &#123; sum += p.Age count += 1 } 12 return sum / count&#125; GO In this example, the range variable p is declared on line 10 and only referenced on the following line. p lives for a very short time both on the page, and during the execution of the function. A reader who is interested in the effect values of p have on the program need only read two lines. By comparison people is declared in the function parameters and lives for seven lines. The same is true for sum , and count , thus they justify their longer names. The reader has to scan a wider number of lines to locate them so they are given more distinctive names. I could have chosen s for sum and c (or possibly n ) for but this would have reduced all the variables in the program to the same level of importance. I could have chosen instead of but that would have left the problem of what to call the for … range iteration variable. The singular would look odd as the loop iteration variable which lives for little time has a longer name than the slice of values it was derived from. count TIP Use blank lines to break up the flow of a function in the same way you use paragraphs to break up the flow of a document. In AverageAge we have three operations occurring in sequence. The first is the precondition, checking that we don’t divide by zero if people is empty, the second is the accumulation of the sum and count, and the final is the computation of the average. 2.2.1. Context is key https://dave.cheney.net/practical-go/presentations/qcon-china.html 5/45 p people person 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs It’s important to recognise that most advice on naming is contextual. I like to say it is a principle, not a rule. What is the difference between two identifiers, i , and index . We cannot say conclusively that one is better than another, for example is fundamentally more readable than I argue it is not, because it is likely the scope of i , and index for that matter, is limited to the body of the for loop and the extra verbosity of the latter adds little to comprehension of the program. However, which of these functions is more readable? 1func (s *SNMP) Fetch(oid []int, index int) (int, error) or 1func (s *SNMP) Fetch(o []int, i int) (int, error) In this example, oid is an abbreviation for SNMP Object ID, so shortening it to o would mean programmers have to translate from the common notation that they read in documentation to the shorter notation in your code. Similarly, reducing index to i obscures what i stands for as in SNMP messages a sub value of each OID is called an Index. TIP Don’t mix and match long and short formal parameters in the same declaration. 2.3. Don’t name your variables for their types You shouldn’t name your variables after their types for the same reason you don’t name your pets “dog” and “cat”. You also probably shouldn’t include the name of your type in the name of your variable’s name for the same reason. The name of the variable should describe its contents, not the type of the contents. Consider this example: var usersMap map[string]*User What’s good about this declaration? We can see that its a map, and it has something to do with the *User type, that’s probably good. But usersMap is a map, and Go being a statically typed language won’t let us accidentally use it where a scalar variable is required, so the Map suffix is redundant. Now, consider what happens if we were to declare other variables like: 12for index := 0; index &lt; len(s); index++ &#123; // } 12for i := 0; i &lt; len(s); i++ &#123; // } https://dave.cheney.net/practical-go/presentations/qcon-china.html 6/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs 123var ( companiesMap map[string]*Company productsMap map[string]*Products ) Now we have three map type variables in scope, usersMap , companiesMap , and productsMap , all mapping strings to different types. We know they are maps, and we also know that their map declarations prevent us from using one in place of another—the compiler will throw an error if we try to use companiesMap where the code is expecting a map[string]*User . In this situation it’s clear that the Map suffix does not improve the clarity of the code, its just extra boilerplate to type. My suggestion is to avoid any suffix that resembles the type of the variable. TIP If users isn’t descriptive enough, then usersMap won’t be either. This advice also applies to function parameters. For example: Naming the Config parameter config is redundant. We know its a Config , it says so right there. In this case consider conf or maybe c will do if the lifetime of the variable is short enough. If there is more that one in scope at any one time then calling them conf1 and conf2 is less descriptive than calling them and as the latter are less likely to be mistaken for one another. 1234type Config struct &#123; //&#125;func WriteConfig(w io.Writer, config *Config) *Config original updated Don’t let package names steal good variable names. The name of an imported identifier includes its package name. For example the context package will be known as context.Context . This makes it impossible to use a variable or type in your package. type in the as func WriteLog(context context.Context, message string) Will not compile. This is why the local declaration for context.Context types is traditionally ctx . eg. func WriteLog(ctx context.Context, message string) 2.4. Use a consistent naming style Another property of a good name is it should be predictable. The reader should be able to understand the use of a name when they encounter it for the first time. When they encounter a common name, they should be able to assume it has not changed meanings since the last time they saw it. NOTE https://dave.cheney.net/practical-go/presentations/qcon-china.html 7/45 Context context 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs For example, if your code passes around a database handle, make sure each time the parameter appears, it has the same name. Rather than a combination of d sql.DB , dbase sql.DB , DB sql.DB , and database sql.DB , instead consolidate on something like; db sql.DB Doing so promotes familiarity; if you see a db , you know it’s a sql.DB and that it has either been declared locally or provided for you by the caller. Similarly for method receivers; use the same receiver name every method on that type. This makes it easier for the reader to internalise the use of the receiver across the methods in this type. The convention for short receiver names in Go is at odds with the advice provided so far. This is just NOTE one of the choices made early on that has become the preferred style, just like the use of CamelCase TIP rather than snake_case . Go style dictates that receivers have a single letter name, or acronyms derived from their type. You may find that the name of your receiver sometimes conflicts with name of a parameter in a method. In this case, consider making the parameter name slightly longer, and don’t forget to use this new parameter name consistently. Finally, certain single letter variables have traditionally been associated with loops and counting. For example, i , j , and k are commonly the loop induction variable for simple for loops. n is commonly associated with a counter or accumulator. v is a common shorthand for a value in a generic encoding function, k is commonly used for the key of a map, and s is often used as shorthand for parameters of type string . As with the db example above programmers expect to be a loop induction variable. If you ensure that is always a loop variable, not used in other contexts outside a loop. When readers encounter a variable called , or j , they know that a loop is close by. i i for i TIP If you found yourself with so many nested loops that you exhaust your supply of i , j , and k variables, its probably time to break your function into smaller units. 2.5. Use a consistent declaration style Go has at least six different ways to declare a variable varxint=1 varx=1 varxint;x=1 var x = int(1) x:=1 I’m sure there are more that I haven’t thought of. This is something that Go’s designers recognise was probably a mistake, but its too late to change it now. With all these different ways of declaring a variable, how do we avoid each Go programmer choosing their own style? I want to present a suggestions for how I declare variables in my programs. This is the style I try to use where possible. https://dave.cheney.net/practical-go/presentations/qcon-china.html 8/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs When declaring, but not initialising, a variable, use var . When declaring a variable that will be explicitly initialised later in the function, use the var keyword. The var acts as a clue to say that this variable has been deliberately declared as the zero value of the indicated type. This is also consistent with the requirement to declare variables at the package level using var as opposed to the short declaration syntax—although I’ll argue later that you shouldn’t be using package level variables at all. When declaring and initialising, use := . When declaring and initialising the variable at the same time, that is to say we’re not letting the variable be implicitly initialised to its zero value, I recommend using the short variable declaration form. This makes it clear to the reader that the variable on the left hand side of the := is being deliberately initialised. To explain why, Let’s look at the previous example, but this time deliberately initialising each variable: In the first and third examples, because in Go there are no automatic conversions from one type to another; the type on the left hand side of the assignment operator must be identical to the type on the right hand side. The compiler can infer the type of the variable being declared from the type on the right hand side, to the example can be written more concisely like this: This leaves us with explicitly initialising players to 0 which is redundant because 0 is `players’ zero value. So its better to make it clear that we’re going to use the zero value by instead writing 1var players int What about the second statement? We cannot elide the type and write var things = nil Because nil does not have a type. [2] Instead we have a choice, do we want the zero value for a slice? 123456789101112var players int // 0var things []Thing // an empty slice of Thingsvar thing Thing // empty Thing structjson.Unmarshall(reader, &amp;thing)var players int = 0var things []Thing = nilvar thing *Thing = new(Thing)json.Unmarshall(reader, thing)var players = 0var things []Thing = nilvar thing = new(Thing)json.Unmarshall(reader, thing) https://dave.cheney.net/practical-go/presentations/qcon-china.html 9/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs 1var things []Thing or do we want to create a slice with zero elements? 1var things = make([]Thing, 0) If we wanted the latter then this is not the zero value for a slice so we should make it clear to the reader that we’re making this choice by using the short declaration form: things := make([]Thing, 0) Which tells the reader that we have chosen to initialise things explicitly. This brings us to the third declaration, var thing = new(Thing) Which is both explicitly initialising a variable and introduces the uncommon use of the new keyword which some Go programmer dislike. If we apply our short declaration syntax recommendation then the statement becomes thing := new(Thing) Which makes it clear that thing is explicitly initialised to the result of new(Thing) –a pointer to a Thing –but still leaves us with the unusual use of new . We could address this by using the compact literal struct initialiser form, thing := &amp;Thing{} Which does the same as means we’re explicitly initialising , hence why some Go programmers are upset by the duplication. However this with a pointer to a Thing{} , which is the zero value for a Thing . new(Thing) thing Instead we should recognise that is being declared as its zero value and use the address of operator to pass the address of thing to thing 123json.Unmarshallvar thing Thingjson.Unmarshall(reader, &amp;thing) https://dave.cheney.net/practical-go/presentations/qcon-china.html 10/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs NOTE Of course, with any rule of thumb, there are exceptions. For example, sometimes two variables are closely related so writing Would be odd. The declaration may be more readable like this min, max := 0, 1000 12var min intmax := 1000 In summary: When declaring a variable without initialisation, use the var syntax. When declaring and explicitly initialising a variable, use := . Make tricky declarations obvious. When something is complicated, it should look complicated. var length uint32 = 0x80 Here length may be being used with a library which requires a specific numeric type and is more TIP explicit that length is being explicitly chosen to be uint32 than the short declaration form: length := uint32(0x80) In the first example I’m deliberately breaking my rule of using the var declaration form with an explicit initialiser. This decision to vary from my usual form is a clue to the reader that something unusual is happening. 2.6. Be a team player I talked about a goal of software engineering to produce readable, maintainable, code. Therefore you will likely spend most of your career working on projects of which you are not the sole author. My advice in this situation is to follow the local style. Changing styles in the middle of a file is jarring. Uniformity, even if its not your preferred approach, is more valuable for maintenance than your personal preference. My rule of thumb is; if it fits through gofmt then its usually not worth holding up a code review for. If you want to do a renaming across a code-base, do not mix this into another change. If someone is TIP using git bisect they don’t want to wade through thousands of lines of renaming to find the code you changed as well. \3. Comments Before we move on to larger items I want to spend a few minutes talking about comments. “https://dave.cheney.net/practical-go/presentations/qcon-china.html 11/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs “Good code has lots of comments, bad code requires lots of comments. — Dave Thomas and Andrew Hunt The Pragmatic Programmer Comments are very important to the readability of a Go program. A comments should do one of three things: \1. The comment should explain what the thing does. \2. The comment should explain how the thing does what it does. 3. The comment should explain why the thing is why it is. The first form is ideal for commentary on public symbols: The second form is ideal for commentary inside a method: The third form, the why , is unique as it does not displace the first two, but at the same time it’s not a replacement for the what, or the how. The why style of commentary exists to explain the external factors that drove the code you read on the page. Frequently those factors rarely make sense taken out of context, the comment exists to provide that context. In this example it may not be immediately clear what the effect of setting HealthyPanicThreshold to zero percent will do. The comment is needed to clarify that the value of 0 will disable the panic threshold behaviour. 3.1. Comments on variables and constants should describe their contents not their purpose I talked earlier that the name of a variable, or a constant, should describe its purpose. When you add a comment to a variable or constant, that comment should describe the variables contents, not the variables purpose. 1const randomNumber = 6 // determined from an unbiased die In this example the comment describes why is assigned the value six, and where the six was derived from. The comment does not describe where will be used. Here are some more examples: 12345// Open opens the named file for reading.// If successful, methods on the returned file can be used for reading.// queue all dependant actionsvar results []chan errorfor _, dep := range a.Deps &#123; } 12345results = append(results, execute(seen, dep))return &amp;v2.Cluster_CommonLbConfig&#123; // Disable HealthyPanicThreshold HealthyPanicThreshold: &amp;envoy_type.Percent&#123; Value: 0, }, } https://dave.cheney.net/practical-go/presentations/qcon-china.html 12/45 12randomNumberrandomNumber 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs 12345const ( StatusContinue = 100 // RFC 7231, 6.2.1 StatusSwitchingProtocols = 101 // RFC 7231, 6.2.2 StatusProcessing = 102 // RFC 2518, 10.1 StatusOK = 200 // RFC 7231, 6.3.1 In the context of HTTP the number 100 is known as StatusContinue , as defined in RFC 7231, section 6.2.1. For variables without an initial value, the comment should describe who is responsible for // sizeCalculationDisabled indicates whether it is safe // to calculate Types’ widths and alignments. See dowidth. var sizeCalculationDisabled bool TIP initialising this variable. Here the comment lets the reader know that the dowidth function is responsible for maintaining the state of sizeCalculationDisabled . Hiding in plain sight This is a tip from Kate Gregory. [3] Sometimes you’ll find a better name for a variable hiding in a comment. The comment was added by the author because registry doesn’t explain enough about its purpose —it’s a registry, but a registry of what? By renaming the variable to sqlDrivers its now clear that the purpose of this variable is to hold SQL drivers. var sqlDrivers = make(map[string]*sql.Driver) Now the comment is redundant and can be removed. // registry of SQL drivers var registry = make(map[string]*sql.Driver) TIP 3.2. Always document public symbols Because godoc is the documentation for your package, you should always add a comment for every public symbol— variable, constant, function, and method—declared in your package. Here are two rules from the Google Style guide Any public function that is not both obvious and short must be commented. Any function in a library must be commented regardless of length or complexity https://dave.cheney.net/practical-go/presentations/qcon-china.html 13/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs 123456package ioutil// ReadAll reads from r until an error or EOF and returns the data it read.// A successful call returns err == nil, not err == EOF. Because ReadAll is// defined to read from src until EOF, it does not treat an EOF from Read// as an error to be reported.func ReadAll(r io.Reader) ([]byte, error) There is one exception to this rule; you don’t need to document methods that implement an interface. Specifically don’t do this: This comment says nothing. It doesn’t tell you what the method does, in fact it’s worse, it tells you to go look somewhere else for the documentation. In this situation I suggest removing the comment entirely. Here is an example from the io package 123456789101112131415161718192021222324// Read implements the io.Reader interfacefunc (r *FileReader) Read(buf []byte) (int, error)// LimitReader returns a Reader that reads from r// but stops with EOF after n bytes.// The underlying implementation is a *LimitedReader.func LimitReader(r Reader, n int64) Reader &#123; return &amp;LimitedReader&#123;r, n&#125; &#125;// A LimitedReader reads from R but limits the amount of// data returned to just N bytes. Each call to Read// updates N to reflect the new amount remaining.// Read returns EOF when N &lt;= 0 or when the underlying R returns EOF.type LimitedReader struct &#123; R Reader // underlying reader N int64 // max bytes remaining&#125;func (l *LimitedReader) Read(p []byte) (n int, err error) &#123; if l.N &lt;= 0 &#123; return 0, EOF &#125; if int64(len(p)) &gt; l.N &#123; p = p[0:l.N] &#125; n, err = l.R.Read(p) l.N -= int64(n) return } Note that the declaration is directly preceded by the function that uses it, and the declaration of follows the declaration of LimitedReader itself. Even though LimitedReader.Read has no documentation itself, its clear from that it is an implementation of io.Reader . 12LimitedReaderLimitedReader.Read TIP Before you write the function, write the comment describing the function. If you find it hard to write the comment, then it’s a sign that the code you’re about to write is going to be hard to understand. 3.2.1. Don’t comment bad code, rewrite it “https://dave.cheney.net/practical-go/presentations/qcon-china.html 14/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs “ Don’t comment bad code — rewrite it — Brian Kernighan Comments highlighting the grossness of a particular piece of code are not sufficient. If you encounter one of these comments, you should raise an issue as a reminder to refactor it later. It is okay to live with technical debt, as long as the amount of debt is known. The tradition in the standard library is to annotate a TODO style comment with the username of the person who noticed it. 1// TODO(dfc) this is O(N^2), find a faster way to do this. The username is not a promise that that person has committed to fixing the issue, but they may be the best person to ask when the time comes to address it. Other projects annotate TODOs with a date or an issue number. “3.2.2. Rather than commenting a block of code, refactor it Good code is its own best documentation. As you’re about to add a comment, ask yourself, ‘How can I improve the code so that this comment isn’t needed?’ Improve the code and then document it to make it even clearer. — Steve McConnell Functions should do one thing only. If you find yourself commenting a piece of code because it is unrelated to the rest of the function, consider extracting it into a function of its own. In addition to be easier to comprehend, smaller functions are easier to test in isolation, and now you’ve isolated the orthogonal code into its own function, its name may be all the documentation required. “4. Package Design Write shy code - modules that don’t reveal anything unnecessary to other modules and that don’t rely on other modules’ implementations. — Dave Thomas Each Go package is in effect it’s own small Go program. Just as the implementation of a function or method is unimportant to the caller, the implementation of the functions and methods and types that make your package’s public API—its behaviour—is unimportant for the caller. A good Go package should strive to have a low degree of source level coupling such that, as the project grows, changes to one package do not cascade across the code-base. These stop-the-world refactorings place a hard limit on the rate of change in a code base and thus the productivity of the members working in that code-base. In this section we’ll talk about designing a package including the package’s name, naming types, and tips for writing methods and functions. 4.1. A good package starts with its name Writing a good Go package starts with the package’s name. Think of your package’s name as an elevator pitch to describe what it does using just one word. https://dave.cheney.net/practical-go/presentations/qcon-china.html 15/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Just as I talked about names for variables in the previous section, the name of a package is very important. The rule of thumb I follow is not, “what types should I put in this package?”. Instead the question I ask “what does service does package provide?” Normally the answer to that question is not “this package provides the X type”, but “this package let’s you speak HTTP”. TIP Name your package after what is provides, not what it contains. 4.1.1. Good package names should be unique. Within your project, each package name should be unique. This advice is pretty easy to follow if the advice that a package’s name should derive from its purpose—if you find you have two packages which need the same name, it is likely either; a. The name of the package is too generic. b. The package overlaps another package of a similar name. In this case either you should review your design, or consider merging the packages. 4.2. Avoid package names like base , common , or util A common cause of poor package names is what call utility packages. These are packages where common helpers and utility code congeals over time. As these packages contain an assortment of unrelated functions, their utility is hard to describe in terms of what the package provides. This often leads to the package’s name being derived from what the package contains–utilities. Package names like utils or helpers are commonly found in larger projects which have developed deep package hierarchies and want to share helper functions without encountering import loops. By extracting utility functions to new package the import loop is broken, but because the package stems from a design problem in the project, its name doesn’t reflect its purpose, only its function of breaking the import cycle. My recommendation to improve the name of utils or helpers packages is to analyse where they are called and if possible move the relevant functions into their caller’s package. Even if this involves duplicating some helper code this is better than introducing an import dependency between two packages. “[A little] duplication is far cheaper than the wrong abstraction. — Sandy Metz In the case where utility functions are used in many places prefer multiple packages, each focused on a single aspect, to a single monolithic package. TIP Use plurals for naming utility packages. For example the strings for string handling utilities. Packages with names like base or common are often found when functionality common to two or more implementations, or common types for a client and server, has been refactored into a separate package. I believe the solution to this is to reduce the number of packages, to combine the client, server, and common code into a single package named after the function of the package. For example, the net/http package does not have client and sub packages, instead it has a client.go and server.go file, each holding their respective types, and a file for the common message transport code. server https://dave.cheney.net/practical-go/presentations/qcon-china.html 16/45 1transport.go 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs TIP An identifier’s name includes its package name. It’s important to remember that the name of an identifier includes the name of its package. The Get function from the net/http package becomes http.Get when referenced by another package. The Reader type from the strings package becomes strings.Reader when imported into other packages. The Error interface from the net package is clearly related to network errors. 4.3. Return early rather than nesting deeply As Go does not use exceptions for control flow there is no requirement to deeply indent your code just to provide a top level structure for the try and catch blocks. Rather than the successful path nesting deeper and deeper to the right, Go code is written in a style where the success path continues down the screen as the function progresses. My friend Mat Ryer calls this practice ‘line of sight’ coding. [4] This is achieved by using guard clauses; conditional blocks with assert preconditions upon entering a function. Here is an example from the bytes package, 12func (b *Buffer) UnreadRune() error &#123; if b.lastRead &lt;= opInvalid &#123; GO 1234567 return errors.New(&quot;bytes.Buffer: UnreadRune: previous operation was not a successfulReadRune&quot;) &#125; if b.off &gt;= int(b.lastRead) &#123; b.off -= int(b.lastRead) &#125; b.lastRead = opInvalid return nil } Upon entering UnreadRune the state of b.lastRead is checked and if the previous operation was not an error is returned immediately. From there the rest of the function proceeds with the assertion that is greater that opInvalid . Compare this to the same function written without a guard clause, 1234567func (b *Buffer) UnreadRune() error &#123; if b.lastRead &gt; opInvalid &#123; if b.off &gt;= int(b.lastRead) &#123; b.off -= int(b.lastRead) &#125; b.lastRead = opInvalid return nil } 12 return errors.New(&quot;bytes.Buffer: UnreadRune: previous operation was not a successfulReadRune&quot;) } GO The body of the successful case, the most common, is nested inside the first if condition and the successful exit condition, return nil , has to be discovered by careful matching of closing braces. The final line of the function now returns an error, and the called must trace the execution of the function back to the matching opening brace to know https://dave.cheney.net/practical-go/presentations/qcon-china.html 17/45 ReadRune b.lastRead 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs when control will reach this point. This is more error prone for the reader, and the maintenance programmer, hence why Go prefer to use guard clauses and returning early on errors. 4.4. Make the zero value useful Every variable declaration, assuming no explicit initialiser is provided, will be automatically initialised to a value that matches the contents of zeroed memory. This is the values zero value. The type of the value determines its zero value; for numeric types it is zero, for pointer types nil, the same for slices, maps, and channels. This property of always setting a value to a known default is important for safety and correctness of your program and can make your Go programs simpler and more compact. This is what Go programmers talk about when they say “give your structs a useful zero value”. Consider the sync.Mutex type. sync.Mutex contains two unexported integer fields, representing the mutex’s internal state. Thanks to the zero value those fields will be set to will be set to 0 whenever a sync.Mutex is declared. sync.Mutex has been deliberately coded to take advantage of this property, making the type usable without explicit initialisation. 12type MyInt struct &#123; mu sync.Mutex val int } 123456func main() &#123; var i MyInt // i.mu is usable without explicit initialisation. i.mu.Lock() i.val++ i.mu.Unlock() } GO Another example of a type with a useful zero value is bytes.Buffer . You can declare a bytes.Buffer and start writing to it without explicit initialisation. A useful property of slices is their zero value is nil . This makes sense if we look at the runtime’s definition of a slice header. 1234func main() &#123; var b bytes.Buffer b.WriteString(&quot;Hello, world!\n&quot;) io.Copy(os.Stdout, &amp;b) } GO 1234type slice struct &#123; array *[...]T // pointer to the underlying array len int cap int } https://dave.cheney.net/practical-go/presentations/qcon-china.html 18/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs The zero value of this struct would imply len and cap have the value 0 , and array , the pointer to memory holding the contents of the slice’s backing array, would be nil . This means you don’t need to explicitly make a slice, you can just declare it. 1234567func main() &#123; // s := make([]string, 0) // s := []string&#123;&#125; var s []string s = append(s, &quot;Hello&quot;) s = append(s, &quot;world&quot;) fmt.Println(strings.Join(s, &quot; &quot;)) } GO var s []string is similar to the two commented lines above it, but not identical. It is possible to detect the difference between a slice value that is nil and a slice value that has zero length. The following code will output false. NOTE A surprising, but useful, property of uninitialised pointer variables—nil pointers—is you can call methods on types that have a nil value. This can be used to provide default values simply. func main() { var s1 = []string{} var s2 []string fmt.Println(reflect.DeepEqual(s1, s2)) } GO 12type Config struct &#123; path string } 12345678910func (c *Config) Path() string &#123; if c == nil &#123; return &quot;/usr/home&quot; &#125; return c.path&#125;func main() &#123; var c1 *Config var c2 = &amp;Config&#123; path: &quot;/export&quot;, } 12 fmt.Println(c1.Path(), c2.Path())&#125; GO 4.5. Avoid package level state The key to writing maintainable programs is that they should be loosely coupled—a change to one package should have a low probability of affecting another package that does not directly depend on the first. There are two excellent ways to achieve loose coupling in Go https://dave.cheney.net/practical-go/presentations/qcon-china.html 19/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs \1. Use interfaces to describe the behaviour your functions or methods require. 2. Avoid the use of global state. In Go we can declare variables at the function or method scope, and also at the package scope. When the variable is public, given a identifier starting with a capital letter, then its scope is effectively global to the entire program—any package may observe the type and contents of that variable at any time. Mutable global state introduces tight coupling between independent parts of your program as global variables become an invisible parameter to every function in your program! Any function that relies on a global variable can be broken if that variable’s type changes. Any function that relies on the state of a global variable can be broken if another part of the program changes that variable. If you want to reduce the coupling a global variable creates, \1. Move the relevant variables as fields on structs that need them. \2. Use interfaces to reduce the coupling between the behaviour and the implementation of that behaviour. \5. Project Structure Let’s talk about combining packages together into a project. Commonly this will be a single git repository, but in the future Go developers will use module and project interchangeably. Just like a package, each project should have a clear purpose. If your project is a library, it should provide one thing, say XML parsing, or logging. You should avoid combining multiple purposes into a single package, this will help avoid the dreaded common library. In my experience, the common repo ends up tightly coupled to its biggest consumer and that makes TIP it hard to back-port fixes without upgrading both common and consumer in lock step, bringing in a lot of unrelated changes and API breakage along the way. If your project is an application, like your web application, Kubernetes controller, and so on, then you might have one or more packages inside your project. For example, the Kubernetes controller I work on has a single package which serves as both the server deployed to a Kubernetes cluster, and a client for debugging purposes. 5.1. Consider fewer, larger packages One of the things I tend to pick up in code review for programmers who are transitioning from other languages to Go is they tend to overuse packages. Go does not provide elaborate ways of establishing visibility; thing Java’s public , protected , private , and implicit default access modifiers. There is no equivalent of C++’s notion of friend classes. In Go we have only two access modifiers, public and private, indicated by the capitalisation of the first letter of the identifier. If an identifier is public, it’s name starts with a capital letter, that identifier can be referenced by any other Go package. NOTE You may hear people say exported and not exported as synonyms for public and private. Given the limited controls available to control access to a package’s symbols, what practices should Go programmers follow to avoid creating over-complicated package hierarchies? main cmd/contour https://dave.cheney.net/practical-go/presentations/qcon-china.html 20/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs TIP Every package, with the exception of cmd/ and internal/ , should contain some source code. The advice I find myself repeating is to prefer fewer, larger packages. Your default position should be to not create a new package. That will lead to too many types being made public creating a wide, shallow, API surface for your package.. The sections below explores this suggestion in more detail. TIP Coming from Java? If you’re coming from a Java or C# background, consider this rule of thumb. - A Java package is equivalent to a single .go source file. - A Go package is equivalent to a whole Maven module or .NET assembly. 5.1.1. Arrange code into les by import statements If you’re arranging your packages by what they provide to callers, should you do the same for files within a Go package? How do you know when you should break up a .go file into multiple ones? How do you know when you’ve gone to far and should consider consolidating .go file? Here are the rules of thumb I use: Start each package with one file. Give that file the same name as the name of the folder. eg. package http should be placed in a file called in a directory named http . As your package grows you may decide to split apart the various responsibilities into different files. eg, contains the `Request and Response types, client.go contains the Client type, server.go contains the type. If you find your files have similar import declarations, consider combining them. Alternatively, identify the differences between the import sets and move those Different files should be responsible for different areas of the package. may be responsible for marshalling of HTTP requests and responses on and off the network, may contain the low level network handling logic, client.go and server.go implement the HTTP business logic of request construction or routing, and so on. TIP Prefer nouns for source file names. The Go compiler compiles each package in parallel. Within a package the compiler compiles each NOTE function (methods are just fancy functions in Go) in parallel. Changing the layout of your code within a package does not affect compilation time. 5.1.2. Prefer internal tests to external tests The go tool supports writing your testing package tests in two places. Assuming your package is called http2 , you can write a file and use the declaration. Doing so will compile the code in as if it were part of the package. This is known colloquially as an internal test. The go tool also supports a special package declaration, ending in test , ie., package http_test . This allows your test files to live alongside your code in the same package, however when those tests are compiled they are not part of your package’s code, they live in their own package. This allows you to write your tests as if you were another package calling into your code. This is known as an _external test. .go http.go messages.go Server messages.go http.go 1http2_test.go package http2 1http2_test.go http2 https://dave.cheney.net/practical-go/presentations/qcon-china.html 21/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs I recommend using internal tests when writing unit tests for your package. This allows you to test each function or method directly, avoiding the bureaucracy of external testing. However, you should place your Example test functions in an external test file. This ensures that when viewed in godoc, the examples have the appropriate package prefix and can be easily copy pasted. TIP Avoid elaborate package hierarchies, resist the desire to apply taxonomy With one exception, which we’ll talk about next, the hierarchy of Go packages has no meaning to the go tool. For example, the net/http package is not a child or sub-package of the net package. If you find you have created intermediate directories in your project which contain no .go files, you may have failed to follow this advice. 5.1.3. Use internal packages to reduce your public API surface If your project contains multiple packages you may have some exported functions which are intended to be used by other packages in your project, but are not intended to be part of your project’s public API. If you find yourself in this situation the go tool recognises a special folder name—not package name–, internal/ which can be used to place code which is public to your project, but private to other projects. To create such a package, place it in a directory named internal/ or in a sub-directory of a directory named internal/ . When the go command sees an import of a package with in its path, it verifies that the package doing the import is within the tree rooted at the parent of the directory. For example, a package can be imported only by code in the directory tree rooted at … /a/b/c . It cannot be imported by code in or in any other repository. [5] 5.2. Keep package main small as small as possible Your main function, and package should do as little as possible. This is because main.main acts as a singleton; there can only be one function in a program, including tests. Because main.main is a singleton there are a lot of assumptions built into the things that main.main will call that they will only be called during main.main or main.init, and only called once. This makes it hard to write tests for code written in main.main , thus you should aim to move as much of your business logic out of your main function and ideally out of your main package. TIP main should parse flags, open connections to databases, loggers, and such, then hand off execution to a high level object. \6. API Design The last piece of design advice I’m going to give today I feel is the most important. All of the suggestions I’ve made so far are just that, suggestions. These are the way I try to write my Go, but I’m not going to push them hard in code review. However when it comes to reviewing APIs during code review, I am less forgiving. This is because everything I’ve talked about so far can be fixed without breaking backward compatibility; they are, for the most part, implementation details. When it comes to the public API of a package, it pays to put considerable thought into the initial design, because changing that design later is going to be disruptive for people who are already using your API. https://dave.cheney.net/practical-go/presentations/qcon-china.html 22/45 internal main …/a/b/g internal 1.../a/b/c/internal/d/e/f main 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs “6.1. Design APIs that are hard to misuse. APIs should be easy to use and hard to misuse. — Josh Bloch [3] If you take anything away from this presentation, it should be this advice from Josh Bloch. If an API is hard to use for simple things, then every invocation of the API will look complicated. When the actual invocation of the API is complicated it will be less obvious and more likely to be overlooked. 6.1.1. Be wary of functions which take several parameters of the same type A good example of a simple looking, but hard to use correctly API is one which takes two or more parameters of the same type. Let’s compare two function signatures: What’s the difference between these two functions? Obviously one returns the maximum of two numbers, the other copies a file, but that’s not the important thing. Max is commutative; the order of the parameters does not matter. The maximum of eight and ten is ten regardless of if I compare eight to ten or ten two eight. However, this property does not hold true for CopyFile . Which one of these statements made a backup of your presentation and which one overwrite your presentation with last week’s version? You can’t tell without consulting the documentation. A code reviewer cannot know if you’ve got the order correct without consulting the documentation. One possible solution to this is to introduce a helper type which will be responsible for calling CopyFile correctly. 123456789func Max(a, b int) intfunc CopyFile(to, from string) errorMax(8, 10) // 10Max(10, 8) // 10CopyFile(&quot;/tmp/backup&quot;, &quot;presentation.md&quot;)CopyFile(&quot;presentation.md&quot;, &quot;/tmp/backup&quot;)type Source stringfunc (src Source) CopyTo(dest string) error &#123; return CopyFile(dest, string(src)) } 123func main() &#123; var from Source = &quot;presentation.md&quot; from.CopyTo(&quot;/tmp/backup&quot;) } GO In this way CopyFile is always called correctly—this can be asserted with a unit test—and can possibly be made private, further reducing the likelihood of misuse. https://dave.cheney.net/practical-go/presentations/qcon-china.html 23/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs TIP APIs with multiple parameters of the same type are hard to use correctly. 6.2. Design APIs for their default use case A few years ago I gave a talk [6] about using functional options [7] to make APIs easier to use for their default case. The gist of this talk was you should design your APIs for the common use case. Sad another way, your API should not require the caller to provide parameters which they don’t care about. 6.2.1. Discourage the use of nil as a parameter I opened this chapter with the suggestion that you shouldn’t force the caller of your API into providing you parameters when they don’t really care what those parameters mean. This is what I mean when I say design APIs for their default use case. Here’s an example from the net/http package package http 12345678// ListenAndServe listens on the TCP network address addr and then calls// Serve with handler to handle requests on incoming connections.// Accepted connections are configured to enable TCP keep-alives.//// The handler is typically nil, in which case the DefaultServeMux is used.//// ListenAndServe always returns a non-nil error.func ListenAndServe(addr string, handler Handler) error &#123; ListenAndServe takes two parameters, a TCP address to listen for incoming connections, and http.Handler to handle the incoming HTTP request. Serve allows the second parameter to be nil , and notes that usually the caller will pass nil indicating that they want to use http.DefaultServeMux as the implicit parameter. Now the caller of Serve has two ways to do the same thing. Both do exactly the same thing. This behaviour is viral. The http package also has a http.Serve helper, which you can reasonably imagine that builds upon like this 12http.ListenAndServe(&quot;0.0.0.0:8080&quot;, nil)http.ListenAndServe(&quot;0.0.0.0:8080&quot;, http.DefaultServeMux) nil 1234ListenAndServefunc ListenAndServe(addr string, handler Handler) error &#123; l, err := net.Listen(&quot;tcp&quot;, addr) if err != nil &#123; return err } 123 defer l.Close() return Serve(l, handler)&#125; GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 24/45 http.Serve 1ListenAndServe nil handler DefaultServeMux`” logic. http.Serve Accepting `nil nil Serve 123http.Serve(nil, nil) http.ListenAndServeDefaultServeMux nil 123const root = http.Dir(&quot;/htdocs&quot;)http.Handle(&quot;/&quot;, http.FileServer(root))http.ListenAndServe(&quot;0.0.0.0:8080&quot;, nil) GO 123const root = http.Dir(&quot;/htdocs&quot;)http.Handle(&quot;/&quot;, http.FileServer(root))http.ListenAndServe(&quot;0.0.0.0:8080&quot;, http.DefaultServeMux) GO 1234const root = http.Dir(&quot;/htdocs&quot;)mux := http.NewServeMux()http.Handle(&quot;/&quot;, http.FileServer(root))http.ListenAndServe(&quot;0.0.0.0:8080&quot;, mux) GO 1func ShutdownVMs(ids []string) error 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Because behaviour. In fact, permits the caller to pass for the second parameter, also supports this is the one that implements the “if is nil , use for one parameter may lead the caller into thinking they can pass for both parameters. However calling like this, results in an ugly panic. TIP Don’t mix nil and non nil-able parameters in the same function signature. The author of was trying to make the API user’s life easier in the common case, but possibly made the package harder to use safely. There is no difference in line count between using explicitly, or implicitly via . verses and a was this confusion really worth saving one line? TIP Give serious consideration to how much time helper functions will save the programmer. Clear is better than concise. Avoid public APIs with test only parameters TIP Avoid exposing APIs with values who only differ in test scope. Instead, use Public wrappers to hide those parameters, use test scoped helpers to set the property in test scope. 6.2.2. Prefer var args to []T parameters It’s very common to write a function or method that takes a slice of values. https://dave.cheney.net/practical-go/presentations/qcon-china.html 25/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs This is just an example I made up, but its common to a lot of code I’ve worked on. The problem with signatures like these is they presume that they will be called with more than one entry. However, what I have found is many times these type of functions are called with only one argument, which has to be “boxed” inside a slice just to meet the requirements of the functions signature. Additionally, because the ids parameter is a slice, you can pass an empty slice or nil to the function and the compiler will be happy. This adds extra testing load because you should cover these cases in your testing. To give an example of this class of API, recently I was refactoring a piece of logic that required me to set some extra fields if at least one of a set of parameters was non zero. The logic looked like this: As the if statement was getting very long I wanted to pull the logic of the check out into its own function. This is what I came up with: 12345678if svc.MaxConnections &gt; 0 || svc.MaxPendingRequests &gt; 0 || svc.MaxRequests &gt; 0 ||svc.MaxRetries &gt; 0 &#123; // apply the non zero parameters&#125;// anyPostive indicates if any value is greater than zero.func anyPositive(values ...int) bool &#123; for _, v := range values &#123; if v &gt; 0 &#123; return true } } 12 return false&#125; GO This enabled me to make the condition where the inner block will be executed clear to the reader: However there is a problem with anyPositive , someone could accidentally invoke it like this if anyPositive() { … } In this case anyPositive would return false because it would execute zero iterations and immediately return false . This isn’t the worst thing in the world — that would be if anyPositive returned true when passed no arguments. Nevertheless it would be be better if we could change the signature of anyPositive to enforce that the caller should pass at least one argument. We can do that by combining normal and vararg parameters like this: 12if anyPositive(svc.MaxConnections, svc.MaxPendingRequests, svc.MaxRequests, svc.MaxRetries) &#123; // apply the non zero parameters } https://dave.cheney.net/practical-go/presentations/qcon-china.html 26/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Now anyPositive cannot be called with less than one argument. 6.3. Let functions dene the behaviour they requires Let’s say I’ve been given a task to write a function that persists a Document structure to disk. I could specify this function, Save, which takes an *os.File as the destination to write the Document . But this has a few problems The signature of Save precludes the option to write the data to a network location. Assuming that network storage is likely to become requirement later, the signature of this function would have to change, impacting all its callers. Save is also unpleasant to test, because it operates directly with files on disk. So, to verify its operation, the test would have to read the contents of the file after being written. And I would have to ensure that f was written to a temporary location and always removed afterwards. os.File also defines a lot of methods which are not relevant to , like reading directories and checking to see if a path is a symlink. It would be useful if the signature of the function could describe only the parts of os.File that were relevant. What can we do ? Using io.ReadWriteCloser we can apply the interface segregation principle to redefine Save to take an interface that describes more general file shaped things. With this change, any type that implements the io.ReadWriteCloser interface can be substituted for the previous *os.File . This makes Save both broader in its application, and clarifies to the caller of Save which methods of the *os.File type are relevant to its operation. 12// Save writes the contents of doc to the file f.func Save(f *os.File, doc *Document) error Save Save 1234567891011// Save writes the contents of doc to the supplied// ReadWriterCloser.func Save(rwc io.ReadWriteCloser, doc *Document) error// anyPostive indicates if any value is greater than zero.func anyPositive(first int, rest ...int) bool &#123; if first &gt; 0 &#123; return true &#125; for _, v := range rest &#123; if v &gt; 0 &#123; return true } } 12 return false&#125; GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 27/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs And as the author of I no longer have the option to call those unrelated methods on as it is hidden behind the interface. But we can take the interface segregation principle a bit further. Firstly, it is unlikely that if Save follows the single responsibility principle, it will read the file it just wrote to verify its contents—that should be responsibility of another piece of code. So we can narrow the specification for the interface we pass to Save to just writing and closing. Secondly, by providing Save with a mechanism to close its stream, which we inherited in this desire to make it still look like a file, this raises the question of under what circumstances will wc be closed. Possibly Save will call Close unconditionally, or perhaps Close will be called in the case of success. This presents a problem for the caller of Save as it may want to write additional data to the stream after the document is written. A better solution would be to redefine Save to take only an io.Writer , stripping it completely of the responsibility to do anything but write data to a stream. By applying the interface segregation principle to our Save function, the results has simultaneously been a function which is the most specific in terms of its requirements—it only needs a thing that is writable—and the most general in its function, we can now use Save to save our data to anything which implements io.Writer. \7. Error handling I’ve given several presentations about error handling [8] and written a lot about error handling on my blog. I also spoke a lot about error handling in yesterday’s session so I won’t repeat what I’ve said. https://dave.cheney.net/2014/12/24/inspecting-errors https://dave.cheney.net/2016/04/07/constant-errors Instead I want to cover two other areas related to error handling. 7.1. Eliminate error handling by eliminating errors If you were in my presentation yesterday I talked about the draft proposals for improving error handling. But do you know what is better than an improved syntax for handling errors? Not needing to handle errors at all. Save *os.File 123456// Save writes the contents of doc to the supplied// WriteCloser.func Save(wc io.WriteCloser, doc *Document) error// Save writes the contents of doc to the supplied// Writer.func Save(w io.Writer, doc *Document) error NOTE I’m not saying “remove your error handling”. What I am suggesting is, change your code so you do not have errors to handle. 1io.ReadWriteCloser https://dave.cheney.net/practical-go/presentations/qcon-china.html 28/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs This section draws inspiration from John Ousterhout’s recently book, A philosophy of Software Design [9]. One of the chapters in that book is called “Define Errors Out of Existence”. We’re going to try to apply this advice to Go. 7.1.1. Counting lines Let’s write a function to count the number of lines in a file. 12345func CountLines(r io.Reader) (int, error) &#123; var ( br = bufio.NewReader(r) lines int err error ) 1234for &#123; _, err = br.ReadString(&apos;\n&apos;) lines++ if err != nil &#123; break } } 12if err != io.EOF &#123; return 0, err } 12 return lines, nil&#125; GO Because we’re following our advice from previous sections, CountLines takes an io.Reader, not a *File; its the job of the caller to provide the io.Reader who’s contents we want to count. We construct a bufio.Reader , and then sit in a loop calling the ReadString method, incrementing a counter until we reach the end of the file, then we return the number of lines read. At least that’s the code we want to write, but instead this function is made more complicated by error handling. For example, there is this strange construction, We increment the count of lines before checking the error—that looks odd. The reason we have to write it this way is ReadString will return an error if it encounters and end-of-file before hitting a newline character. This can happen if there is no final newline in the file. To try to fix this, we rearrange the logic to increment the line count, then see if we need to exit the loop. NOTE this logic still isn’t perfect, can you spot the bug? 123_, err = br.ReadString(&apos;\n&apos;)lines++if err != nil &#123; break } GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 29/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs But we’re not done checking errors yet. will return when it hits the end of the file. This is expected, needs some way of saying stop, there is nothing more to read. So before we return the error to the caller of , we need to check if the error was not io.EOF , and in that case propagate it up, otherwise we return nil to say that everything worked fine. I think this is a good example of Russ Cox’s observation that error handling can obscure the operation of the function. Let’s look at an improved version. ReadString io.EOF ReadString CountLine 12345func CountLines(r io.Reader) (int, error) &#123; sc := bufio.NewScanner(r) lines := 0 for sc.Scan() &#123; lines++ } 12 return lines, sc.Err()&#125; GO This improved version switches from using bufio.Reader to bufio.Scanner . Under the hood bufio.Scanner uses , but it adds a nice layer of abstraction which helps remove the error handling with obscured the operation of . 1bufio.Reader CountLines NOTE The method, the body of our bufio.Scanner can scan for any pattern, but by default it looks for newlines. returns true if the scanner has matched a line of text and has not encountered an error. So, loop will be called only when there is a line of text in the scanner’s buffer. This means our revised sc.Scan() for CountLines correctly handles the case where there is no trailing newline, and also handles the case where the file was empty. Secondly, as sc.Scan returns false once an error is encountered, our for loop will exit when the end-of-file is reached or an error is encountered. The type memoises the first error it encountered and we can recover that error once we’ve exited the loop using the method. Lastly, sc.Err() takes care of handling io.EOF and will convert it to a nil if the end of file was reached without encountering another error. 1bufio.Scanner sc.Err() TIP When you find yourself faced with overbearing error handling, try to extract some of the operations into a helper type. 7.1.2. WriteResponse My second example is inspired from the Errors are values blog post [10]. Earlier in this presentation We’ve seen examples dealing with opening, writing and closing files. The error handling is present, but not overwhelming as the operations can be encapsulated in helpers like ioutil.ReadFile and ioutil.WriteFile . However when dealing with low level network protocols it becomes necessary to build the response directly using I/O primitives the error handling can become repetitive. Consider this fragment of a HTTP server which is constructing the HTTP response. https://dave.cheney.net/practical-go/presentations/qcon-china.html 30/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs First we construct the status line using fmt.Fprintf , and check the error. Then for each header we write the header key and value, checking the error each time. Lastly we terminate the header section with an additional \r\n , check the error, and copy the response body to the client. Finally, although we don’t need to check the error from io.Copy , we need to translate it from the two return value form that io.Copy returns into the single return value that WriteResponse returns. That’s a lot of repetitive work. But we can make it easier on ourselves by introducing a small wrapper type, errWriter . errWriter fulfils the io.Writer contract so it can be used to wrap an existing io.Writer . errWriter passes writes through to its underlying writer until an error is detected. From that point on, it discards any writes and returns the previous error. 12type Header struct &#123; Key, Value string } 1234567type Status struct &#123; Code int Reason string&#125;func WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error &#123; _, err := fmt.Fprintf(w, &quot;HTTP/1.1 %d %s\r\n&quot;, st.Code, st.Reason) if err != nil &#123; return err } 123for _, h := range headers &#123; _, err := fmt.Fprintf(w, &quot;%s: %s\r\n&quot;, h.Key, h.Value) if err != nil &#123; return err } } 12if _, err := fmt.Fprint(w, &quot;\r\n&quot;); err != nil &#123; return err } 1_, err = io.Copy(w, body) return err } GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 31/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Applying errWriter to WriteResponse dramatically improves the clarity of the code. Each of the operations no longer needs to bracket itself with an error check. Reporting the error is moved to the end of the function by inspecting the ew.err field, avoiding the annoying translation from `io.Copy’s return values. 7.2. Only handle an error once Lastly, I want to mention that you should only handle errors once. Handling an error means inspecting the error value, and making a single decision. If you make less than one decision, you’re ignoring the error. As we see here, the error from w.WriteAll is being discarded. But making more than one decision in response to a single error is also problematic. The following is code that I come across frequently. 12// WriteAll writes the contents of buf to the supplied writer.func WriteAll(w io.Writer, buf []byte) &#123; } 123w.Write(buf)type errWriter struct &#123; io.Writer err error } 1234567func (e *errWriter) Write(buf []byte) (int, error) &#123; if e.err != nil &#123; return 0, e.err &#125; var n int n, e.err = e.Writer.Write(buf) return n, nil } 12345func WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error &#123; ew := &amp;errWriter&#123;Writer: w&#125; fmt.Fprintf(ew, &quot;HTTP/1.1 %d %s\r\n&quot;, st.Code, st.Reason) for _, h := range headers &#123; fmt.Fprintf(ew, &quot;%s: %s\r\n&quot;, h.Key, h.Value) } 123fmt.Fprint(ew, &quot;\r\n&quot;)io.Copy(ew, body)return ew.err } GO 123456func WriteAll(w io.Writer, buf []byte) error &#123; _, err := w.Write(buf) if err != nil &#123; log.Println(&quot;unable to write:&quot;, err) // annotated error goes to log file return err // unannotated error returned to caller &#125; return nil } GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 32/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs In this example if an error occurs during , a line will be written to a log file, noting the file and line that the error occurred, and the error is also returned to the caller, who possibly will log it, and return it, all the way back up to the top of the program. The caller is probably doing the same 1234func WriteConfig(w io.Writer, conf *Config) error &#123; buf, err := json.Marshal(conf) if err != nil &#123; log.Printf(&quot;could not marshal config: %v&quot;, err) return err } 123if err := WriteAll(w, buf); err != nil &#123; log.Println(&quot;could not write config: %v&quot;, err) return err } return nil } GO So you get a stack of duplicate lines in your log file, but at the top of the program you get the original error without any context. I want to dig into this a little further because I don’t see the problems with logging and returning as just a matter of personal preference. 12345678910111213unable to write: io.EOFcould not write config: io.EOFerr := WriteConfig(f, &amp;conf)fmt.Println(err) // io.EOFfunc WriteConfig(w io.Writer, conf *Config) error &#123; buf, err := json.Marshal(conf) if err != nil &#123; log.Printf(&quot;could not marshal config: %v&quot;, err) // oops, forgot to return &#125; if err := WriteAll(w, buf); err != nil &#123; log.Println(&quot;could not write config: %v&quot;, err) return err } return nil } GO The problem I see a lot is programmers forgetting to return from an error. As we talked about earlier, Go style is to use guard clauses, checking preconditions as the function progresses and returning early. In this example the author checked the error, logged it, but forgot to return. This has caused a subtle bug. w.Write https://dave.cheney.net/practical-go/presentations/qcon-china.html 33/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs The contract for error handling in Go says that you cannot make any assumptions about the contents of other return values in the presence of an error. As the JSON marshalling failed, the contents of buf are unknown, maybe it contains nothing, but worse it could contain a 1/2 written JSON fragment. Because the programmer forgot to return after checking and logging the error, the corrupt buffer will be passed to WriteAll , which will probably succeed and so the config file will be written incorrectly. However the function will return just fine, and the only indication that a problem happened will be a single log line complaining about marshalling JSON, not a failure to write the config. 7.2.1. Adding context to errors The bug occurred because the author was trying to add context to the error message. They were trying to leave themselves a breadcrumb to point them back to the source of the error. Let’s look at another way to do the same thing using fmt.Errorf . 1234567func WriteConfig(w io.Writer, conf *Config) error &#123; buf, err := json.Marshal(conf) if err != nil &#123; return fmt.Errorf(&quot;could not marshal config: %v&quot;, err) &#125; if err := WriteAll(w, buf); err != nil &#123; return fmt.Errorf(&quot;could not write config: %v&quot;, err) } return nil } 12345func WriteAll(w io.Writer, buf []byte) error &#123; _, err := w.Write(buf) if err != nil &#123; return fmt.Errorf(&quot;write failed: %v&quot;, err) &#125; return nil } GO By combining the annotation of the error with returning onto one line there it is harder to forget to return an error and avoid continuing accidentally. If an I/O error occurs writing the file, the error’s `Error() method will report something like this; could not write config: write failed: input/output error 7.2.2. Wrapping errors with github.com/pkg/errors The fmt.Errorf pattern works well for annotating the error message, but it does so at the cost of obscuring the type of the original error. I’ve argued that treating errors as opaque values is important to producing software which is loosely coupled, so the face that the type of the original error should not matter if the only thing you do with an error value is \1. Check that it is not nil . 2. Print or log it. However there are some cases, I believe they are infrequent, where you do need to recover the original error. In that case you can use something like my errors package to annotate errors like this https://dave.cheney.net/practical-go/presentations/qcon-china.html 34/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Now the error reported will be the nice K&amp;D [11] style error, 1could not read config: open failed: open /Users/dfc/.settings.xml: no such file or directory and the error value retains a reference to the original cause. 123456func main() &#123; _, err := ReadConfig() if err != nil &#123; fmt.Printf(&quot;original error: %T %v\n&quot;, errors.Cause(err), errors.Cause(err)) fmt.Printf(&quot;stack trace:\n%+v\n&quot;, err) os.Exit(1) } } GO Thus you can recover the original error and print a stack trace; 12345678910111213141516func ReadFile(path string) ([]byte, error) &#123; f, err := os.Open(path) if err != nil &#123; return nil, errors.Wrap(err, &quot;open failed&quot;) &#125; defer f.Close() buf, err := ioutil.ReadAll(f) if err != nil &#123; return nil, errors.Wrap(err, &quot;read failed&quot;) &#125; return buf, nil&#125;func ReadConfig() ([]byte, error) &#123; home := os.Getenv(&quot;HOME&quot;) config, err := ReadFile(filepath.Join(home, &quot;.settings.xml&quot;)) return config, errors.WithMessage(err, &quot;could not read config&quot;) } 1234func main() &#123; _, err := ReadConfig() if err != nil &#123; fmt.Println(err) os.Exit(1) } } GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 35/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Using the errors package gives you the ability to add context to error values, in a way that is inspectable by both a human and a machine. If you came to my presentation yesterday you’ll know that wrapping is moving into the standard library in an upcoming Go release. \8. Concurrency Often Go is chosen for a project because of its concurrency features. The Go team have gone to great lengths to make concurrency in Go cheap (in terms of hardware resources) and performant, however it is possible to use Go’s concurrency features to write code which is neither performent or reliable. With the time I have left I want to leave you with some advice for avoid some of the pitfalls that come with Go’s concurrency features. Go features first class support for concurrency with channels, and the select and go statements. If you’ve learnt Go formally from a book or training course, you might have noticed that the concurrency section is always one of the last you’ll cover. This workshop is no different, I have chosen to cover concurrency last, as if it is somehow additional to the regular the skills a Go programmer should master. There is a dichotomy here; Go’s headline feature is our simple, lightweight concurrency model. As a product, our language almost sells itself on this on feature alone. On the other hand, there is a narrative that concurrency isn’t actually that easy to use, otherwise authors wouldn’t make it the last chapter in their book and we wouldn’t look back on our formative efforts with regret. This section discusses some pitfalls of naive usage of Go’s concurrency features. 8.1. Keep yourself busy or do the work yourself What is the problem with this program? 123456789101112131415original error: *os.PathError open /Users/dfc/.settings.xml: no such file or directorystack trace:open /Users/dfc/.settings.xml: no such file or directoryopen failedmain.ReadFile /Users/dfc/devel/practical-go/src/errors/readfile2.go:16main.ReadConfig /Users/dfc/devel/practical-go/src/errors/readfile2.go:29main.main /Users/dfc/devel/practical-go/src/errors/readfile2.go:35runtime.main /Users/dfc/go/src/runtime/proc.go:201runtime.goexit /Users/dfc/go/src/runtime/asm_amd64.s:1333could not read config https://dave.cheney.net/practical-go/presentations/qcon-china.html 36/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs The program does what we intended, it serves a simple web server. However it also does something else at the same time, it wastes CPU in an infinite loop. This is because the for{} on the last line of main is going to block the main goroutine because it doesn’t do any IO, wait on a lock, send or receive on a channel, or otherwise communicate with the scheduler. As the Go runtime is mostly cooperatively scheduled, this program is going to spin fruitlessly on a single CPU, and may eventually end up live-locked. How could we fix this? Here’s one suggestion. package main 123import ( &quot;fmt&quot; &quot;log&quot; “net/http” “runtime” ) 12345678func main() &#123; http.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintln(w, &quot;Hello, GopherCon SG&quot;) &#125;) go func() &#123; if err := http.ListenAndServe(&quot;:8080&quot;, nil); err != nil &#123; log.Fatal(err) &#125; }() 12for &#123; runtime.Gosched() } } GO package main GO 123import ( &quot;fmt&quot; &quot;log&quot; “net/http” ) 12345678func main() &#123; http.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintln(w, &quot;Hello, GopherCon SG&quot;) &#125;) go func() &#123; if err := http.ListenAndServe(&quot;:8080&quot;, nil); err != nil &#123; log.Fatal(err) &#125; }() for { } } https://dave.cheney.net/practical-go/presentations/qcon-china.html 37/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs This might look silly, but it’s a common common solution I see in the wild. It’s symptomatic of not understanding the underlying problem. Now, if you’re a little more experienced with go, you might instead write something like this. package main 123import ( &quot;fmt&quot; &quot;log&quot; “net/http” ) 12345678func main() &#123; http.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintln(w, &quot;Hello, GopherCon SG&quot;) &#125;) go func() &#123; if err := http.ListenAndServe(&quot;:8080&quot;, nil); err != nil &#123; log.Fatal(err) &#125; }() select {} } GO An empty select statement will block forever. This is a useful property because now we’re not spinning a whole CPU just to call runtime.GoSched() . However, we’re only treating the symptom, not the cause. I want to present to you another solution, one which has hopefully already occurred to you. Rather than run in a goroutine, leaving us with the problem of what to do with the main goroutine, simply run 12http.ListenAndServehttp.ListenAndServe TIP on the main goroutine itself. If the main.main function of a Go program returns then the Go program will unconditionally exit no matter what other goroutines started by the program over time are doing. package main 123import ( &quot;fmt&quot; &quot;log&quot; “net/http” ) 123456func main() &#123; http.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintln(w, &quot;Hello, GopherCon SG&quot;) &#125;) if err := http.ListenAndServe(&quot;:8080&quot;, nil); err != nil &#123; log.Fatal(err) } } GO So this is my first piece of advice: if your goroutine cannot make progress until it gets the result from another, oftentimes it is simpler to just do the work yourself rather than to delegate it. https://dave.cheney.net/practical-go/presentations/qcon-china.html 38/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs This often eliminates a lot of state tracking and channel manipulation required to plumb a result back from a goroutine to its initiator. TIP Many Go programmers overuse goroutines, especially when they are starting out. As with all things in life, moderation is the key the key to success. 8.2. Leave concurrency to the caller What is the difference between these two APIs? 123456// ListDirectory returns the contents of dir.func ListDirectory(dir string) ([]string, error)// ListDirectory returns a channel over which// directory entries will be published. When the list// of entries is exhausted, the channel will be closed.func ListDirectory(dir string) chan string Firstly, the obvious differences; the first example reads a directory into a slice then returns the whole slice, or an error if something went wrong. This happens synchronously, the caller of ListDirectory blocks until all directory entries have been read. Depending on how large the directory, this could take a long time, and could potentially allocate a lot of memory building up the slide of directory entry names. Lets look at the second example. This is a little more Go like, ListDirectory returns a channel over which directory entries will be passed. When the channel is closed, that is your indication that there are no more directory entries. As the population of the channel happens after ListDirectory returns, ListDirectory is probably starting a goroutine to populate the channel. NOTE Its not necessary for the second version to actually use a Go routine; it could allocate a channel sufficient to hold all the directory entries without blocking, fill the channel, close it, then return the channel to the caller. But this is unlikely, as this would have the same problems with consuming a large amount of memory to buffer all the results in a channel. The channel version of ListDirectory has two further problems: By using a closed channel as the signal that there are no more items to process there is no way for ListDirectory to tell the caller that the set of items returned over the channel is incomplete because an error was encountered partway through. There is no way for the caller to tell the difference between an empty directory and an error to read from the directory entirely. Both result in a channel returned from ListDirectory which appears to be closed immediately. The caller must continue to read from the channel until it is closed because that is the only way the caller can know that the goroutine which was started to fill the channel has stopped. This is a serious limitation on the use of ListDirectory , the caller has to spend time reading from the channel even though it may have received the answer it wanted. It is probably more efficient in terms of memory usage for medium to large directories, but this method is no faster than the original slice based method. The solution to the problems of both implementations is to use a callback, a function that is called in the context of each directory entry as it is executed. https://dave.cheney.net/practical-go/presentations/qcon-china.html 39/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Not surprisingly this is how the filepath.WalkDir function works. If your function starts a goroutine you must provide the caller with a way to explicitly stop that TIP goroutine. It is often easier to leave decision to execute a function asynchronously to the caller of that function. 8.3. Never start a goroutine without when it will stop. The previous example showed using a goroutine when one wasn’t really necessary. But one of the driving reasons for using Go is the first class concurrency features the language offers. Indeed there are many instances where you want to exploit the parallelism available in your hardware. To do so, you must use goroutines. This simple application serves http traffic on two different ports, port 8080 for application traffic and port 8001 for access to the /debug/pprof endpoint. package main 12import ( &quot;fmt&quot; “net/http” 12345678910 _ &quot;net/http/pprof&quot;)func main() &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/&quot;, func(resp http.ResponseWriter, req *http.Request) &#123; fmt.Fprintln(resp, &quot;Hello, QCon!&quot;) &#125;) go http.ListenAndServe(&quot;127.0.0.1:8001&quot;, http.DefaultServeMux) // debug http.ListenAndServe(&quot;0.0.0.0:8080&quot;, mux) // app traffic&#125; GO Although this program isn’t very complicated, it represents the basis of a real application. There are a few problems with the application as it stands which will reveal themselves as the application grows, so lets address a few of them now. 1func ListDirectory(dir string, fn func(string)) https://dave.cheney.net/practical-go/presentations/qcon-china.html 40/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs By breaking the serveApp and serveDebug handlers out into their own functions we’ve decoupled them from main.main . We’ve also followed the advice from above and make sure that serveApp and serveDebug leave their concurrency to the caller. But there are some operability problems with this program. If serveApp returns then main.main will return causing the program to shutdown and be restarted by whatever process manager you’re using. TIP Just as functions in Go leave concurrency to the caller, applications should leave the job of monitoring their status and restarting them if they fail to the program that invoked them. Do not make your applications responsible for restarting themselves, this is a procedure best handled from outside the application. However, serveDebug is run in a separate goroutine and if it returns just that goroutine will exit while the rest of the program continues on. Your operations staff will not be happy to find that they cannot get the statistics out of your application when they want too because the /debug handler stopped working a long time ago. What we want to ensure is that if any of the goroutines responsible for serving this application stop, we shut down the application. 123456789func serveApp() &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/&quot;, func(resp http.ResponseWriter, req *http.Request) &#123; fmt.Fprintln(resp, &quot;Hello, QCon!&quot;) &#125;) http.ListenAndServe(&quot;0.0.0.0:8080&quot;, mux)&#125;func serveDebug() &#123; http.ListenAndServe(&quot;127.0.0.1:8001&quot;, http.DefaultServeMux) } 12func main() &#123; go serveDebug() serveApp() } GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 41/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Now serverApp and serveDebug check the error returned from ListenAndServe and call if required. Because both handlers are running in goroutines, we park the main goroutine in a . This approach has a number of problems: \1. If ListenAndServer returns with a nil error, log.Fatal won’t be called and the HTTP service on that port will shut down without stopping the application. \2. log.Fatal calls os.Exit which will unconditionally exit the program; defers won’t be called, other goroutines won’t be notified to shut down, the program will just stop. This makes it difficult to write tests for those functions. TIP Only use log.Fatal from main.main or init functions. What we’d really like is to pass any error that occurs back to the originator of the goroutine so that it can know why the goroutine stopped, can shut down the process cleanly. log.Fatal select{} 1234567func serveApp() &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/&quot;, func(resp http.ResponseWriter, req *http.Request) &#123; fmt.Fprintln(resp, &quot;Hello, QCon!&quot;) &#125;) if err := http.ListenAndServe(&quot;0.0.0.0:8080&quot;, mux); err != nil &#123; log.Fatal(err) } } 1234func serveDebug() &#123; if err := http.ListenAndServe(&quot;127.0.0.1:8001&quot;, http.DefaultServeMux); err != nil &#123; log.Fatal(err) &#125; } 123func main() &#123; go serveDebug() go serveApp() select {} } GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 42/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs We can use a channel to collect the return status of the goroutine. The size of the channel is equal to the number of goroutines we want to manage so that sending to the done channel will not block, as this will block the shutdown the of goroutine, causing it to leak. As there is no way to safely close the done channel we cannot use the for range idiom to loop of the channel until all goroutines have reported in, instead we loop for as many goroutines we started, which is equal to the capacity of the channel. Now we have a way to wait for each goroutine to exit cleanly and log any error they encounter. All that is needed is a way to forward the shutdown signal from the first goroutine that exits to the others. It turns out that asking a http.Server to shut down is a little involved, so I’ve spun that logic out into a helper function. The serve helper takes an address and http.Handler , similar to http.ListenAndServe , and also a stop channel which we use to trigger the Shutdown method. 123456789func serveApp() error &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/&quot;, func(resp http.ResponseWriter, req *http.Request) &#123; fmt.Fprintln(resp, &quot;Hello, QCon!&quot;) &#125;) return http.ListenAndServe(&quot;0.0.0.0:8080&quot;, mux)&#125;func serveDebug() error &#123; return http.ListenAndServe(&quot;127.0.0.1:8001&quot;, http.DefaultServeMux) } 1234567func main() &#123; done := make(chan error, 2) go func() &#123; done &lt;- serveDebug() &#125;() go func() &#123; done &lt;- serveApp() }() 1234for i := 0; i &lt; cap(done); i++ &#123; if err := &lt;-done; err != nil &#123; fmt.Println(&quot;error: %v&quot;, err) &#125; } } GO https://dave.cheney.net/practical-go/presentations/qcon-china.html 43/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs Now, each time we receive a value on the channel, we close the stop channel which causes all the goroutines waiting on that channel to shut down their . This in turn will cause all the remaining ListenAndServe goroutines to return. Once all the goroutines we started have stopped, main.main returns and the process stops cleanly. done http.Server TIP Writing this logic yourself is repetitive and subtle. Consider something like this package, https://github.com/heptio/workgroup which will do most of the work for you. 12func serve(addr string, handler http.Handler, stop &lt;-chan struct&#123;&#125;) error &#123; s := http.Server&#123; Addr: addr, 12345 Handler: handler,&#125;go func() &#123; &lt;-stop // wait for stop signal s.Shutdown(context.Background()) }() 1234567891011 return s.ListenAndServe()&#125;func serveApp(stop &lt;-chan struct&#123;&#125;) error &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/&quot;, func(resp http.ResponseWriter, req *http.Request) &#123; fmt.Fprintln(resp, &quot;Hello, QCon!&quot;) &#125;) return serve(&quot;0.0.0.0:8080&quot;, mux, stop)&#125;func serveDebug(stop &lt;-chan struct&#123;&#125;) error &#123; return serve(&quot;127.0.0.1:8001&quot;, http.DefaultServeMux, stop) } 12345678func main() &#123; done := make(chan error, 2) stop := make(chan struct&#123;&#125;) go func() &#123; done &lt;- serveDebug(stop) &#125;() go func() &#123; done &lt;- serveApp(stop) }() 123456789var stopped boolfor i := 0; i &lt; cap(done); i++ &#123; if err := &lt;-done; err != nil &#123; fmt.Println(&quot;error: %v&quot;, err) &#125; if !stopped &#123; stopped = true close(stop) &#125; } } GO 下面是David给出的一下关于go的学习参考资料的链接： https://dave.cheney.net/practical-go/presentations/qcon-china.html 44/45 2018/10/21 Practical Go: Real world advice for writing maintainable Go programs https://gaston.life/books/effective-programming/ https://talks.golang.org/2014/names.slide#4 https://www.infoq.com/articles/API-Design-Joshua-Bloch https://www.lysator.liu.se/c/pikestyle.html https://speakerdeck.com/campoy/understanding-nil https://www.youtube.com/watch?v=Ic2y6w8lMPA https://medium.com/@matryer/line-of-sight-in-code-186dd7cdea88 https://golang.org/doc/go1.4#internalpackages https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully https://www.amazon.com/Philosophy-Software-Design-John-Ousterhout/dp/1732102201 https://blog.golang.org/errors-are-values http://www.gopl.io/]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>GO QCon 技术分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之改善 Python 程序的 91 个建议（转载)]]></title>
    <url>%2F2018%2F10%2F21%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E6%94%B9%E5%96%84-Python-%E7%A8%8B%E5%BA%8F%E7%9A%84-91-%E4%B8%AA%E5%BB%BA%E8%AE%AE%EF%BC%88%E8%BD%AC%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[本篇博客转载自zhuanlan.zhihu.com/p/32817459。 除了Google的Python代码规范外，从来没有类似的书籍。偶然的机会看到这么一本书，读完之后觉得还不错，所以做个简单的笔记。有想学习类似知识的朋友，又懒得去读完整本书籍，可以参考一下。 1：引论建议1、理解Pythonic概念—-详见Python中的《Python之禅》 建议2、编写Pythonic代码 （1）避免不规范代码，比如只用大小写区分变量、使用容易混淆的变量名、害怕过长变量名等。有时候长的变量名会使代码更加具有可读性。 （2）深入学习Python相关知识，比如语言特性、库特性等，比如Python演变过程等。深入学习一两个业内公认的Pythonic的代码库，比如Flask等。 建议3：理解Python与C的不同之处，比如缩进与{}，单引号双引号，三元操作符？，Switch-Case语句等。 建议4：在代码中适当添加注释 建议5：适当添加空行使代码布局更加合理 建议6：编写函数的4个原则 （1）函数设计要尽量短小，嵌套层次不宜过深 （2）函数声明应该做到合理、简单、易用 （3）函数参数设计应该考虑向下兼容 （4）一个函数只做一件事，尽量保证函数粒度的一致性 建议7：将常量集中在一个文件，且常量名尽量使用全大写字母 2：编程惯用法建议8：利用assert语句来发现问题，但要注意，断言assert会影响效率 建议9：数据交换值时不推荐使用临时变量，而是直接a, b = b, a 建议10：充分利用惰性计算（Lazy evaluation）的特性，从而避免不必要的计算 建议11：理解枚举替代实现的缺陷（最新版Python中已经加入了枚举特性） 建议12：不推荐使用type来进行类型检查，因为有些时候type的结果并不一定可靠。如果有需求，建议使用isinstance函数来代替 建议13：尽量将变量转化为浮点类型后再做除法（Python3以后不用考虑） 建议14：警惕eval()函数的安全漏洞，有点类似于SQL注入 建议15：使用enumerate()同时获取序列迭代的索引和值 建议16：分清==和is的适用场景，特别是在比较字符串等不可变类型变量时（详见评论） 建议17：尽量使用Unicode。在Python2中编码是很让人头痛的一件事，但Python3就不用过多考虑了 建议18：构建合理的包层次来管理Module 3：基础用法建议19：有节制的使用from…import语句，防止污染命名空间 建议20：优先使用absolute import来导入模块（Python3中已经移除了relative import） 建议21：i+=1不等于++i，在Python中，++i前边的加号仅表示正，不表示操作 建议22：习惯使用with自动关闭资源，特别是在文件读写中 建议23：使用else子句简化循环（异常处理） 建议24：遵循异常处理的几点基本原则 （1）注意异常的粒度，try块中尽量少写代码 （2）谨慎使用单独的except语句，或except Exception语句，而是定位到具体异常 （3）注意异常捕获的顺序，在合适的层次处理异常 （4）使用更加友好的异常信息，遵守异常参数的规范 建议25：避免finally中可能发生的陷阱 建议26：深入理解None，正确判断对象是否为空。Python中下列数据会判断为空： 建议27：连接字符串应优先使用join函数，而不是+操作 建议28：格式化字符串时尽量使用.format函数，而不是%形式 建议29：区别对待可变对象和不可变对象，特别是作为函数参数时 建议30：[], {}和()：一致的容器初始化形式。使用列表解析可以使代码更清晰，同时效率更高 建议31：函数传参数，既不是传值也不是传引用，而是传对象或者说对象的引用 建议32：警惕默认参数潜在的问题，特别是当默认参数为可变对象时 建议33：函数中慎用变长参数*args和**kargs （1）这种使用太灵活，从而使得函数签名不够清晰，可读性较差 （2）如果因为函数参数过多而是用变长参数简化函数定义，那么一般该函数可以重构 建议34：深入理解str()和repr()的区别 （1）两者之间的目标不同：str主要面向客户，其目的是可读性，返回形式为用户友好性和可读性都比较高的字符串形式；而repr是面向Python解释器或者说Python开发人员，其目的是准确性，其返回值表示Python解释器内部的定义 （2）在解释器中直接输入变量，默认调用repr函数，而print(var)默认调用str函数 （3）repr函数的返回值一般可以用eval函数来还原对象 （4）两者分别调用对象的内建函数str__()和__repr() 建议35：分清静态方法staticmethod和类方法classmethod的使用场景 4：库建议36：掌握字符串的基本用法 建议37：按需选择sort()和sorted()函数 》sort()是列表在就地进行排序，所以不能排序元组等不可变类型。 》sorted()可以排序任意的可迭代类型，同时不改变原变量本身。 建议38：使用copy模块深拷贝对象，区分浅拷贝（shallow copy）和深拷贝（deep copy） 建议39：使用Counter进行计数统计，Counter是字典类的子类，在collections模块中 建议40：深入掌握ConfigParser 建议41：使用argparse模块处理命令行参数 建议42：使用pandas处理大型CSV文件 》Python本身提供一个CSV文件处理模块，并提供reader、writer等函数。 》Pandas可提供分块、合并处理等，适用于数据量大的情况，且对二维数据操作更方便。 建议43：使用ElementTree解析XML 建议44：理解模块pickle的优劣 》优势：接口简单、各平台通用、支持的数据类型广泛、扩展性强 》劣势：不保证数据操作的原子性、存在安全问题、不同语言之间不兼容 建议45：序列化的另一个选择JSON模块：load和dump操作 建议46：使用traceback获取栈信息 建议47：使用logging记录日志信息 建议48：使用threading模块编写多线程程序 建议49：使用Queue模块使多线程编程更安全 5：设计模式建议50：利用模块实现单例模式 建议51：用mixin模式让程序更加灵活 建议52：用发布-订阅模式实现松耦合 建议53：用状态模式美化代码 6：内部机制建议54：理解build-in对象 建议55：init__()不是构造方法，理解__new()与它之间的区别 建议56：理解变量的查找机制，即作用域 》局部作用域 》全局作用域 》嵌套作用域 》内置作用域 建议57：为什么需要self参数 建议58：理解MRO（方法解析顺序）与多继承 建议59：理解描述符机制 建议60：区别getattr__()与__getattribute()方法之间的区别 建议61：使用更安全的property 建议62：掌握元类metaclass 建议63：熟悉Python对象协议 建议64：利用操作符重载实现中缀语法 建议65：熟悉Python的迭代器协议 建议66：熟悉Python的生成器 建议67：基于生成器的协程和greenlet，理解协程、多线程、多进程之间的区别 建议68：理解GIL的局限性 建议69：对象的管理和垃圾回收 7：使用工具辅助项目开发建议70：从PyPI安装第三方包 建议71：使用pip和yolk安装、管理包 建议72：做paster创建包 建议73：理解单元测试的概念 建议74：为包编写单元测试 建议75：利用测试驱动开发（TDD）提高代码的可测性 建议76：使用Pylint检查代码风格 》代码风格审查 》代码错误检查 》发现重复以及不合理的代码，方便重构 》高度的可配置化和可定制化 》支持各种IDE和编辑器的集成 》能够基于Python代码生成UML图 》能够与Jenkins等持续集成工具相结合，支持自动代码审查 建议77：进行高效的代码审查 建议78：将包发布到PyPI 8：性能剖析与优化建议79：了解代码优化的基本原则 建议80：借助性能优化工具 建议81：利用cProfile定位性能瓶颈 建议82：使用memory_profiler和objgraph剖析内存使用 建议83：努力降低算法复杂度 建议84：掌握循环优化的基本技巧 》减少循环内部的计算 》将显式循环改为隐式循环，当然这会牺牲代码的可读性 》在循环中尽量引用局部变量 》关注内层嵌套循环 建议85：使用生成器提高效率 建议86：使用不同的数据结构优化性能 建议87：充分利用set的优势 建议88：使用multiprocessing模块克服GIL缺陷 建议89：使用线程池提高效率 建议90：使用C/C++模块扩展提高性能 建议91：使用Cythonb编写扩展模块]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>编程规范</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之基于beego web框架的RESTful API的构建之旅]]></title>
    <url>%2F2018%2F10%2F14%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E5%9F%BA%E4%BA%8Ebeego-web%E6%A1%86%E6%9E%B6%E7%9A%84RESTful-API%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B9%8B%E6%97%85%2F</url>
    <content type="text"><![CDATA[前言​ beego是一个快速开发GO应用的http框架，作者是go语言方向的大牛，astaxie。beego可以用来快速开发API、web、后端服务等应用，是一个RESTFul风格的框架，主要的设计灵感来自于Python web开发框架tornado、flask、sinstra，很好的结合了Go语言本身的一些特性（interface，struct继承等）。 ​ beego是基于八大独立模块来实现的，很好的实现了模块间的解耦，即使用户不使用http的逻辑，也可以很好的使用其中的各个模块。作者自己说，他的这种思想来自于乐高积木，设计beego的时候，这些模块就是积木，而最终搭建好的机器人就是beego。 ​ 这篇博文通过使用beego来构建API，讲解实现过程中的细节以及遇到的一些坑，让我们马上开始beego的API构建之旅吧！ 项目创建 进入到你的$GOPATH/src 安装beego开发包自己快速开发工具bee 123go get github.com/astaxie/beegogo get github.com/astaxie/beego/ormgo get github.com/beego/bee 使用快速开发工具bee，创建我们的API项目 1bee new firstAPI 我们得到的项目结构如下图所示： 可以看出这是一个典型的MVC架构的应用，beego把我们项目所需要的一些都准备好了，例如配置文件conf，测试文件tests等，我们只需要专注于API代码的编写即可。 运行项目并获得API自动化文档1bee run -gendoc=true -downdoc=true 运行上述代码输出如下图所示： 我们在浏览器中访问：本机IP：8080/swagger，就会看到swagger的API文档，我们代码更新后，该文档就会自动更新，非常方便。 models设计 对 数据库object 操作有四个方法 Read / Insert / Update / Delete 1234567891011示例代码：o := orm.NewOrm()user := new(User)user.Name = "slene"fmt.Println(o.Insert(user))user.Name = "Your"fmt.Println(o.Update(user))fmt.Println(o.Read(user))fmt.Println(o.Delete(user)) 还有其他的方法可以参阅beego官方文档，里面对orm操作有着详细的介绍。 创建一个数据库并设计一张数据库表 1234567CREATE TABLE IF NOT EXISTS `student` (`Id` int(11),`Name` varchar(255),`Birthdate` varchar(255),`Gender` bool,`Score` int(11)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 在models文件夹下新建一个文件Student.go,并实现以下代码，代码中关键点都有注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package modelsimport ( "fmt" "github.com/astaxie/beego/orm")//在models模块中创建一个struct，目的是使用beego的orm框架，使struct与数据库中的字段产生对应关系type Student struct &#123; Id int`orm:"column(Id)"` //column()括号中的字段就是在定义数据库时的相应字段，这一段必须严格填写，不然在API读写数据时就会出现读不到或者写不进去的问题 Name string `orm:"column(Name)"` BirthDate string `orm:"column(Birthdate)"` Gender bool `orm:"column(Gender)"` Score int `orm:"column(Score)"`&#125;//该函数获得数据库中所有student的信息，返回值是一个结构体数组指针func GetAllStudents() []*Student &#123; o := orm.NewOrm() //产生一个orm对象 o.Using("default") //这句话的意思是使用定义的默认数据库，与main.go中的orm.RegisterDataBase()对应 var students []*Student //定义指向结构体数组的指针 q := o.QueryTable("student")//获得一个数据库表的请求 q.All(&amp;students)//取到这个表中的所有数据 return students&#125;//该函数根据student中的Id，返回该学生的信息func GetStudentById(id int) Student &#123; u := Student&#123;Id:id&#125;//根据所传入的Id得到对应student的对象 o := orm.NewOrm()//new 一个orm对象 o.Using("default")//使用最开始定义的default数据库 err := o.Read(&amp;u)//读取Id=id的student的信息 if err == orm.ErrNoRows &#123; fmt.Println("查询不到")//对应操作，不一定是print &#125; else if err == orm.ErrMissPK &#123; fmt.Println("没有主键") &#125; return u&#125;//添加一个学生的信息到数据库中，参数是指向student结构题的指针func AddStudent(student *Student) Student &#123; o := orm.NewOrm() o.Using("default") o.Insert(student)//插入数据库 return *student&#125;func UpdateStudent(student *Student) &#123; o := orm.NewOrm() o.Using("default") o.Update(student)//更新该student的信息&#125;func DeleteStudent(id int) &#123; o := orm.NewOrm() o.Using("default") o.Delete(&amp;Student&#123;Id:id&#125;)//删除对应id的student的信息&#125;func init() &#123; orm.RegisterModel(new(Student))//将数据库注册到orm&#125; model这一层主要是定义struct，并为上层编写读写数据库。处理数据的代码。 controller层实现基于 beego 的 Controller 设计，只需要匿名组合 beego.Controller 就可以了，如下所示： 123type xxxController struct &#123; beego.Controller&#125; beego.Controller 实现了接口 beego.ControllerInterface，beego.ControllerInterface 定义了如下函数： Init(ct *context.Context, childName string, app interface{}) 这个函数主要初始化了 Context、相应的 Controller 名称，模板名，初始化模板参数的容器 Data，app 即为当前执行的 Controller 的 reflecttype，这个 app 可以用来执行子类的方法。 Prepare() 这个函数主要是为了用户扩展用的，这个函数会在下面定义的这些 Method 方法之前执行，用户可以重写这个函数实现类似用户验证之类。 Get() 如果用户请求的 HTTP Method 是 GET，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Get 请求。 Post() 如果用户请求的 HTTP Method 是 POST，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Post 请求。 Delete() 如果用户请求的 HTTP Method 是 DELETE，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Delete 请求。 Put() 如果用户请求的 HTTP Method 是 PUT，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Put 请求. Head() 如果用户请求的 HTTP Method 是 HEAD，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Head 请求。 Patch() 如果用户请求的 HTTP Method 是 PATCH，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Patch 请求. Options() 如果用户请求的HTTP Method是OPTIONS，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Options 请求。 Finish() 这个函数是在执行完相应的 HTTP Method 方法之后执行的，默认是空，用户可以在子 struct 中重写这个函数，执行例如数据库关闭，清理数据之类的工作。 Render() error 这个函数主要用来实现渲染模板，如果 beego.AutoRender 为 true 的情况下才会执行。 所以通过子 struct 的方法重写，用户就可以实现自己的逻辑。 routers层实现什么是路由设置呢？前面介绍的 MVC 结构执行时，介绍过 beego 存在三种方式的路由:固定路由、正则路由、自动路由，与RESTFul API相关的就是固定路由和正则路由。 下面就是固定路由的例子 1234beego.Router("/", &amp;controllers.MainController&#123;&#125;)beego.Router("/admin", &amp;admin.UserController&#123;&#125;)beego.Router("/admin/index", &amp;admin.ArticleController&#123;&#125;)beego.Router("/admin/addpkg", &amp;admin.AddController&#123;&#125;) 下面是正则路由的例子： beego.Router(“/api/?:id”, &amp;controllers.RController{}) 默认匹配 //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123” beego.Router(“/api/:id”, &amp;controllers.RController{}) 默认匹配 //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123”，但URL”/api/“匹配失败 beego.Router(“/api/:id([0-9]+)“, &amp;controllers.RController{}) 自定义正则匹配 //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123” beego.Router(“/user/:username([\w]+)“, &amp;controllers.RController{}) 正则字符串匹配 //例如对于URL”/user/astaxie”可以匹配成功，此时变量”:username”值为”astaxie” beego.Router(“/download/.”, &amp;controllers.RController{}) *匹配方式 //例如对于URL”/download/file/api.xml”可以匹配成功，此时变量”:path”值为”file/api”， “:ext”值为”xml” beego.Router(“/download/ceshi/*“, &amp;controllers.RController{}) *全匹配方式 //例如对于URL”/download/ceshi/file/api.json”可以匹配成功，此时变量”:splat”值为”file/api.json” beego.Router(“/:id:int”, &amp;controllers.RController{}) int 类型设置方式，匹配 :id为int 类型，框架帮你实现了正则 ([0-9]+) beego.Router(“/:hi:string”, &amp;controllers.RController{}) string 类型设置方式，匹配 :hi 为 string 类型。框架帮你实现了正则 ([\w]+) beego.Router(“/cms_:id([0-9]+).html”, &amp;controllers.CmsController{}) 带有前缀的自定义正则 //匹配 :id 为正则类型。匹配 cms_123.html 这样的 url :id = 123 个人觉得，最方便的还是类似于Python框架flask的注解路由，也是在这个项目中使用的： 在routers/routers.go里面添加你所希望的API 12345678910111213141516171819202122232425262728package routersimport ( "firstAPI/controllers" "github.com/astaxie/beego")func init() &#123; ns := beego.NewNamespace("/v1", beego.NSNamespace("/object", beego.NSInclude( &amp;controllers.ObjectController&#123;&#125;, ), ), beego.NSNamespace("/user", beego.NSInclude( &amp;controllers.UserController&#123;&#125;, ), ), beego.NSNamespace("/student", beego.NSInclude( &amp;controllers.StudentController&#123;&#125;, ), ), ) beego.AddNamespace(ns)&#125; 以上代码实现了如下的API： /v1/object /v1/user /v1/student 非常清晰明了。 main.go的数据库配置1234567891011121314151617181920212223package mainimport ( _ "firstAPI/routers" "github.com/astaxie/beego" "github.com/astaxie/beego/orm" _ "github.com/go-sql-driver/mysql")func init() &#123; orm.RegisterDriver("mysql", orm.DRMySQL)//注册MySQL的driver orm.RegisterDataBase("default", "mysql", "root:test@tcp(127.0.0.1:3306)/restapi_test?charset=utf8")//本地数据库的账号。密码等 orm.RunSyncdb("default", false, true)&#125;func main() &#123; if beego.BConfig.RunMode == "dev" &#123; beego.BConfig.WebConfig.DirectoryIndex = true beego.BConfig.WebConfig.StaticDir["/swagger"] = "swagger"//静态文档 &#125; beego.Run()&#125; 关键点都在代码中以注释的形式展现。 postman测试bee run 运行代码后，我们使用postman测试一下我们所构建的API效果如何。 这里节省篇幅，只测试一个接口。 到此为止，我们基于beego就实现了简单API接口的构建，是不是既清晰又简单呢？赶快自己动手试试吧！ 本期技术周刊结束，代码已上传到GitHub，可以查阅，我们下期再会！]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>golang beego</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结版图解http]]></title>
    <url>%2F2018%2F10%2F12%2F%E6%80%BB%E7%BB%93%E7%89%88%E5%9B%BE%E8%A7%A3http%2F</url>
    <content type="text"><![CDATA[该博客转载自公众号freeCodeCamp 作为一个前端，如果对一个网页从发起请求到返回数据这期间具体发生了什么都不知道的话，那不是一个好前端。最近，读了图解http，以及有关http相关的文章，还有自己也下载了wireshark抓包工具，实际观察了一下这个过程，下面就此做些总结。 一.从输入一个url到返回数据，中间到底发生了什么？ 假设，我们在浏览器输入http://www.baidu.com:80/index.html，假设解析出的ip地址是202.43.78.3 1.浏览器解析出主机名 解析出的主机名是www.baidu.com 2.浏览器查询这个主机名的ip地址（dns） dns解析的作用就是把域名解析成ip地址，这样才能在广域网路由器转发报文给目标ip，不然路由器不知道要把报文发给谁。下面就讲下大概的过程，不会涉及太多细节。（以chrome为例子） （1）浏览器启动时，首先浏览器会去操作系统获取dns服务器地址，然后把这个地址缓存下来。同时浏览器还会去读取和解析hosts文件，同样放到缓存中。浏览器对解析过的域名和ip地址，都会保存着这两者的映射关系。（存到cache中） （2）当解析域名的时候，首先浏览器会去cache中查找有没有缓存好的映射关系，如果没有的话，就去hosts文件中查找，如果也没有的话，浏览器就会发起请求去dns服务器缓存查询了，如果缓存里面也没有，那最后就是dns服务器去查询了。 3.浏览器获取端口号 4.浏览器向目标ip地址发起一条到202.43.78.3:80的tcp连接 为了传输的可靠性，tcp协议要有三次握手过程： （1）首先浏览器会向服务器发起一个连接请求 （2）服务器会对连接请求做出响应，表示同意建立连接 （3）浏览器收到响应后，再告知对方，它知道服务器同意它建立连接了。 5.数据包在ip层传输 数据包在ip层传输，通过多台计算机和网络设备中转，在中转时，利用中转设备的mac地址搜索下一个中转目标（采用ARP协议，根据通信方的ip地址就可以反查出对应的mac地址），直到目标ip地址。 6.数据链路层处理网络连接的硬件部分 数据链路层处理网络连接的硬件部分，比如网卡，找到服务器的网卡 7.浏览器向服务器发送一条http报文 每一条http报文的组成： 起始行+首部+主体(可选) 起始行：http/1.0 200 ok (一般包括http版本，返回状态码，返回码原因) 首部：content-type:text/plain content-length:19 主体：name=jane 8.服务器接受客户端请求，进行一些处理，返回响应报文 web服务器接收到请求之后，实际上会做些什么呢？ （1）建立连接，如果接受一个客户端连接，就建立连接，如果不同意，就将其关闭。 （2）接收请求，读取http请求报文 （3）访问资源，访问报文中指定的资源 （4）构建响应，创建带有首部的http响应报文 （5）发送响应，将响应回送给客户端 9.浏览器读取http响应报文 10.浏览器关闭连接 看了上面的一个简单过程，大家会不会有这样一个问题，难道每次发起一个http请求，都要建立一次tcp连接吗，我们经常写的并发ajax请求，每条请求都是各自独立建立的tcp连接？一条tcp连接建立之后，是什么时候关闭的？带着这些问题，看看下面要讲的http的特性 二.http的特性 1.http是不保存状态的协议 http协议是一种无状态的协议，意思就是说它不会对每次的请求和响应之间的通信状态进行保存。你之前发过的任何请求的信息，没有任何记录。之所以这样设计，也是为了让http变得比较简单，可以处理大量事物。但是无状态的特性，也会导致一些问题，比如说一个用户登录一家网站之后，跳到另一个页面，应该还保持着登录状态，所以后面就出了cookie状态管理技术。相信大家应该都很熟悉了。 2.请求只能从客户端开始，客户端不可以接收除响应以外的指令 服务器必须等待客户端的请求，才能给客户端发送响应数据，所以说服务器是不能主动给客户端推送数据的。对于一些实时监控的功能，常常用websocket来代替 3.没有用户认证，任何人都可以发起请求 在http协议通信时，是不存在确认通信方的处理步骤的，任何人都可以发起请求。另外，服务器只要收到请求，无论是谁，都会返回一个响应。所以会存在伪装的隐患。后面出现的https就可以解决这个问题。 4.通信使用的是明文 5.无法证明报文完整性 6.可任意选择数据压缩格式，非强制压缩发送 7.http持久连接和并行连接 一开始，http请求是串行的，一个http请求，就会建立一条tcp连接，浏览器收到响应之后，就会断开连接。等上一个请求回来了，下一个请求才能继续请求。这样做的缺点是，比较耗时间和内存，后面就出现了下面一系列的优化连接性能的方法。 （1）并行连接 原理：通过多条tcp连接发起并发的http请求 并行连接可以同时发起多个http请求，每次发起一个http请求，就会建立一个tcp连接。每个http请求是独立的，不会相互等待，这样做，很可能会提高页面的加载速度，因为人们会看到页面上面，很多个东西会同时出现，所以感觉页面加载变快了。实际上有时候是真的变快了，因为它是并行工作的。但是有时候不是真的快了。比如说，客户端的网络带宽不足时，（浏览器是通过一个28kbps的modem连接到因特网上去的），如果并行加载多个请求，每个请求就会去竞争这个有限的带宽，每个请求就会以比较慢的速度加载。这样带来的性能提升就很小。 （2）持久连接 原理：重用tcp连接，以消除连接及关闭时延 从http1.1开始，就允许当http响应结束后，tcp连接可以保持在打开状态，以便给未来的http请求重用现在的连接。那么，这个tcp连接什么时候会关闭呢，一般情况下，40s内，如果没有新的请求，就会关闭。 （3）管道化连接 原理：通过共享的tcp连接发起并发的http请求 并行连接可以提高复合页面的传输速度，但是也有许多缺点，比如每次都会建立一次tcp连接，会耗费时间和带宽。持久连接的优势就是降低了时延和tcp的连接数量。但是持久连接可能会导致的一个问题是，可能会累积大量的空闲连接。耗费资源。 持久连接和并行连接配合使用才是最高效的方式。 一般浏览器会限制，同个域名下的并行连接的个数是4个，即打开少量的并行连接，其中每个都是持久连接。这也是现在用的最多的方式。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python apscheduler - skipped: maximum number of running instances reached]]></title>
    <url>%2F2018%2F09%2F28%2Fpython-apscheduler-skipped-maximum-number-of-running-instances-reached%2F</url>
    <content type="text"><![CDATA[出现问题的代码123scheduler = BackgroundScheduler()scheduler.add_job(runsync, 'interval', seconds=1)scheduler.start() 问题出现的情况 运行一段代码，时而报错时而不报错 报错是： 1WARNING:apscheduler.scheduler:Execution of job &quot;runsync (trigger: interval[0:00:01], next run at: 2015-12-01 11:50:42 UTC)&quot; skipped: maximum number of running instances reached (1) 分析 apscheduler这个模块，在你的代码运行时间大于interval的时候，就会报错 也就是说，你的代码运行时间超出了你的定时任务的时间间隔。 解决 增大时间间隔即可 ###]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 的logging模块实现json格式的日志输出]]></title>
    <url>%2F2018%2F09%2F27%2Fpython-%E7%9A%84logging%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0json%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[前言： 想要让开发过程或者是上线后的bug无处可藏，最好的方式便是在程序运行过程中，不断收集重要的日志，以供分析使用。Python中内置的log收集模块是logging，该模块使用起来比较方便，但是美中不足的地方就是日志的格式转成json比较麻烦。于是我结合logging和另一个模块python-json-logger(pip install python-json-logger) ，实现json格式的日志输出。 源码：以下代码可以做成模块，直接导入使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import logging, logging.config, osimport structlogfrom structlog import configure, processors, stdlib, threadlocalfrom pythonjsonlogger import jsonloggerBASE_DIR = BASE_DIR = os.path.dirname(os.path.abspath(__file__))DEBUG = True # 标记是否在开发环境# 给过滤器使用的判断class RequireDebugTrue(logging.Filter): # 实现filter方法 def filter(self, record): return DEBUGdef get_logger(): LOGGING = &#123; # 基本设置 'version': 1, # 日志级别 'disable_existing_loggers': False, # 是否禁用现有的记录器 # 日志格式集合 'formatters': &#123; # 标准输出格式 'json': &#123; # [具体时间][线程名:线程ID][日志名字:日志级别名称(日志级别ID)] [输出的模块:输出的函数]:日志内容 'format': '[%(asctime)s][%(threadName)s:%(thread)d][%(name)s:%(levelname)s(%(lineno)d)]\n[%(module)s:%(funcName)s]:%(message)s', 'class': 'pythonjsonlogger.jsonlogger.JsonFormatter', &#125; &#125;, # 过滤器 'filters': &#123; 'require_debug_true': &#123; '()': RequireDebugTrue, &#125; &#125;, # 处理器集合 'handlers': &#123; # 输出到控制台 # 输出到文件 'TimeChecklog': &#123; 'level': 'DEBUG', 'class': 'logging.handlers.RotatingFileHandler', 'formatter': 'json', 'filename': os.path.join("./log/", 'TimeoutCheck.log'), # 输出位置 'maxBytes': 1024 * 1024 * 5, # 文件大小 5M 'backupCount': 5, # 备份份数 'encoding': 'utf8', # 文件编码 &#125;, &#125;, # 日志管理器集合 'loggers': &#123; # 管理器 'proxyCheck': &#123; 'handlers': ['TimeChecklog'], 'level': 'DEBUG', 'propagate': True, # 是否传递给父记录器 &#125;, &#125; &#125; configure( logger_factory=stdlib.LoggerFactory(), processors=[ stdlib.render_to_log_kwargs] ) logging.config.dictConfig(LOGGING) logger = logging.getLogger("proxyCheck") return logger# 测试用例，你可以把get_logger()封装成一个模块，from xxx import get_logger()logger1 = get_logger()def test(): try: a = 1 / 0 except Exception as e: logger1.error(e) # 写入错误日志 #如果需要添加额外的信息，使用extra关键字即可 logger1.error(e, extra=&#123;key1: value1, key2:value2&#125;) # 其他错误处理代码 passtest() ### 测试结果 测试的结果，可以在./log/xxx.log文件中看到输出的日志 1&#123;&quot;asctime&quot;: &quot;2018-09-28 09:52:12,622&quot;, &quot;threadName&quot;: &quot;MainThread&quot;, &quot;thread&quot;: 4338656704, &quot;name&quot;: &quot;proxyCheck&quot;, &quot;levelname&quot;: &quot;ERROR&quot;, &quot;%(lineno&quot;: null, &quot;module&quot;: &quot;mylog&quot;, &quot;funcName&quot;: &quot;test&quot;, &quot;message&quot;: &quot;division by zero&quot;&#125; 可以看到日志是json格式，这样你就可以很方便的使用grafna和ES将日志做成看板来展示了。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 发送各种格式的邮件]]></title>
    <url>%2F2018%2F09%2F17%2Fpython-%E5%8F%91%E9%80%81%E5%90%84%E7%A7%8D%E6%A0%BC%E5%BC%8F%E7%9A%84%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.mime.application import MIMEApplication_user = "sigeken@qq.com"_pwd = "***"_to = "402363522@qq.com" #如名字所示Multipart就是分多个部分msg = MIMEMultipart()msg["Subject"] = "don't panic"msg["From"] = _usermsg["To"] = _to #---这是文字部分---part = MIMEText("乔装打扮，不择手段")msg.attach(part) #---这是附件部分---#xlsx类型附件part = MIMEApplication(open('foo.xlsx','rb').read())part.add_header('Content-Disposition', 'attachment', filename="foo.xlsx")msg.attach(part) #jpg类型附件part = MIMEApplication(open('foo.jpg','rb').read())part.add_header('Content-Disposition', 'attachment', filename="foo.jpg")msg.attach(part) #pdf类型附件part = MIMEApplication(open('foo.pdf','rb').read())part.add_header('Content-Disposition', 'attachment', filename="foo.pdf")msg.attach(part) #mp3类型附件part = MIMEApplication(open('foo.mp3','rb').read())part.add_header('Content-Disposition', 'attachment', filename="foo.mp3")msg.attach(part) s = smtplib.SMTP("smtp.qq.com", timeout=30)#连接smtp邮件服务器,端口默认是25s.login(_user, _pwd)#登陆服务器s.sendmail(_user, _to, msg.as_string())#发送邮件s.close()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之当你ping的时候，发生了什么？]]></title>
    <url>%2F2018%2F09%2F16%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E5%BD%93%E4%BD%A0ping%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[我们在遇到网络不通的情况，大家都知道去 ping 一下，看一下网络状况。那你知道「ping」命令后背的逻辑是什么吗？知道它是如何实现的吗？本周就让我们深入浅出ping的机制。 ping的作用和原理简单来说，「ping」是用来探测本机与网络中另一主机之间是否可达的命令，如果两台主机之间ping不通，则表明这两台主机不能建立起连接。ping是定位网络通不通的一个重要手段。 ping 命令是基于 ICMP 协议来工作的，「 ICMP 」全称为 Internet 控制报文协议（ Internet Control Message Protocol）。ping 命令会发送一份ICMP回显请求报文给目标主机，并等待目标主机返回ICMP回显应答。因为ICMP协议会要求目标主机在收到消息之后，必须返回ICMP应答消息给源主机，如果源主机在一定时间内收到了目标主机的应答，则表明两台主机之间网络是可达的。 举一个例子来描述「ping」命令的工作过程： 假设有两个主机，主机A（192.168.0.1）和主机B（192.168.0.2），现在我们要监测主机A和主机B之间网络是否可达，那么我们在主机A上输入命令：ping 192.168.0.2 此时，ping命令会在主机A上构建一个 ICMP的请求数据包（数据包里的内容后面再详述），然后 ICMP协议会将这个数据包以及目标IP（192.168.0.2）等信息一同交给IP层协议。 IP层协议得到这些信息后，将源地址（即本机IP）、目标地址（即目标IP：192.168.0.2）、再加上一些其它的控制信息，构建成一个IP数据包。 IP数据包构建完成后，还不够，还需要加上MAC地址，因此，还需要通过ARP映射表找出目标IP所对应的MAC地址。当拿到了目标主机的MAC地址和本机MAC后，一并交给数据链路层，组装成一个数据帧，依据以太网的介质访问规则，将它们传送出出去。 当主机B收到这个数据帧之后，会首先检查它的目标MAC地址是不是本机，如果是就接收下来处理，接收之后会检查这个数据帧，将数据帧中的IP数据包取出来，交给本机的IP层协议，然后IP层协议检查完之后，再将ICMP数据包取出来交给ICMP协议处理，当这一步也处理完成之后，就会构建一个ICMP应答数据包，回发给主机A 在一定的时间内，如果主机A收到了应答包，则说明它与主机B之间网络可达，如果没有收到，则说明网络不可达。除了监测是否可达以外，还可以利用应答时间和发起时间之间的差值，计算出数据包的延迟耗时。 通过ping的流程可以发现，ICMP协议是这个过程的基础，是非常重要的，因此下面就把ICMP协议再详细解释一下。 ICMP简介我们知道，ping命令是基于ICMP协议来实现的。那么我们再来看下图，就明白了ICMP协议又是通过IP协议来发送的，即ICMP报文是封装在IP包中。 IP协议是一种无连接的，不可靠的数据包协议，它并不能保证数据一定被送达，那么我们要保证数据送到就需要通过其它模块来协助实现，这里就引入的是ICMP协议。 当传送的IP数据包发送异常的时候，ICMP就会将异常信息封装在包内，然后回传给源主机。 将上图再细拆一下可见： 将ICMP部分拆开继续分析： 由图可知，ICMP数据包由8bit的类型字段和8bit的代码字段以及16bit的校验字段再加上选项数据组成。 ICMP协议大致可分为两类： 查询报文类型 差错报文类型 查询报文类型： 查询报文主要应用于：ping查询、子网掩码查询、时间戳查询等等。 上面讲到的ping命令的流程其实就对应ICMP协议查询报文类型的一种使用。在主机A构建ICMP请求数据包的时候，其ICMP的类型字段中使用的是 8 （回送请求），当主机B构建ICMP应答包的时候，其ICMP类型字段就使用的是 0 （回送应答），更多类型值参考上表。 对 查询报文类型 的理解可参考一下文章最开始讲的ping流程，这里就不做赘述。 差错报文类型： 差错报文主要产生于当数据传送发送错误的时候。 它包括：目标不可达（网络不可达、主机不可达、协议不可达、端口不可达、禁止分片等）、超时、参数问题、重定向（网络重定向、主机重定向等）等等。 差错报文通常包含了引起错误的IP数据包的第一个分片的IP首部，加上该分片数据部分的前8个字节。 当传送IP数据包发生错误的时候（例如 主机不可达），ICMP协议就会把错误信息封包，然后传送回源主机，那么源主机就知道该怎么处理了。 那是不是只有遇到错误的时候才能使用 差错报文类型 呢？也不一定。 Traceroute 就是一个例外，Traceroute是用来侦测源主机到目标主机之间所经过路由情况的常用工具。Traceroute 的原理就是利用ICMP的规则，制造一些错误的事件出来，然后根据错误的事件来评估网络路由情况。 具体做法就是： Traceroute会设置特殊的TTL值，来追踪源主机和目标主机之间的路由数。首先它给目标主机发送一个 TTL=1 的UDP数据包，那么这个数据包一旦在路上遇到一个路由器，TTL就变成了0（TTL规则是每经过一个路由器都会减1），因为TTL=0了，所以路由器就会把这个数据包丢掉，然后产生一个错误类型（超时）的ICMP数据包回发给源主机，也就是差错包。这个时候源主机就拿到了第一个路由节点的IP和相关信息了。 接着，源主机再给目标主机发一个 TTL=2 的UDP数据包，依旧上述流程走一遍，就知道第二个路由节点的IP和耗时情况等信息了。 如此反复进行，Traceroute就可以拿到从主机A到主机B之间所有路由器的信息了。 但是有个问题是，如果数据包到达了目标主机的话，即使目标主机接收到TTL值为1的IP数据包，它也是不会丢弃该数据包的，也不会产生一份超时的ICMP回发数据包的，因为数据包已经达到了目的地嘛。那我们应该怎么认定数据包是否达到了目标主机呢？ Traceroute的方法是在源主机发送UDP数据包给目标主机的时候，会设置一个不可能达到的目标端口号（例如大于30000的端口号），那么当这个数据包真的到达目标主机的时候，目标主机发现没有对应的端口号，因此会产生一份“端口不可达”的错误ICMP报文返回给源主机。 traceroot的具体使用方法网上都有很多讲解，可以实际操作一下。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7-安装docker-compose时由于pip10包管理导致的错误]]></title>
    <url>%2F2018%2F09%2F13%2FCentOS7-%E5%AE%89%E8%A3%85docker-compose%E6%97%B6%E7%94%B1%E4%BA%8Epip10%E5%8C%85%E7%AE%A1%E7%90%86%E5%AF%BC%E8%87%B4%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[今天在CentOS下安装docker-compose，遇到了Cannot uninstall ‘requests’. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.错误的原因是requests默认版本为2.6.0，但是docker-compose要2.9以上才支持，但是无法正常卸载2.9版本，是pip10对包的管理存在变化。 解决方案： pip install -l requests==2.9]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之解析Python中的赋值、浅拷贝、深拷贝]]></title>
    <url>%2F2018%2F09%2F09%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E8%A7%A3%E6%9E%90Python%E4%B8%AD%E7%9A%84%E8%B5%8B%E5%80%BC%E3%80%81%E6%B5%85%E6%8B%B7%E8%B4%9D%E3%80%81%E6%B7%B1%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[事情的起因 本周我们分享的主题是Python中关于浅拷贝和深拷贝的特性，想要深入研究Python中的浅拷贝和深拷贝的起因在于，我想生成一个json字符串，该字符串未dumps之前是一个Python的数据结构，里面包含字典，以及List，在遍历生成dictionary时候，出现一个bug，就是每次遍历生成的dictionary都是上一次的值，现象可以看以下代码。 123456789101112131415161718# 这里我们定义一个函数get_data()def get_data(): ...: appid_dict = &#123;&#125; ...: appid_all_dict = &#123;&#125; ...: import pdb;pdb.set_trace() ...: for i in range(10): ...: appid_dict['a'] = i ...: appid_all_dict[i] = appid_dict# 我们的初衷是想要得到# &#123;0: &#123;'a': 0&#125;, 1: &#123;'a': 1&#125;, 2: &#123;'a': 2&#125;, 3: &#123;'a': 3&#125;&#125;....这样的一个dict# 但是在调试过程中，发现得到的结果是这样的：# (Pdb) appid_all_dict# &#123;0: &#123;'a': 2&#125;, 1: &#123;'a': 2&#125;, 2: &#123;'a': 2&#125;&#125;# (Pdb) # 即，后面的appid_dict都会把前面的覆盖掉，这是什么原因呢？# 我们这里先把原因说一下：因为Python中对dict的操作默认是浅拷贝，即同样的字典，使用多次的话，每次使用都是指向同一片内存地址(引用)，所以在上面的程序中后面对appid_dict的赋值，都将前面的给覆盖掉了，导致每一个appid_dict指向同一片内存，读取的当然就是最后一次的appid_dict的值，即上面程序的执行结果：&#123;0: &#123;'a': 9&#125;, 1: &#123;'a': 9&#125;, 2: &#123;'a': 9&#125;, 3: &#123;'a': 9&#125;, 4: &#123;'a': 9&#125;, 5: &#123;'a': 9&#125;, 6: &#123;'a': 9&#125;, 7: &#123;'a': 9&#125;, 8: &#123;'a': 9&#125;, 9: &#123;'a': 9&#125;&#125; 那么如何修改这个bug，让程序输出我们想要得到的结果： 1&#123;0: &#123;'a': 0&#125;, 1: &#123;'a': 1&#125;, 2: &#123;'a': 2&#125;, 3: &#123;'a': 3&#125;, 4: &#123;'a': 4&#125;, 5: &#123;'a': 5&#125;, 6: &#123;'a': 6&#125;, 7: &#123;'a': 7&#125;, 8: &#123;'a': 8&#125;, 9: &#123;'a': 9&#125;&#125; 看完下面对于Python赋值、浅拷贝、深拷贝的解析，相信你就可以自己解决这个问题了 Python中的赋值操作 赋值：就是对象的引用 举例： a = b: 赋值引用，a和b都指向同一个对象，如图所示 Python中浅拷贝 a = b.copy(): a 是b的浅拷贝，a和b是一个独立的对象，但是它们的子对象还是指向同一片引用。 Python中对字典的默认赋值操作就是浅拷贝，所以导致了文章开头所出现的情况。 Python中的深拷贝 首先import copy,导入copy模块（Python中自带），b = copy.deepcopy(a), 我们就说b是a的深拷贝，b拷贝了a所有的资源对象，并新开辟了一块地址空间，两者互不干涉。 实际的例子来进一步说明12345678910111213141516171819202122In [13]: import copyIn [14]: def temp(): ...: a = [1, 2, 3, 4, ['a', 'b']] ...: b = a # 赋值操作，直接传所有对象的引用 ...: c = copy.copy(a) # 浅拷贝，子对象指向同一引用 ...: d = copy.deepcopy(a) # 深拷贝，互不干涉 ...: a.append(5) # 修改对象a ...: a[4].append('c') # 修改a中的数组 ...: print( 'a = ', a ) ...: print( 'b = ', b ) ...: print( 'c = ', c ) ...: print( 'd = ', d ) ...: In [15]: In [15]: temp()a = [1, 2, 3, 4, ['a', 'b', 'c'], 5]b = [1, 2, 3, 4, ['a', 'b', 'c'], 5]c = [1, 2, 3, 4, ['a', 'b', 'c']]d = [1, 2, 3, 4, ['a', 'b']] 解决最初的问题 看到这里，我们再回头看文章最初的那个问题，就可以很easy地解决了。 12345678def get_data(): ...: appid_dict = &#123;&#125; ...: appid_all_dict = &#123;&#125; ...: import pdb;pdb.set_trace() ...: for i in range(10): appid_dict = copy.deepcopy(appid_dict)# 只需要加上这一行，使其成为深拷贝，问题解决！ ...: appid_dict['a'] = i ...: appid_all_dict[i] = appid_dict 总结要对Python的dictionary进行迭代分析，一定要注意其中的深拷贝问题，出现问题后，也要多往这方面考虑。 本期技术周刊到此结束。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>技术周刊</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang 编译针对不同平台的可执行程序]]></title>
    <url>%2F2018%2F09%2F07%2Fgolang-%E7%BC%96%E8%AF%91%E9%92%88%E5%AF%B9%E4%B8%8D%E5%90%8C%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738Golang 支持在一个平台下生成另一个平台可执行程序的交叉编译功能。Mac下编译Linux, Windows平台的64位可执行程序：CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build test.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.goLinux下编译Mac, Windows平台的64位可执行程序：CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build test.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.goWindows下编译Mac, Linux平台的64位可执行程序：SET CGO_ENABLED=0SET GOOS=darwin3SET GOARCH=amd64go build test.goSET CGO_ENABLED=0SET GOOS=linuxSET GOARCH=amd64go build test.go GOOS：目标可执行程序运行操作系统，支持 darwin，freebsd，linux，windowsGOARCH：目标可执行程序操作系统构架，包括 386，amd64，armGolang version 1.5以前版本在首次交叉编译时还需要配置交叉编译环境：CGO_ENABLED=0 GOOS=linux GOARCH=amd64 ./make.bashCGO_ENABLED=0 GOOS=windows GOARCH=amd64 ./make.bash]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的Python小模块]]></title>
    <url>%2F2018%2F09%2F06%2F%E5%B8%B8%E7%94%A8%E7%9A%84Python%E5%B0%8F%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[工作或者生活中总会遇到一些常用的Python模块，为了避免重复的工作，将这些自己写过的Python模块记录下来，方便使用的时候查找。 Python写CSV文件，并防止中文乱码12345678def write_csv(a_list,b_list): with open('vm_data.csv', 'w') as f: f.write(codecs.BOM_UTF8.decode()) writer1 = csv.writer(f, dialect='excel') #写CVS的标题 writer1.writerow(['a', 'b']) #将数据写入CSV文件 writer1.writerows(zip(a_list, b_list)) Python将数据结构转为json,并优化json字符串的结构，处理中文乱码12345with open("appid.json", 'w', encoding='utf8', ) as f: f.write(json.dumps(final, sort_keys=True, indent=2, ensure_ascii=False))# sort_keys = True: 将字典的key按照字母排序# ident = 2: 优化json字符串结构，看起来更美观# ensure_ascii=False: 防止json字符串中的中文乱码 使用requests包进行网络请求（以post为例）1234567891011def get_data(url): final = &#123;&#125; url = &quot;http://xxxx.com&quot; request_body = &#123; &apos;access_token&apos;: access_token, &apos;request_body&apos;: &#123;&quot;params1&quot;: param1, &apos;params2&apos;: param2&#125; &#125; headers = &#123; &apos;Content-type&apos;: &apos;application/json&apos; &#125; data = requests.post(url, headers=headers, data=json.dumps(request_body))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql无法连接[MySql Host is blocked because of many connection errors]]]></title>
    <url>%2F2018%2F09%2F01%2FMysql%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[测试环境，发现数据库（MySQL数据库）无法登录，报错如下： Host is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’ 解决方案：使用mysqladmin flush-hosts 命令清理一下hosts文件（不知道mysqladmin在哪个目录下可以使用命令查找：whereis mysqladmin）； 登录到MySQL数据库中，mysql -uroot -h host -p 执行 1mysqladmin flush-hosts 问题解决。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 开启远程连接]]></title>
    <url>%2F2018%2F08%2F29%2Fmysql-%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[背景： 建站的时候会出现数据库和网站是不同的ip，就需要开启MySQL的远程连接服务，但是MySQL由于安全原因，默认设置是不允许远程只能本地连接，要开启远程连接就需要修改某些配置文件。 按照下面的步骤，开启MySQL的远程连接 进入数据库cmd 12mysql -uroot -h host -pEnter password:*** 连接到默认mysql数据库 123show databases;use mysql; 配置 1Grant all privileges on *.* to 'root'@'host' identified by 'password' with grant option; host表示你远程连接数据库设备的ip地址（如果你想让所有机器都能远程连接，host改为‘%’，不推荐这样使用），password表示MySQL的root用户密码 刷新or重启MySQL 1mysql&gt; flush privileges; 最后非常重要的一点 123vim /etc/vim /etc/mysql/my.cnf屏蔽bing-server 127.0.0.0#bing-server 127.0.0.0 完成，可以远程连接你的数据库了]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang factory design 引发的一系列思考]]></title>
    <url>%2F2018%2F08%2F29%2Fgolang-factory-design-%E5%BC%95%E5%8F%91%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[写在前面，突然萌生一个念头，做一个技术周刊系列，将每周工作或者生活当中遇到的比较有趣的问题记录下来，一来时总结一下，二来是为了以后退役了，可以回顾自己的技术生涯。 没有什么意外的话，我会每周六晚更新。 最近在整合三家公有云（AWS，ali, ucloud）的接口，考虑到代码复用的问题，于是开始考虑使用一种设计模式，这种场景下，最合适的便是工厂模式，将三家厂商的公有接口放入工厂方法中，然后对每一家new一个实例即可，以后再有新的厂商加入，改动的代码也不会太多。但是设计模式这种东西天然适合于java，对于golang这种比较新的语言来说，实现起来相对没有那么容易，对于刚接触golang的我来说，对一些golang的特性上并不是很熟悉，所以在此期间遇到一些不解的问题，写出来分享一下。 首先，什么是工厂模式 简单工厂模式就是通过传递不同的参数，生成不同的实例，工厂方法为每一个product提供一个工程类，通过不同的工厂创建不同的实例。 典型工厂模式的实现方式（即典型oop实现方式） 12345678910111213141516171819202122class ProviderModel&#123; provider string func factory(providerName string, test string)&#123; if providerName == "AWS" &#123; return new AWS(test) &#125; if providerName == "Ali"&#123; return new Ali(test) &#125; &#125;&#125;class AWS extends ProviderModel &#123; func construct(test string)&#123; this.test = test &#125; func doRequest()&#123;&#125;&#125;awsmodel := ProviderModel::factory("AWS")awsmodel.doRequest()alimodel := ProviderModel ::factory("Ali") alimodel.doRequest() golang实现工厂模式存在的问题 golang的特性中并没有像java一样的继承和重载，所以我们要利用golang存在的特性，透过工厂模式的表面透析其本质。 我们看一下工厂模式就知道，所谓工厂其实就是定义了一些需要去实现的方法，golang的interface正是可以做到。于是先到Google上搜了一段golang实现的工厂模式的代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( "fmt")type Operater interface &#123; Operate(int, int) int&#125;type AddOperate struct &#123;&#125;func (this *AddOperate) Operate(rhs int, lhs int) int &#123; return rhs + lhs&#125;type MultipleOperate struct &#123;&#125;func (this *MultipleOperate) Operate(rhs int, lhs int) int &#123; return rhs * lhs&#125;type OperateFactory struct &#123;&#125;func NewOperateFactory() *OperateFactory &#123; return &amp;OperateFactory&#123;&#125;&#125;func (this *OperateFactory) CreateOperate(operatename string) Operater &#123; switch operatename &#123; case "+": return &amp;AddOperate&#123;&#125; case "*": return &amp;MultipleOperate&#123;&#125; default: panic("无效运算符号") return nil &#125;&#125;func main() &#123; Operator := NewOperateFactory().CreateOperate("+") fmt.Printf("add result is %d\n", Operator.Operate(1, 2))&#125; 代码看起来没什么问题，后来又看到一种实现方式，来自这篇博客，代码如下： 12345678910111213141516171819202122232425262728type site interface &#123; fetch()&#125;type siteModel struct &#123; URL string&#125;type site1 struct &#123; siteModel&#125;func (s site1) fetch() &#123; fmt.Println("site1 fetch data")&#125;func factory(s string) site &#123; if s == "site" &#123; return site1&#123; siteModel&#123;URL: "http://www.xxxx.com"&#125;, &#125; &#125; return nil&#125;func main() &#123; s := factory("site") s.fetch()&#125; 代码初看上去跟第一个实现没什么不一样，但是当我详细阅读代码时，下面的这句代码着实把我弄晕了 12345678func factory(s string) site &#123; if s == "site" &#123; return site1&#123; siteModel&#123;URL: "http://www.xxxx.com"&#125;, &#125; &#125; return nil&#125; factory函数的返回值定义明明是一个interface, 但是在return的时候，却返回一个struct，查阅很多资料后，这篇博客帮了我的大忙，其中对interface的解释有这么一句话：在 Golang 中，interface 是一组 method 的集合，是 duck-type programming 的一种体现。不关心属性（数据），只关心行为（方法）。具体使用中你可以自定义自己的 struct，并提供特定的 interface 里面的 method 就可以把它当成 interface 来使用。之后又详细看了几遍这篇博文，犹如醍醐灌顶，对golanginterface的理解更深了一层。读完这篇后再去实现工厂模式，或者再去写golang的代码，对interface的使用就会更自如一些。 总结 本期技术周刊主要由golang工厂模式的讨论引起，之后又涉及到golang interface特性的讨论，对以后使用golang编写更加复杂的代码很有帮助。 本期结束，欲知后事如何，且看下周分解。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>golang design pattern go-interface</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang中的工厂模式]]></title>
    <url>%2F2018%2F08%2F27%2Fgolang%E4%B8%AD%E7%9A%84%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F-md%2F</url>
    <content type="text"><![CDATA[研究go的设计模式，必须了解go的struct和interface，若不熟悉，先阅读以下内容 go语言的struct go语言的interface 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849* 简单工厂模式package mainimport ( "fmt")type Operater interface &#123; Operate(int, int) int&#125;type AddOperate struct &#123;&#125;func (this *AddOperate) Operate(rhs int, lhs int) int &#123; return rhs + lhs&#125;type MultipleOperate struct &#123;&#125;func (this *MultipleOperate) Operate(rhs int, lhs int) int &#123; return rhs * lhs&#125;type OperateFactory struct &#123;&#125;func NewOperateFactory() *OperateFactory &#123; return &amp;OperateFactory&#123;&#125;&#125;func (this *OperateFactory) CreateOperate(operatename string) Operater &#123; switch operatename &#123; case "+": return &amp;AddOperate&#123;&#125; case "*": return &amp;MultipleOperate&#123;&#125; default: panic("无效运算符号") return nil &#125;&#125;func main() &#123; Operator := NewOperateFactory().CreateOperate("+") fmt.Printf("add result is %d\n", Operator.Operate(1, 2))&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697* 工厂方法package mainimport ( "fmt")type Operation struct &#123; a float64 b float64&#125;type OperationI interface &#123; GetResult() float64 SetA(float64) SetB(float64)&#125;func (op *Operation) SetA(a float64) &#123; op.a = a&#125;func (op *Operation) SetB(b float64) &#123; op.b = b&#125;type AddOperation struct &#123; Operation&#125;func (this *AddOperation) GetResult() float64 &#123; return this.a + this.b&#125;type SubOperation struct &#123; Operation&#125;func (this *SubOperation) GetResult() float64 &#123; return this.a - this.b&#125;type MulOperation struct &#123; Operation&#125;func (this *MulOperation) GetResult() float64 &#123; return this.a * this.b&#125;type DivOperation struct &#123; Operation&#125;func (this *DivOperation) GetResult() float64 &#123; return this.a / this.b&#125;type IFactory interface &#123; CreateOperation() Operation&#125;type AddFactory struct &#123;&#125;func (this *AddFactory) CreateOperation() OperationI &#123; return &amp;(AddOperation&#123;&#125;)&#125;type SubFactory struct &#123;&#125;func (this *SubFactory) CreateOperation() OperationI &#123; return &amp;(SubOperation&#123;&#125;)&#125;type MulFactory struct &#123;&#125;func (this *MulFactory) CreateOperation() OperationI &#123; return &amp;(MulOperation&#123;&#125;)&#125;type DivFactory struct &#123;&#125;func (this *DivFactory) CreateOperation() OperationI &#123; return &amp;(DivOperation&#123;&#125;)&#125;func main() &#123; fac := &amp;(AddFactory&#123;&#125;) oper := fac.CreateOperation() oper.SetA(1) oper.SetB(2) fmt.Println(oper.GetResult())&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849* 抽象工厂方法package mainimport "fmt"type GirlFriend struct &#123; nationality string eyesColor string language string&#125;type AbstractFactory interface &#123; CreateMyLove() GirlFriend&#125;type IndianGirlFriendFactory struct &#123;&#125;type KoreanGirlFriendFactory struct &#123;&#125;func (a IndianGirlFriendFactory) CreateMyLove() GirlFriend &#123; return GirlFriend&#123;"Indian", "Black", "Hindi"&#125;&#125;func (a KoreanGirlFriendFactory) CreateMyLove() GirlFriend &#123; return GirlFriend&#123;"Korean", "Brown", "Korean"&#125;&#125;func getGirlFriend(typeGf string) GirlFriend &#123; var gffact AbstractFactory switch typeGf &#123; case "Indian": gffact = IndianGirlFriendFactory&#123;&#125; return gffact.CreateMyLove() case "Korean": gffact = KoreanGirlFriendFactory&#123;&#125; return gffact.CreateMyLove() &#125; return GirlFriend&#123;&#125;&#125;func main() &#123; a := getGirlFriend("Indian") fmt.Println(a.eyesColor)&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac os 环境配置ruby on rails 及其Hello world]]></title>
    <url>%2F2018%2F08%2F26%2FMac-os-%E9%85%8D%E7%BD%AE-ruby-on-rails-md%2F</url>
    <content type="text"><![CDATA[今天在Mac OS环境中倒腾ruby on rails，遇到一些坑并排坑后总结一个搭建过程，供大家参考。 大纲 本着IT届能用最新的就不用前面的版本的宗旨，在进行之前必须将你的Mac升级到最新的macOS High Sierra 安装 XCode Command Line Tools 配置Git 安装Homebrew 安装GPG 安装RVM 安装ruby 升级RubyGems 安装rails 基本MVC探究之Hello world Ruby On rails for mac os High Sierra Mac OS是自带ruby的，但是这些ruby的版本都不是最新的，我们也不要用这些过时的版本 首先，升级你的Mac OS到10.13 查看是否安装xcode command line tool： 1234$:xcode-select -p如果你看到：xcode-select: error: unable to get active developer directory...说明你没有安装xcode command line tool,需要按照下面的步骤安装。 123如果你看到：$:/Applications/Xcode.app/Contents/Developer 或者/Library/Developer/CommandLineTools恭喜你，xcode command line tool你已经安装好了 123But，如果你很不幸运地看到了这句话：$: /Applications/Apple Dev Tools/Xcode.app/Contents/Developer那么你就要卸掉xcode重新安装了，具体原因看 这里 安装xcode 1xcode-select --install 一路确认之后，就可以安好xcode，但是如果你的网速不好，等待时间过长，你可以从这里输入你的APPID下载。 确认一下是否安好 12$ xcode-select -p/Library/Developer/CommandLineTools 配置Git 在安装ruby on rails 之前，你应该配置你的Git。Git在Mac OS上使自动安装的软件 检查Git版本并确认已经安装让你放心 12$ git versiongit version 2.4.9 (Apple Git-60) 配置Git之前，你应该到GitHub上注册你的账号并记住密码和邮箱。并使用下面的命令配置： 1234567$ git config -l --globalfatal: unable to read config file '/Users/.../.gitconfig': No such file or directory$ git config --global user.name "Your Real Name"$ git config --global user.email me@example.com$ git config -l --globaluser.name=Your Real Nameuser.email=me@example.com Git配置完成，在你想用Git的时候，它就会蹦出来了。 安装Homebrow 检查homebrow是否已经安装 12$ brew-bash: brew: command not found RVM需要Homebrow,其实一个Mac OS额安装包管理工具，用来下载一些软件，类似于Ubuntu的apt-get和centos的yum install.为避免安装RM出现问题，我们必须安装homebrow： 1$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 安装过程中可能会出现一些warning并让你输入密码： 123WARNING: Improper use of the sudo command could lead to data loss...To proceed, enter your password...Password: 尽管输入密码，忽略warning。 我们这里是使用了Mac OS内置的ruby来安装homebrow。 安装GPG gpg是一个用来检查RVM下载包的安全性的程序，我们使用homebrew来安装gpg: 1$ brew install gpg gpg安装之后，为RVM安装key: 1$ command curl -sSL https://rvm.io/mpapis.asc | gpg --import - 安装RVM RVM，是Ruby version manager的简写，用来安装ruby或者管理rails版本。这个网站详细说明了安装ruby的方式，但是我们有一种最简便的方式： 1$ \curl -L https://get.rvm.io | bash -s stable “curl”前面的“\”用来避免ruby版本的冲突，不要漏掉。 安装过程中你可能会看到 123mkdir: /etc/openssl: Permission deniedmkdir -p "/etc/openssl" failed, retrying with sudoyour password required for 'mkdir -p /etc/openssl': 请输入密码并继续。 如果你已经安装过RVM，使用下面的命令update： 1$ rvm get stable --autolibs=enable 重启terminal窗口或者使用：使RVM生效 1$ source ~/.rvm/scripts/rvm 安装ruby 在安装RVM之后，我们安装最新版本的ruby。ruby 2.5.1是写此博客时当前最新的ruby版本，还请查看ruby官网查看最新版本的ruby。必须指定ruby的版本： 1$ rvm install ruby-2.5.1 安装后检查是否安装成功： 12$ ruby -vruby 2.5.1... 升级rubyGemset RubyGems是一个ruby的包管理工具，用来安装ruby的工具或者额外功能的包。 查看gem版本： 1$ gem -v 将gem升级到最新版本 1$ gem update --system 显示RVM gemsets的最初两个设置 1234$ rvm gemset listgemsets for ruby-2.5.0=&gt; (default) global 一般使用global： 1$ rvm gemset use global 安装bundle,Bundle是一个管理gem的必须的工具 1$ gem install Bundler 安装Nokogiri，Nokogiri需要编译成指定的系统，在上面的配置下，号称最难安装的包，也将安装好 1$ gem install nokogiri 如果你真的不幸运在安装时遇到问题，Stack Overflow能帮到你。 安装rails 这里是ruby On rail最新的版本，5.1是最新稳定版本，5.2是release版本，我们安装5.1. 1$ gem install rails --version=5.1 如果你喜欢尝鲜，可以使用 1$ gem install rails --pre 安装release版本。 检查一下rails是否装好： 12$ rails -vRails 5.2.0 到此为止，ruby on rails 以及其环境配置都已妥当，可以开始你的ruby之旅了。 ruby on rails 的Hello world 123456$ cd /$ mkdir worlspace$ cd workspace$ rails _5.1.0_ new hello_app$ cd hello_app$ rails server 将http://localhost:3000输入浏览器，就能看到ruby on rails的欢迎界面。]]></content>
      <categories>
        <category>ruby</category>
      </categories>
      <tags>
        <tag>ruby on rails</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go实现UNIX command]]></title>
    <url>%2F2018%2F08%2F22%2Fgo-unix-cmd-md%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( "bufio" "errors" "fmt" "os" "os/exec" "strings")func main() &#123; reader := bufio.NewReader(os.Stdin) for &#123; fmt.Print("&gt; ") // 读取键盘的输入. input, err := reader.ReadString('\n') if err != nil &#123; fmt.Fprintln(os.Stderr, err) &#125; // 执行并解析command. err = execInput(input) if err != nil &#123; fmt.Fprintln(os.Stderr, err) &#125; &#125;&#125;// 如果cd命令没有路径的话，就报下面的错误var ErrNoPath = errors.New("path required")func execInput(input string) error &#123; // 移除换行符. input = strings.TrimSuffix(input, "\n") // 将输入分割成参数. args := strings.Split(input, " ") // 对cd命令的情况进行区分. switch args[0] &#123; case "cd": // 暂时不支持cd加空格进入home目录. if len(args) &lt; 2 &#123; return ErrNoPath &#125; err := os.Chdir(args[1]) if err != nil &#123; return err &#125; // Stop further processing. return nil case "exit": os.Exit(0) &#125; // Prepare the command to execute. cmd := exec.Command(args[0], args[1:]...) // Set the correct output device. cmd.Stderr = os.Stderr cmd.Stdout = os.Stdout // Execute the command and save it's output. err := cmd.Run() if err != nil &#123; return err &#125; return nil&#125; 12//执行并测试go run main.go 暂时不支持tab键自动补全命令，只是提供一种简单的思路。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iterm2 突然报很奇怪的错误-Error No user exists for uid 501]]></title>
    <url>%2F2018%2F08%2F21%2Fiterm2-strange-err-md-md%2F</url>
    <content type="text"><![CDATA[123No user exists for uid 501fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 上午还好好的，刚刚连接GitHub报这个错误，排查后了解到是iterm2的神坑。 重启iterm终端就好 系统有更新的话 需要重启终端 更新。]]></content>
      <categories>
        <category>生活中奇怪的坑</category>
      </categories>
      <tags>
        <tag>日常的坑系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang中interface的通用设计方法]]></title>
    <url>%2F2018%2F08%2F21%2Fgolang%E9%80%9A%E7%94%A8%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[golang中接口设计的通用方法 123456789101112131415161718192021222324251. 接口定义type XxxManager interface &#123; Create(args argsType) (*XxxStruct, error) Get(args argsType) (**XxxStruct, error) Update(args argsType) (*XxxStruct, error) Delete(name string, options *DeleleOptions) error&#125;2. 结构体定义 type XxxManagerImpl struct &#123; Name string Namespace string kubeCli *kubernetes.Clientset&#125;3，构造函数func NewXxxManagerImpl (namespace, name string, kubeCli *kubernetes.Clientset) XxxManager &#123; return &amp;XxxManagerImpl&#123; Name name, Namespace namespace, kubeCli: kubeCli, &#125;&#125;4. 方法具体实现func (xm *XxxManagerImpl) Create(args argsType) (*XxxStruct, error) &#123; //具体的方法实现&#125; golang通用接口设计 根据以上设计cdosapi封装接口：]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3中遇到'TypeError Unicode-objects must be encoded before hashing']]></title>
    <url>%2F2018%2F08%2F20%2Fpython-md5-err-md%2F</url>
    <content type="text"><![CDATA[Python3中进行MD5加密，遇到编码问题 12345678910111213141516171819202122232425262728293031323334353637383940import hashlibfrom urllib.parse import urlencode, quote_plusimport urllibdef verfy_ac(private_key): item = &#123; "Action" : "CreateUHostInstance", "CPU" : 2, "ChargeType" : "Month", "DiskSpace" : 10, "ImageId" : "f43736e1-65a5-4bea-ad2e-8a46e18883c2", "LoginMode" : "Password", "Memory" : 2048, "Name" : "Host01", "Password" : "VUNsb3VkLmNu", "PublicKey" : "ucloudsomeone%40example.com1296235120854146120", "Quantity" : 1, "Region" : "cn-bj2", "Zone" : "cn-bj2-04" &#125; # 将参数串排序 params_data = "" import pdb;pdb.set_trace() for key, value in item.items(): params_data = params_data + str(key) + str(value) params_data = params_data + private_key params_data_en = quote_plus(params_data) sign = hashlib.sha1() sign.update(params_data_en.encode('utf8')) signature = sign.hexdigest() return signatureprint(verfy_ac("46f09bb9fab4f12dfc160dae12273d5332b5debe")) 这是ucloud官方的API教程，想根据此教程生成签名，教程中的代码是基于Python2.7编写，我将其改成了Python3.但是在执行时报错： 1TypeError: Unicode-objects must be encoded before hashing 排错后发现python3中字符对象是unicode对象，不能直接加密，需要编码后才能进行update。 就是改成如下即可： 1sign.update(params_data_en.encode('utf8'))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>md5编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F08%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
