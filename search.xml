<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[技术周刊之改善 Python 程序的 91 个建议（转载)]]></title>
    <url>%2F2018%2F10%2F21%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E6%94%B9%E5%96%84-Python-%E7%A8%8B%E5%BA%8F%E7%9A%84-91-%E4%B8%AA%E5%BB%BA%E8%AE%AE%EF%BC%88%E8%BD%AC%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[本篇博客转载自zhuanlan.zhihu.com/p/32817459。 除了Google的Python代码规范外，从来没有类似的书籍。偶然的机会看到这么一本书，读完之后觉得还不错，所以做个简单的笔记。有想学习类似知识的朋友，又懒得去读完整本书籍，可以参考一下。 1：引论建议1、理解Pythonic概念—-详见Python中的《Python之禅》 建议2、编写Pythonic代码 （1）避免不规范代码，比如只用大小写区分变量、使用容易混淆的变量名、害怕过长变量名等。有时候长的变量名会使代码更加具有可读性。 （2）深入学习Python相关知识，比如语言特性、库特性等，比如Python演变过程等。深入学习一两个业内公认的Pythonic的代码库，比如Flask等。 建议3：理解Python与C的不同之处，比如缩进与{}，单引号双引号，三元操作符？，Switch-Case语句等。 建议4：在代码中适当添加注释 建议5：适当添加空行使代码布局更加合理 建议6：编写函数的4个原则 （1）函数设计要尽量短小，嵌套层次不宜过深 （2）函数声明应该做到合理、简单、易用 （3）函数参数设计应该考虑向下兼容 （4）一个函数只做一件事，尽量保证函数粒度的一致性 建议7：将常量集中在一个文件，且常量名尽量使用全大写字母 2：编程惯用法建议8：利用assert语句来发现问题，但要注意，断言assert会影响效率 建议9：数据交换值时不推荐使用临时变量，而是直接a, b = b, a 建议10：充分利用惰性计算（Lazy evaluation）的特性，从而避免不必要的计算 建议11：理解枚举替代实现的缺陷（最新版Python中已经加入了枚举特性） 建议12：不推荐使用type来进行类型检查，因为有些时候type的结果并不一定可靠。如果有需求，建议使用isinstance函数来代替 建议13：尽量将变量转化为浮点类型后再做除法（Python3以后不用考虑） 建议14：警惕eval()函数的安全漏洞，有点类似于SQL注入 建议15：使用enumerate()同时获取序列迭代的索引和值 建议16：分清==和is的适用场景，特别是在比较字符串等不可变类型变量时（详见评论） 建议17：尽量使用Unicode。在Python2中编码是很让人头痛的一件事，但Python3就不用过多考虑了 建议18：构建合理的包层次来管理Module 3：基础用法建议19：有节制的使用from…import语句，防止污染命名空间 建议20：优先使用absolute import来导入模块（Python3中已经移除了relative import） 建议21：i+=1不等于++i，在Python中，++i前边的加号仅表示正，不表示操作 建议22：习惯使用with自动关闭资源，特别是在文件读写中 建议23：使用else子句简化循环（异常处理） 建议24：遵循异常处理的几点基本原则 （1）注意异常的粒度，try块中尽量少写代码 （2）谨慎使用单独的except语句，或except Exception语句，而是定位到具体异常 （3）注意异常捕获的顺序，在合适的层次处理异常 （4）使用更加友好的异常信息，遵守异常参数的规范 建议25：避免finally中可能发生的陷阱 建议26：深入理解None，正确判断对象是否为空。Python中下列数据会判断为空： 建议27：连接字符串应优先使用join函数，而不是+操作 建议28：格式化字符串时尽量使用.format函数，而不是%形式 建议29：区别对待可变对象和不可变对象，特别是作为函数参数时 建议30：[], {}和()：一致的容器初始化形式。使用列表解析可以使代码更清晰，同时效率更高 建议31：函数传参数，既不是传值也不是传引用，而是传对象或者说对象的引用 建议32：警惕默认参数潜在的问题，特别是当默认参数为可变对象时 建议33：函数中慎用变长参数*args和**kargs （1）这种使用太灵活，从而使得函数签名不够清晰，可读性较差 （2）如果因为函数参数过多而是用变长参数简化函数定义，那么一般该函数可以重构 建议34：深入理解str()和repr()的区别 （1）两者之间的目标不同：str主要面向客户，其目的是可读性，返回形式为用户友好性和可读性都比较高的字符串形式；而repr是面向Python解释器或者说Python开发人员，其目的是准确性，其返回值表示Python解释器内部的定义 （2）在解释器中直接输入变量，默认调用repr函数，而print(var)默认调用str函数 （3）repr函数的返回值一般可以用eval函数来还原对象 （4）两者分别调用对象的内建函数str__()和__repr() 建议35：分清静态方法staticmethod和类方法classmethod的使用场景 4：库建议36：掌握字符串的基本用法 建议37：按需选择sort()和sorted()函数 》sort()是列表在就地进行排序，所以不能排序元组等不可变类型。 》sorted()可以排序任意的可迭代类型，同时不改变原变量本身。 建议38：使用copy模块深拷贝对象，区分浅拷贝（shallow copy）和深拷贝（deep copy） 建议39：使用Counter进行计数统计，Counter是字典类的子类，在collections模块中 建议40：深入掌握ConfigParser 建议41：使用argparse模块处理命令行参数 建议42：使用pandas处理大型CSV文件 》Python本身提供一个CSV文件处理模块，并提供reader、writer等函数。 》Pandas可提供分块、合并处理等，适用于数据量大的情况，且对二维数据操作更方便。 建议43：使用ElementTree解析XML 建议44：理解模块pickle的优劣 》优势：接口简单、各平台通用、支持的数据类型广泛、扩展性强 》劣势：不保证数据操作的原子性、存在安全问题、不同语言之间不兼容 建议45：序列化的另一个选择JSON模块：load和dump操作 建议46：使用traceback获取栈信息 建议47：使用logging记录日志信息 建议48：使用threading模块编写多线程程序 建议49：使用Queue模块使多线程编程更安全 5：设计模式建议50：利用模块实现单例模式 建议51：用mixin模式让程序更加灵活 建议52：用发布-订阅模式实现松耦合 建议53：用状态模式美化代码 6：内部机制建议54：理解build-in对象 建议55：init__()不是构造方法，理解__new()与它之间的区别 建议56：理解变量的查找机制，即作用域 》局部作用域 》全局作用域 》嵌套作用域 》内置作用域 建议57：为什么需要self参数 建议58：理解MRO（方法解析顺序）与多继承 建议59：理解描述符机制 建议60：区别getattr__()与__getattribute()方法之间的区别 建议61：使用更安全的property 建议62：掌握元类metaclass 建议63：熟悉Python对象协议 建议64：利用操作符重载实现中缀语法 建议65：熟悉Python的迭代器协议 建议66：熟悉Python的生成器 建议67：基于生成器的协程和greenlet，理解协程、多线程、多进程之间的区别 建议68：理解GIL的局限性 建议69：对象的管理和垃圾回收 7：使用工具辅助项目开发建议70：从PyPI安装第三方包 建议71：使用pip和yolk安装、管理包 建议72：做paster创建包 建议73：理解单元测试的概念 建议74：为包编写单元测试 建议75：利用测试驱动开发（TDD）提高代码的可测性 建议76：使用Pylint检查代码风格 》代码风格审查 》代码错误检查 》发现重复以及不合理的代码，方便重构 》高度的可配置化和可定制化 》支持各种IDE和编辑器的集成 》能够基于Python代码生成UML图 》能够与Jenkins等持续集成工具相结合，支持自动代码审查 建议77：进行高效的代码审查 建议78：将包发布到PyPI 8：性能剖析与优化建议79：了解代码优化的基本原则 建议80：借助性能优化工具 建议81：利用cProfile定位性能瓶颈 建议82：使用memory_profiler和objgraph剖析内存使用 建议83：努力降低算法复杂度 建议84：掌握循环优化的基本技巧 》减少循环内部的计算 》将显式循环改为隐式循环，当然这会牺牲代码的可读性 》在循环中尽量引用局部变量 》关注内层嵌套循环 建议85：使用生成器提高效率 建议86：使用不同的数据结构优化性能 建议87：充分利用set的优势 建议88：使用multiprocessing模块克服GIL缺陷 建议89：使用线程池提高效率 建议90：使用C/C++模块扩展提高性能 建议91：使用Cythonb编写扩展模块]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>编程规范</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之基于beego web框架的RESTful API的构建之旅]]></title>
    <url>%2F2018%2F10%2F14%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E5%9F%BA%E4%BA%8Ebeego-web%E6%A1%86%E6%9E%B6%E7%9A%84RESTful-API%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B9%8B%E6%97%85%2F</url>
    <content type="text"><![CDATA[前言​ beego是一个快速开发GO应用的http框架，作者是go语言方向的大牛，astaxie。beego可以用来快速开发API、web、后端服务等应用，是一个RESTFul风格的框架，主要的设计灵感来自于Python web开发框架tornado、flask、sinstra，很好的结合了Go语言本身的一些特性（interface，struct继承等）。 ​ beego是基于八大独立模块来实现的，很好的实现了模块间的解耦，即使用户不使用http的逻辑，也可以很好的使用其中的各个模块。作者自己说，他的这种思想来自于乐高积木，设计beego的时候，这些模块就是积木，而最终搭建好的机器人就是beego。 ​ 这篇博文通过使用beego来构建API，讲解实现过程中的细节以及遇到的一些坑，让我们马上开始beego的API构建之旅吧！ 项目创建 进入到你的$GOPATH/src 安装beego开发包自己快速开发工具bee 123go get github.com/astaxie/beegogo get github.com/astaxie/beego/ormgo get github.com/beego/bee 使用快速开发工具bee，创建我们的API项目 1bee new firstAPI 我们得到的项目结构如下图所示： 可以看出这是一个典型的MVC架构的应用，beego把我们项目所需要的一些都准备好了，例如配置文件conf，测试文件tests等，我们只需要专注于API代码的编写即可。 运行项目并获得API自动化文档1bee run -gendoc=true -downdoc=true 运行上述代码输出如下图所示： 我们在浏览器中访问：本机IP：8080/swagger，就会看到swagger的API文档，我们代码更新后，该文档就会自动更新，非常方便。 models设计 对 数据库object 操作有四个方法 Read / Insert / Update / Delete 1234567891011示例代码：o := orm.NewOrm()user := new(User)user.Name = "slene"fmt.Println(o.Insert(user))user.Name = "Your"fmt.Println(o.Update(user))fmt.Println(o.Read(user))fmt.Println(o.Delete(user)) 还有其他的方法可以参阅beego官方文档，里面对orm操作有着详细的介绍。 创建一个数据库并设计一张数据库表 1234567CREATE TABLE IF NOT EXISTS `student` (`Id` int(11),`Name` varchar(255),`Birthdate` varchar(255),`Gender` bool,`Score` int(11)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 在models文件夹下新建一个文件Student.go,并实现以下代码，代码中关键点都有注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package modelsimport ( "fmt" "github.com/astaxie/beego/orm")//在models模块中创建一个struct，目的是使用beego的orm框架，使struct与数据库中的字段产生对应关系type Student struct &#123; Id int`orm:"column(Id)"` //column()括号中的字段就是在定义数据库时的相应字段，这一段必须严格填写，不然在API读写数据时就会出现读不到或者写不进去的问题 Name string `orm:"column(Name)"` BirthDate string `orm:"column(Birthdate)"` Gender bool `orm:"column(Gender)"` Score int `orm:"column(Score)"`&#125;//该函数获得数据库中所有student的信息，返回值是一个结构体数组指针func GetAllStudents() []*Student &#123; o := orm.NewOrm() //产生一个orm对象 o.Using("default") //这句话的意思是使用定义的默认数据库，与main.go中的orm.RegisterDataBase()对应 var students []*Student //定义指向结构体数组的指针 q := o.QueryTable("student")//获得一个数据库表的请求 q.All(&amp;students)//取到这个表中的所有数据 return students&#125;//该函数根据student中的Id，返回该学生的信息func GetStudentById(id int) Student &#123; u := Student&#123;Id:id&#125;//根据所传入的Id得到对应student的对象 o := orm.NewOrm()//new 一个orm对象 o.Using("default")//使用最开始定义的default数据库 err := o.Read(&amp;u)//读取Id=id的student的信息 if err == orm.ErrNoRows &#123; fmt.Println("查询不到")//对应操作，不一定是print &#125; else if err == orm.ErrMissPK &#123; fmt.Println("没有主键") &#125; return u&#125;//添加一个学生的信息到数据库中，参数是指向student结构题的指针func AddStudent(student *Student) Student &#123; o := orm.NewOrm() o.Using("default") o.Insert(student)//插入数据库 return *student&#125;func UpdateStudent(student *Student) &#123; o := orm.NewOrm() o.Using("default") o.Update(student)//更新该student的信息&#125;func DeleteStudent(id int) &#123; o := orm.NewOrm() o.Using("default") o.Delete(&amp;Student&#123;Id:id&#125;)//删除对应id的student的信息&#125;func init() &#123; orm.RegisterModel(new(Student))//将数据库注册到orm&#125; model这一层主要是定义struct，并为上层编写读写数据库。处理数据的代码。 controller层实现基于 beego 的 Controller 设计，只需要匿名组合 beego.Controller 就可以了，如下所示： 123type xxxController struct &#123; beego.Controller&#125; beego.Controller 实现了接口 beego.ControllerInterface，beego.ControllerInterface 定义了如下函数： Init(ct *context.Context, childName string, app interface{}) 这个函数主要初始化了 Context、相应的 Controller 名称，模板名，初始化模板参数的容器 Data，app 即为当前执行的 Controller 的 reflecttype，这个 app 可以用来执行子类的方法。 Prepare() 这个函数主要是为了用户扩展用的，这个函数会在下面定义的这些 Method 方法之前执行，用户可以重写这个函数实现类似用户验证之类。 Get() 如果用户请求的 HTTP Method 是 GET，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Get 请求。 Post() 如果用户请求的 HTTP Method 是 POST，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Post 请求。 Delete() 如果用户请求的 HTTP Method 是 DELETE，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Delete 请求。 Put() 如果用户请求的 HTTP Method 是 PUT，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Put 请求. Head() 如果用户请求的 HTTP Method 是 HEAD，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Head 请求。 Patch() 如果用户请求的 HTTP Method 是 PATCH，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Patch 请求. Options() 如果用户请求的HTTP Method是OPTIONS，那么就执行该函数，默认是 405，用户继承的子 struct 中可以实现了该方法以处理 Options 请求。 Finish() 这个函数是在执行完相应的 HTTP Method 方法之后执行的，默认是空，用户可以在子 struct 中重写这个函数，执行例如数据库关闭，清理数据之类的工作。 Render() error 这个函数主要用来实现渲染模板，如果 beego.AutoRender 为 true 的情况下才会执行。 所以通过子 struct 的方法重写，用户就可以实现自己的逻辑。 routers层实现什么是路由设置呢？前面介绍的 MVC 结构执行时，介绍过 beego 存在三种方式的路由:固定路由、正则路由、自动路由，与RESTFul API相关的就是固定路由和正则路由。 下面就是固定路由的例子 1234beego.Router("/", &amp;controllers.MainController&#123;&#125;)beego.Router("/admin", &amp;admin.UserController&#123;&#125;)beego.Router("/admin/index", &amp;admin.ArticleController&#123;&#125;)beego.Router("/admin/addpkg", &amp;admin.AddController&#123;&#125;) 下面是正则路由的例子： beego.Router(“/api/?:id”, &amp;controllers.RController{}) 默认匹配 //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123” beego.Router(“/api/:id”, &amp;controllers.RController{}) 默认匹配 //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123”，但URL”/api/“匹配失败 beego.Router(“/api/:id([0-9]+)“, &amp;controllers.RController{}) 自定义正则匹配 //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123” beego.Router(“/user/:username([\w]+)“, &amp;controllers.RController{}) 正则字符串匹配 //例如对于URL”/user/astaxie”可以匹配成功，此时变量”:username”值为”astaxie” beego.Router(“/download/.”, &amp;controllers.RController{}) *匹配方式 //例如对于URL”/download/file/api.xml”可以匹配成功，此时变量”:path”值为”file/api”， “:ext”值为”xml” beego.Router(“/download/ceshi/*“, &amp;controllers.RController{}) *全匹配方式 //例如对于URL”/download/ceshi/file/api.json”可以匹配成功，此时变量”:splat”值为”file/api.json” beego.Router(“/:id:int”, &amp;controllers.RController{}) int 类型设置方式，匹配 :id为int 类型，框架帮你实现了正则 ([0-9]+) beego.Router(“/:hi:string”, &amp;controllers.RController{}) string 类型设置方式，匹配 :hi 为 string 类型。框架帮你实现了正则 ([\w]+) beego.Router(“/cms_:id([0-9]+).html”, &amp;controllers.CmsController{}) 带有前缀的自定义正则 //匹配 :id 为正则类型。匹配 cms_123.html 这样的 url :id = 123 个人觉得，最方便的还是类似于Python框架flask的注解路由，也是在这个项目中使用的： 在routers/routers.go里面添加你所希望的API 12345678910111213141516171819202122232425262728package routersimport ( "firstAPI/controllers" "github.com/astaxie/beego")func init() &#123; ns := beego.NewNamespace("/v1", beego.NSNamespace("/object", beego.NSInclude( &amp;controllers.ObjectController&#123;&#125;, ), ), beego.NSNamespace("/user", beego.NSInclude( &amp;controllers.UserController&#123;&#125;, ), ), beego.NSNamespace("/student", beego.NSInclude( &amp;controllers.StudentController&#123;&#125;, ), ), ) beego.AddNamespace(ns)&#125; 以上代码实现了如下的API： /v1/object /v1/user /v1/student 非常清晰明了。 main.go的数据库配置1234567891011121314151617181920212223package mainimport ( _ "firstAPI/routers" "github.com/astaxie/beego" "github.com/astaxie/beego/orm" _ "github.com/go-sql-driver/mysql")func init() &#123; orm.RegisterDriver("mysql", orm.DRMySQL)//注册MySQL的driver orm.RegisterDataBase("default", "mysql", "root:test@tcp(127.0.0.1:3306)/restapi_test?charset=utf8")//本地数据库的账号。密码等 orm.RunSyncdb("default", false, true)&#125;func main() &#123; if beego.BConfig.RunMode == "dev" &#123; beego.BConfig.WebConfig.DirectoryIndex = true beego.BConfig.WebConfig.StaticDir["/swagger"] = "swagger"//静态文档 &#125; beego.Run()&#125; 关键点都在代码中以注释的形式展现。 postman测试bee run 运行代码后，我们使用postman测试一下我们所构建的API效果如何。 这里节省篇幅，只测试一个接口。 到此为止，我们基于beego就实现了简单API接口的构建，是不是既清晰又简单呢？赶快自己动手试试吧！ 本期技术周刊结束，代码已上传到GitHub，可以查阅，我们下期再会！]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>golang beego</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结版图解http]]></title>
    <url>%2F2018%2F10%2F12%2F%E6%80%BB%E7%BB%93%E7%89%88%E5%9B%BE%E8%A7%A3http%2F</url>
    <content type="text"><![CDATA[该博客转载自公众号freeCodeCamp 作为一个前端，如果对一个网页从发起请求到返回数据这期间具体发生了什么都不知道的话，那不是一个好前端。最近，读了图解http，以及有关http相关的文章，还有自己也下载了wireshark抓包工具，实际观察了一下这个过程，下面就此做些总结。 一.从输入一个url到返回数据，中间到底发生了什么？ 假设，我们在浏览器输入http://www.baidu.com:80/index.html，假设解析出的ip地址是202.43.78.3 1.浏览器解析出主机名 解析出的主机名是www.baidu.com 2.浏览器查询这个主机名的ip地址（dns） dns解析的作用就是把域名解析成ip地址，这样才能在广域网路由器转发报文给目标ip，不然路由器不知道要把报文发给谁。下面就讲下大概的过程，不会涉及太多细节。（以chrome为例子） （1）浏览器启动时，首先浏览器会去操作系统获取dns服务器地址，然后把这个地址缓存下来。同时浏览器还会去读取和解析hosts文件，同样放到缓存中。浏览器对解析过的域名和ip地址，都会保存着这两者的映射关系。（存到cache中） （2）当解析域名的时候，首先浏览器会去cache中查找有没有缓存好的映射关系，如果没有的话，就去hosts文件中查找，如果也没有的话，浏览器就会发起请求去dns服务器缓存查询了，如果缓存里面也没有，那最后就是dns服务器去查询了。 3.浏览器获取端口号 4.浏览器向目标ip地址发起一条到202.43.78.3:80的tcp连接 为了传输的可靠性，tcp协议要有三次握手过程： （1）首先浏览器会向服务器发起一个连接请求 （2）服务器会对连接请求做出响应，表示同意建立连接 （3）浏览器收到响应后，再告知对方，它知道服务器同意它建立连接了。 5.数据包在ip层传输 数据包在ip层传输，通过多台计算机和网络设备中转，在中转时，利用中转设备的mac地址搜索下一个中转目标（采用ARP协议，根据通信方的ip地址就可以反查出对应的mac地址），直到目标ip地址。 6.数据链路层处理网络连接的硬件部分 数据链路层处理网络连接的硬件部分，比如网卡，找到服务器的网卡 7.浏览器向服务器发送一条http报文 每一条http报文的组成： 起始行+首部+主体(可选) 起始行：http/1.0 200 ok (一般包括http版本，返回状态码，返回码原因) 首部：content-type:text/plain content-length:19 主体：name=jane 8.服务器接受客户端请求，进行一些处理，返回响应报文 web服务器接收到请求之后，实际上会做些什么呢？ （1）建立连接，如果接受一个客户端连接，就建立连接，如果不同意，就将其关闭。 （2）接收请求，读取http请求报文 （3）访问资源，访问报文中指定的资源 （4）构建响应，创建带有首部的http响应报文 （5）发送响应，将响应回送给客户端 9.浏览器读取http响应报文 10.浏览器关闭连接 看了上面的一个简单过程，大家会不会有这样一个问题，难道每次发起一个http请求，都要建立一次tcp连接吗，我们经常写的并发ajax请求，每条请求都是各自独立建立的tcp连接？一条tcp连接建立之后，是什么时候关闭的？带着这些问题，看看下面要讲的http的特性 二.http的特性 1.http是不保存状态的协议 http协议是一种无状态的协议，意思就是说它不会对每次的请求和响应之间的通信状态进行保存。你之前发过的任何请求的信息，没有任何记录。之所以这样设计，也是为了让http变得比较简单，可以处理大量事物。但是无状态的特性，也会导致一些问题，比如说一个用户登录一家网站之后，跳到另一个页面，应该还保持着登录状态，所以后面就出了cookie状态管理技术。相信大家应该都很熟悉了。 2.请求只能从客户端开始，客户端不可以接收除响应以外的指令 服务器必须等待客户端的请求，才能给客户端发送响应数据，所以说服务器是不能主动给客户端推送数据的。对于一些实时监控的功能，常常用websocket来代替 3.没有用户认证，任何人都可以发起请求 在http协议通信时，是不存在确认通信方的处理步骤的，任何人都可以发起请求。另外，服务器只要收到请求，无论是谁，都会返回一个响应。所以会存在伪装的隐患。后面出现的https就可以解决这个问题。 4.通信使用的是明文 5.无法证明报文完整性 6.可任意选择数据压缩格式，非强制压缩发送 7.http持久连接和并行连接 一开始，http请求是串行的，一个http请求，就会建立一条tcp连接，浏览器收到响应之后，就会断开连接。等上一个请求回来了，下一个请求才能继续请求。这样做的缺点是，比较耗时间和内存，后面就出现了下面一系列的优化连接性能的方法。 （1）并行连接 原理：通过多条tcp连接发起并发的http请求 并行连接可以同时发起多个http请求，每次发起一个http请求，就会建立一个tcp连接。每个http请求是独立的，不会相互等待，这样做，很可能会提高页面的加载速度，因为人们会看到页面上面，很多个东西会同时出现，所以感觉页面加载变快了。实际上有时候是真的变快了，因为它是并行工作的。但是有时候不是真的快了。比如说，客户端的网络带宽不足时，（浏览器是通过一个28kbps的modem连接到因特网上去的），如果并行加载多个请求，每个请求就会去竞争这个有限的带宽，每个请求就会以比较慢的速度加载。这样带来的性能提升就很小。 （2）持久连接 原理：重用tcp连接，以消除连接及关闭时延 从http1.1开始，就允许当http响应结束后，tcp连接可以保持在打开状态，以便给未来的http请求重用现在的连接。那么，这个tcp连接什么时候会关闭呢，一般情况下，40s内，如果没有新的请求，就会关闭。 （3）管道化连接 原理：通过共享的tcp连接发起并发的http请求 并行连接可以提高复合页面的传输速度，但是也有许多缺点，比如每次都会建立一次tcp连接，会耗费时间和带宽。持久连接的优势就是降低了时延和tcp的连接数量。但是持久连接可能会导致的一个问题是，可能会累积大量的空闲连接。耗费资源。 持久连接和并行连接配合使用才是最高效的方式。 一般浏览器会限制，同个域名下的并行连接的个数是4个，即打开少量的并行连接，其中每个都是持久连接。这也是现在用的最多的方式。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python apscheduler - skipped: maximum number of running instances reached]]></title>
    <url>%2F2018%2F09%2F28%2Fpython-apscheduler-skipped-maximum-number-of-running-instances-reached%2F</url>
    <content type="text"><![CDATA[出现问题的代码123scheduler = BackgroundScheduler()scheduler.add_job(runsync, 'interval', seconds=1)scheduler.start() 问题出现的情况 运行一段代码，时而报错时而不报错 报错是： 1WARNING:apscheduler.scheduler:Execution of job &quot;runsync (trigger: interval[0:00:01], next run at: 2015-12-01 11:50:42 UTC)&quot; skipped: maximum number of running instances reached (1) 分析 apscheduler这个模块，在你的代码运行时间大于interval的时候，就会报错 也就是说，你的代码运行时间超出了你的定时任务的时间间隔。 解决 增大时间间隔即可 ###]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 的logging模块实现json格式的日志输出]]></title>
    <url>%2F2018%2F09%2F27%2Fpython-%E7%9A%84logging%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0json%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[前言： 想要让开发过程或者是上线后的bug无处可藏，最好的方式便是在程序运行过程中，不断收集重要的日志，以供分析使用。Python中内置的log收集模块是logging，该模块使用起来比较方便，但是美中不足的地方就是日志的格式转成json比较麻烦。于是我结合logging和另一个模块python-json-logger(pip install python-json-logger) ，实现json格式的日志输出。 源码：以下代码可以做成模块，直接导入使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import logging, logging.config, osimport structlogfrom structlog import configure, processors, stdlib, threadlocalfrom pythonjsonlogger import jsonloggerBASE_DIR = BASE_DIR = os.path.dirname(os.path.abspath(__file__))DEBUG = True # 标记是否在开发环境# 给过滤器使用的判断class RequireDebugTrue(logging.Filter): # 实现filter方法 def filter(self, record): return DEBUGdef get_logger(): LOGGING = &#123; # 基本设置 'version': 1, # 日志级别 'disable_existing_loggers': False, # 是否禁用现有的记录器 # 日志格式集合 'formatters': &#123; # 标准输出格式 'json': &#123; # [具体时间][线程名:线程ID][日志名字:日志级别名称(日志级别ID)] [输出的模块:输出的函数]:日志内容 'format': '[%(asctime)s][%(threadName)s:%(thread)d][%(name)s:%(levelname)s(%(lineno)d)]\n[%(module)s:%(funcName)s]:%(message)s', 'class': 'pythonjsonlogger.jsonlogger.JsonFormatter', &#125; &#125;, # 过滤器 'filters': &#123; 'require_debug_true': &#123; '()': RequireDebugTrue, &#125; &#125;, # 处理器集合 'handlers': &#123; # 输出到控制台 # 输出到文件 'TimeChecklog': &#123; 'level': 'DEBUG', 'class': 'logging.handlers.RotatingFileHandler', 'formatter': 'json', 'filename': os.path.join("./log/", 'TimeoutCheck.log'), # 输出位置 'maxBytes': 1024 * 1024 * 5, # 文件大小 5M 'backupCount': 5, # 备份份数 'encoding': 'utf8', # 文件编码 &#125;, &#125;, # 日志管理器集合 'loggers': &#123; # 管理器 'proxyCheck': &#123; 'handlers': ['TimeChecklog'], 'level': 'DEBUG', 'propagate': True, # 是否传递给父记录器 &#125;, &#125; &#125; configure( logger_factory=stdlib.LoggerFactory(), processors=[ stdlib.render_to_log_kwargs] ) logging.config.dictConfig(LOGGING) logger = logging.getLogger("proxyCheck") return logger# 测试用例，你可以把get_logger()封装成一个模块，from xxx import get_logger()logger1 = get_logger()def test(): try: a = 1 / 0 except Exception as e: logger1.error(e) # 写入错误日志 #如果需要添加额外的信息，使用extra关键字即可 logger1.error(e, extra=&#123;key1: value1, key2:value2&#125;) # 其他错误处理代码 passtest() ### 测试结果 测试的结果，可以在./log/xxx.log文件中看到输出的日志 1&#123;&quot;asctime&quot;: &quot;2018-09-28 09:52:12,622&quot;, &quot;threadName&quot;: &quot;MainThread&quot;, &quot;thread&quot;: 4338656704, &quot;name&quot;: &quot;proxyCheck&quot;, &quot;levelname&quot;: &quot;ERROR&quot;, &quot;%(lineno&quot;: null, &quot;module&quot;: &quot;mylog&quot;, &quot;funcName&quot;: &quot;test&quot;, &quot;message&quot;: &quot;division by zero&quot;&#125; 可以看到日志是json格式，这样你就可以很方便的使用grafna和ES将日志做成看板来展示了。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 发送各种格式的邮件]]></title>
    <url>%2F2018%2F09%2F17%2Fpython-%E5%8F%91%E9%80%81%E5%90%84%E7%A7%8D%E6%A0%BC%E5%BC%8F%E7%9A%84%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.mime.application import MIMEApplication_user = "sigeken@qq.com"_pwd = "***"_to = "402363522@qq.com" #如名字所示Multipart就是分多个部分msg = MIMEMultipart()msg["Subject"] = "don't panic"msg["From"] = _usermsg["To"] = _to #---这是文字部分---part = MIMEText("乔装打扮，不择手段")msg.attach(part) #---这是附件部分---#xlsx类型附件part = MIMEApplication(open('foo.xlsx','rb').read())part.add_header('Content-Disposition', 'attachment', filename="foo.xlsx")msg.attach(part) #jpg类型附件part = MIMEApplication(open('foo.jpg','rb').read())part.add_header('Content-Disposition', 'attachment', filename="foo.jpg")msg.attach(part) #pdf类型附件part = MIMEApplication(open('foo.pdf','rb').read())part.add_header('Content-Disposition', 'attachment', filename="foo.pdf")msg.attach(part) #mp3类型附件part = MIMEApplication(open('foo.mp3','rb').read())part.add_header('Content-Disposition', 'attachment', filename="foo.mp3")msg.attach(part) s = smtplib.SMTP("smtp.qq.com", timeout=30)#连接smtp邮件服务器,端口默认是25s.login(_user, _pwd)#登陆服务器s.sendmail(_user, _to, msg.as_string())#发送邮件s.close()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之当你ping的时候，发生了什么？]]></title>
    <url>%2F2018%2F09%2F16%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E5%BD%93%E4%BD%A0ping%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[我们在遇到网络不通的情况，大家都知道去 ping 一下，看一下网络状况。那你知道「ping」命令后背的逻辑是什么吗？知道它是如何实现的吗？本周就让我们深入浅出ping的机制。 ping的作用和原理简单来说，「ping」是用来探测本机与网络中另一主机之间是否可达的命令，如果两台主机之间ping不通，则表明这两台主机不能建立起连接。ping是定位网络通不通的一个重要手段。 ping 命令是基于 ICMP 协议来工作的，「 ICMP 」全称为 Internet 控制报文协议（ Internet Control Message Protocol）。ping 命令会发送一份ICMP回显请求报文给目标主机，并等待目标主机返回ICMP回显应答。因为ICMP协议会要求目标主机在收到消息之后，必须返回ICMP应答消息给源主机，如果源主机在一定时间内收到了目标主机的应答，则表明两台主机之间网络是可达的。 举一个例子来描述「ping」命令的工作过程： 假设有两个主机，主机A（192.168.0.1）和主机B（192.168.0.2），现在我们要监测主机A和主机B之间网络是否可达，那么我们在主机A上输入命令：ping 192.168.0.2 此时，ping命令会在主机A上构建一个 ICMP的请求数据包（数据包里的内容后面再详述），然后 ICMP协议会将这个数据包以及目标IP（192.168.0.2）等信息一同交给IP层协议。 IP层协议得到这些信息后，将源地址（即本机IP）、目标地址（即目标IP：192.168.0.2）、再加上一些其它的控制信息，构建成一个IP数据包。 IP数据包构建完成后，还不够，还需要加上MAC地址，因此，还需要通过ARP映射表找出目标IP所对应的MAC地址。当拿到了目标主机的MAC地址和本机MAC后，一并交给数据链路层，组装成一个数据帧，依据以太网的介质访问规则，将它们传送出出去。 当主机B收到这个数据帧之后，会首先检查它的目标MAC地址是不是本机，如果是就接收下来处理，接收之后会检查这个数据帧，将数据帧中的IP数据包取出来，交给本机的IP层协议，然后IP层协议检查完之后，再将ICMP数据包取出来交给ICMP协议处理，当这一步也处理完成之后，就会构建一个ICMP应答数据包，回发给主机A 在一定的时间内，如果主机A收到了应答包，则说明它与主机B之间网络可达，如果没有收到，则说明网络不可达。除了监测是否可达以外，还可以利用应答时间和发起时间之间的差值，计算出数据包的延迟耗时。 通过ping的流程可以发现，ICMP协议是这个过程的基础，是非常重要的，因此下面就把ICMP协议再详细解释一下。 ICMP简介我们知道，ping命令是基于ICMP协议来实现的。那么我们再来看下图，就明白了ICMP协议又是通过IP协议来发送的，即ICMP报文是封装在IP包中。 IP协议是一种无连接的，不可靠的数据包协议，它并不能保证数据一定被送达，那么我们要保证数据送到就需要通过其它模块来协助实现，这里就引入的是ICMP协议。 当传送的IP数据包发送异常的时候，ICMP就会将异常信息封装在包内，然后回传给源主机。 将上图再细拆一下可见： 将ICMP部分拆开继续分析： 由图可知，ICMP数据包由8bit的类型字段和8bit的代码字段以及16bit的校验字段再加上选项数据组成。 ICMP协议大致可分为两类： 查询报文类型 差错报文类型 查询报文类型： 查询报文主要应用于：ping查询、子网掩码查询、时间戳查询等等。 上面讲到的ping命令的流程其实就对应ICMP协议查询报文类型的一种使用。在主机A构建ICMP请求数据包的时候，其ICMP的类型字段中使用的是 8 （回送请求），当主机B构建ICMP应答包的时候，其ICMP类型字段就使用的是 0 （回送应答），更多类型值参考上表。 对 查询报文类型 的理解可参考一下文章最开始讲的ping流程，这里就不做赘述。 差错报文类型： 差错报文主要产生于当数据传送发送错误的时候。 它包括：目标不可达（网络不可达、主机不可达、协议不可达、端口不可达、禁止分片等）、超时、参数问题、重定向（网络重定向、主机重定向等）等等。 差错报文通常包含了引起错误的IP数据包的第一个分片的IP首部，加上该分片数据部分的前8个字节。 当传送IP数据包发生错误的时候（例如 主机不可达），ICMP协议就会把错误信息封包，然后传送回源主机，那么源主机就知道该怎么处理了。 那是不是只有遇到错误的时候才能使用 差错报文类型 呢？也不一定。 Traceroute 就是一个例外，Traceroute是用来侦测源主机到目标主机之间所经过路由情况的常用工具。Traceroute 的原理就是利用ICMP的规则，制造一些错误的事件出来，然后根据错误的事件来评估网络路由情况。 具体做法就是： Traceroute会设置特殊的TTL值，来追踪源主机和目标主机之间的路由数。首先它给目标主机发送一个 TTL=1 的UDP数据包，那么这个数据包一旦在路上遇到一个路由器，TTL就变成了0（TTL规则是每经过一个路由器都会减1），因为TTL=0了，所以路由器就会把这个数据包丢掉，然后产生一个错误类型（超时）的ICMP数据包回发给源主机，也就是差错包。这个时候源主机就拿到了第一个路由节点的IP和相关信息了。 接着，源主机再给目标主机发一个 TTL=2 的UDP数据包，依旧上述流程走一遍，就知道第二个路由节点的IP和耗时情况等信息了。 如此反复进行，Traceroute就可以拿到从主机A到主机B之间所有路由器的信息了。 但是有个问题是，如果数据包到达了目标主机的话，即使目标主机接收到TTL值为1的IP数据包，它也是不会丢弃该数据包的，也不会产生一份超时的ICMP回发数据包的，因为数据包已经达到了目的地嘛。那我们应该怎么认定数据包是否达到了目标主机呢？ Traceroute的方法是在源主机发送UDP数据包给目标主机的时候，会设置一个不可能达到的目标端口号（例如大于30000的端口号），那么当这个数据包真的到达目标主机的时候，目标主机发现没有对应的端口号，因此会产生一份“端口不可达”的错误ICMP报文返回给源主机。 traceroot的具体使用方法网上都有很多讲解，可以实际操作一下。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7-安装docker-compose时由于pip10包管理导致的错误]]></title>
    <url>%2F2018%2F09%2F13%2FCentOS7-%E5%AE%89%E8%A3%85docker-compose%E6%97%B6%E7%94%B1%E4%BA%8Epip10%E5%8C%85%E7%AE%A1%E7%90%86%E5%AF%BC%E8%87%B4%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[今天在CentOS下安装docker-compose，遇到了Cannot uninstall ‘requests’. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.错误的原因是requests默认版本为2.6.0，但是docker-compose要2.9以上才支持，但是无法正常卸载2.9版本，是pip10对包的管理存在变化。 解决方案： pip install -l requests==2.9]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术周刊之解析Python中的赋值、浅拷贝、深拷贝]]></title>
    <url>%2F2018%2F09%2F09%2F%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E8%A7%A3%E6%9E%90Python%E4%B8%AD%E7%9A%84%E8%B5%8B%E5%80%BC%E3%80%81%E6%B5%85%E6%8B%B7%E8%B4%9D%E3%80%81%E6%B7%B1%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[事情的起因 本周我们分享的主题是Python中关于浅拷贝和深拷贝的特性，想要深入研究Python中的浅拷贝和深拷贝的起因在于，我想生成一个json字符串，该字符串未dumps之前是一个Python的数据结构，里面包含字典，以及List，在遍历生成dictionary时候，出现一个bug，就是每次遍历生成的dictionary都是上一次的值，现象可以看以下代码。 123456789101112131415161718# 这里我们定义一个函数get_data()def get_data(): ...: appid_dict = &#123;&#125; ...: appid_all_dict = &#123;&#125; ...: import pdb;pdb.set_trace() ...: for i in range(10): ...: appid_dict['a'] = i ...: appid_all_dict[i] = appid_dict# 我们的初衷是想要得到# &#123;0: &#123;'a': 0&#125;, 1: &#123;'a': 1&#125;, 2: &#123;'a': 2&#125;, 3: &#123;'a': 3&#125;&#125;....这样的一个dict# 但是在调试过程中，发现得到的结果是这样的：# (Pdb) appid_all_dict# &#123;0: &#123;'a': 2&#125;, 1: &#123;'a': 2&#125;, 2: &#123;'a': 2&#125;&#125;# (Pdb) # 即，后面的appid_dict都会把前面的覆盖掉，这是什么原因呢？# 我们这里先把原因说一下：因为Python中对dict的操作默认是浅拷贝，即同样的字典，使用多次的话，每次使用都是指向同一片内存地址(引用)，所以在上面的程序中后面对appid_dict的赋值，都将前面的给覆盖掉了，导致每一个appid_dict指向同一片内存，读取的当然就是最后一次的appid_dict的值，即上面程序的执行结果：&#123;0: &#123;'a': 9&#125;, 1: &#123;'a': 9&#125;, 2: &#123;'a': 9&#125;, 3: &#123;'a': 9&#125;, 4: &#123;'a': 9&#125;, 5: &#123;'a': 9&#125;, 6: &#123;'a': 9&#125;, 7: &#123;'a': 9&#125;, 8: &#123;'a': 9&#125;, 9: &#123;'a': 9&#125;&#125; 那么如何修改这个bug，让程序输出我们想要得到的结果： 1&#123;0: &#123;'a': 0&#125;, 1: &#123;'a': 1&#125;, 2: &#123;'a': 2&#125;, 3: &#123;'a': 3&#125;, 4: &#123;'a': 4&#125;, 5: &#123;'a': 5&#125;, 6: &#123;'a': 6&#125;, 7: &#123;'a': 7&#125;, 8: &#123;'a': 8&#125;, 9: &#123;'a': 9&#125;&#125; 看完下面对于Python赋值、浅拷贝、深拷贝的解析，相信你就可以自己解决这个问题了 Python中的赋值操作 赋值：就是对象的引用 举例： a = b: 赋值引用，a和b都指向同一个对象，如图所示 Python中浅拷贝 a = b.copy(): a 是b的浅拷贝，a和b是一个独立的对象，但是它们的子对象还是指向同一片引用。 Python中对字典的默认赋值操作就是浅拷贝，所以导致了文章开头所出现的情况。 Python中的深拷贝 首先import copy,导入copy模块（Python中自带），b = copy.deepcopy(a), 我们就说b是a的深拷贝，b拷贝了a所有的资源对象，并新开辟了一块地址空间，两者互不干涉。 实际的例子来进一步说明12345678910111213141516171819202122In [13]: import copyIn [14]: def temp(): ...: a = [1, 2, 3, 4, ['a', 'b']] ...: b = a # 赋值操作，直接传所有对象的引用 ...: c = copy.copy(a) # 浅拷贝，子对象指向同一引用 ...: d = copy.deepcopy(a) # 深拷贝，互不干涉 ...: a.append(5) # 修改对象a ...: a[4].append('c') # 修改a中的数组 ...: print( 'a = ', a ) ...: print( 'b = ', b ) ...: print( 'c = ', c ) ...: print( 'd = ', d ) ...: In [15]: In [15]: temp()a = [1, 2, 3, 4, ['a', 'b', 'c'], 5]b = [1, 2, 3, 4, ['a', 'b', 'c'], 5]c = [1, 2, 3, 4, ['a', 'b', 'c']]d = [1, 2, 3, 4, ['a', 'b']] 解决最初的问题 看到这里，我们再回头看文章最初的那个问题，就可以很easy地解决了。 12345678def get_data(): ...: appid_dict = &#123;&#125; ...: appid_all_dict = &#123;&#125; ...: import pdb;pdb.set_trace() ...: for i in range(10): appid_dict = copy.deepcopy(appid_dict)# 只需要加上这一行，使其成为深拷贝，问题解决！ ...: appid_dict['a'] = i ...: appid_all_dict[i] = appid_dict 总结要对Python的dictionary进行迭代分析，一定要注意其中的深拷贝问题，出现问题后，也要多往这方面考虑。 本期技术周刊到此结束。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>技术周刊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang 编译针对不同平台的可执行程序]]></title>
    <url>%2F2018%2F09%2F07%2Fgolang-%E7%BC%96%E8%AF%91%E9%92%88%E5%AF%B9%E4%B8%8D%E5%90%8C%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738Golang 支持在一个平台下生成另一个平台可执行程序的交叉编译功能。Mac下编译Linux, Windows平台的64位可执行程序：CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build test.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.goLinux下编译Mac, Windows平台的64位可执行程序：CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build test.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.goWindows下编译Mac, Linux平台的64位可执行程序：SET CGO_ENABLED=0SET GOOS=darwin3SET GOARCH=amd64go build test.goSET CGO_ENABLED=0SET GOOS=linuxSET GOARCH=amd64go build test.go GOOS：目标可执行程序运行操作系统，支持 darwin，freebsd，linux，windowsGOARCH：目标可执行程序操作系统构架，包括 386，amd64，armGolang version 1.5以前版本在首次交叉编译时还需要配置交叉编译环境：CGO_ENABLED=0 GOOS=linux GOARCH=amd64 ./make.bashCGO_ENABLED=0 GOOS=windows GOARCH=amd64 ./make.bash]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的Python小模块]]></title>
    <url>%2F2018%2F09%2F06%2F%E5%B8%B8%E7%94%A8%E7%9A%84Python%E5%B0%8F%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[工作或者生活中总会遇到一些常用的Python模块，为了避免重复的工作，将这些自己写过的Python模块记录下来，方便使用的时候查找。 Python写CSV文件，并防止中文乱码12345678def write_csv(a_list,b_list): with open('vm_data.csv', 'w') as f: f.write(codecs.BOM_UTF8.decode()) writer1 = csv.writer(f, dialect='excel') #写CVS的标题 writer1.writerow(['a', 'b']) #将数据写入CSV文件 writer1.writerows(zip(a_list, b_list)) Python将数据结构转为json,并优化json字符串的结构，处理中文乱码12345with open("appid.json", 'w', encoding='utf8', ) as f: f.write(json.dumps(final, sort_keys=True, indent=2, ensure_ascii=False))# sort_keys = True: 将字典的key按照字母排序# ident = 2: 优化json字符串结构，看起来更美观# ensure_ascii=False: 防止json字符串中的中文乱码 使用requests包进行网络请求（以post为例）1234567891011def get_data(url): final = &#123;&#125; url = &quot;http://xxxx.com&quot; request_body = &#123; &apos;access_token&apos;: access_token, &apos;request_body&apos;: &#123;&quot;params1&quot;: param1, &apos;params2&apos;: param2&#125; &#125; headers = &#123; &apos;Content-type&apos;: &apos;application/json&apos; &#125; data = requests.post(url, headers=headers, data=json.dumps(request_body))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql无法连接[MySql Host is blocked because of many connection errors]]]></title>
    <url>%2F2018%2F09%2F01%2FMysql%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[测试环境，发现数据库（MySQL数据库）无法登录，报错如下： Host is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’ 解决方案：使用mysqladmin flush-hosts 命令清理一下hosts文件（不知道mysqladmin在哪个目录下可以使用命令查找：whereis mysqladmin）； 登录到MySQL数据库中，mysql -uroot -h host -p 执行 1mysqladmin flush-hosts 问题解决。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 开启远程连接]]></title>
    <url>%2F2018%2F08%2F29%2Fmysql-%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[背景： 建站的时候会出现数据库和网站是不同的ip，就需要开启MySQL的远程连接服务，但是MySQL由于安全原因，默认设置是不允许远程只能本地连接，要开启远程连接就需要修改某些配置文件。 按照下面的步骤，开启MySQL的远程连接 进入数据库cmd 12mysql -uroot -h host -pEnter password:*** 连接到默认mysql数据库 123show databases;use mysql; 配置 1Grant all privileges on *.* to 'root'@'host' identified by 'password' with grant option; host表示你远程连接数据库设备的ip地址（如果你想让所有机器都能远程连接，host改为‘%’，不推荐这样使用），password表示MySQL的root用户密码 刷新or重启MySQL 1mysql&gt; flush privileges; 最后非常重要的一点 123vim /etc/vim /etc/mysql/my.cnf屏蔽bing-server 127.0.0.0#bing-server 127.0.0.0 完成，可以远程连接你的数据库了]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang factory design 引发的一系列思考]]></title>
    <url>%2F2018%2F08%2F29%2Fgolang-factory-design-%E5%BC%95%E5%8F%91%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[写在前面，突然萌生一个念头，做一个技术周刊系列，将每周工作或者生活当中遇到的比较有趣的问题记录下来，一来时总结一下，二来是为了以后退役了，可以回顾自己的技术生涯。 没有什么意外的话，我会每周六晚更新。 最近在整合三家公有云（AWS，ali, ucloud）的接口，考虑到代码复用的问题，于是开始考虑使用一种设计模式，这种场景下，最合适的便是工厂模式，将三家厂商的公有接口放入工厂方法中，然后对每一家new一个实例即可，以后再有新的厂商加入，改动的代码也不会太多。但是设计模式这种东西天然适合于java，对于golang这种比较新的语言来说，实现起来相对没有那么容易，对于刚接触golang的我来说，对一些golang的特性上并不是很熟悉，所以在此期间遇到一些不解的问题，写出来分享一下。 首先，什么是工厂模式 简单工厂模式就是通过传递不同的参数，生成不同的实例，工厂方法为每一个product提供一个工程类，通过不同的工厂创建不同的实例。 典型工厂模式的实现方式（即典型oop实现方式） 12345678910111213141516171819202122class ProviderModel&#123; provider string func factory(providerName string, test string)&#123; if providerName == "AWS" &#123; return new AWS(test) &#125; if providerName == "Ali"&#123; return new Ali(test) &#125; &#125;&#125;class AWS extends ProviderModel &#123; func construct(test string)&#123; this.test = test &#125; func doRequest()&#123;&#125;&#125;awsmodel := ProviderModel::factory("AWS")awsmodel.doRequest()alimodel := ProviderModel ::factory("Ali") alimodel.doRequest() golang实现工厂模式存在的问题 golang的特性中并没有像java一样的继承和重载，所以我们要利用golang存在的特性，透过工厂模式的表面透析其本质。 我们看一下工厂模式就知道，所谓工厂其实就是定义了一些需要去实现的方法，golang的interface正是可以做到。于是先到Google上搜了一段golang实现的工厂模式的代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( "fmt")type Operater interface &#123; Operate(int, int) int&#125;type AddOperate struct &#123;&#125;func (this *AddOperate) Operate(rhs int, lhs int) int &#123; return rhs + lhs&#125;type MultipleOperate struct &#123;&#125;func (this *MultipleOperate) Operate(rhs int, lhs int) int &#123; return rhs * lhs&#125;type OperateFactory struct &#123;&#125;func NewOperateFactory() *OperateFactory &#123; return &amp;OperateFactory&#123;&#125;&#125;func (this *OperateFactory) CreateOperate(operatename string) Operater &#123; switch operatename &#123; case "+": return &amp;AddOperate&#123;&#125; case "*": return &amp;MultipleOperate&#123;&#125; default: panic("无效运算符号") return nil &#125;&#125;func main() &#123; Operator := NewOperateFactory().CreateOperate("+") fmt.Printf("add result is %d\n", Operator.Operate(1, 2))&#125; 代码看起来没什么问题，后来又看到一种实现方式，来自这篇博客，代码如下： 12345678910111213141516171819202122232425262728type site interface &#123; fetch()&#125;type siteModel struct &#123; URL string&#125;type site1 struct &#123; siteModel&#125;func (s site1) fetch() &#123; fmt.Println("site1 fetch data")&#125;func factory(s string) site &#123; if s == "site" &#123; return site1&#123; siteModel&#123;URL: "http://www.xxxx.com"&#125;, &#125; &#125; return nil&#125;func main() &#123; s := factory("site") s.fetch()&#125; 代码初看上去跟第一个实现没什么不一样，但是当我详细阅读代码时，下面的这句代码着实把我弄晕了 12345678func factory(s string) site &#123; if s == "site" &#123; return site1&#123; siteModel&#123;URL: "http://www.xxxx.com"&#125;, &#125; &#125; return nil&#125; factory函数的返回值定义明明是一个interface, 但是在return的时候，却返回一个struct，查阅很多资料后，这篇博客帮了我的大忙，其中对interface的解释有这么一句话：在 Golang 中，interface 是一组 method 的集合，是 duck-type programming 的一种体现。不关心属性（数据），只关心行为（方法）。具体使用中你可以自定义自己的 struct，并提供特定的 interface 里面的 method 就可以把它当成 interface 来使用。之后又详细看了几遍这篇博文，犹如醍醐灌顶，对golanginterface的理解更深了一层。读完这篇后再去实现工厂模式，或者再去写golang的代码，对interface的使用就会更自如一些。 总结 本期技术周刊主要由golang工厂模式的讨论引起，之后又涉及到golang interface特性的讨论，对以后使用golang编写更加复杂的代码很有帮助。 本期结束，欲知后事如何，且看下周分解。]]></content>
      <categories>
        <category>技术周刊</category>
      </categories>
      <tags>
        <tag>golang design pattern go-interface</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang中的工厂模式]]></title>
    <url>%2F2018%2F08%2F27%2Fgolang%E4%B8%AD%E7%9A%84%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F-md%2F</url>
    <content type="text"><![CDATA[研究go的设计模式，必须了解go的struct和interface，若不熟悉，先阅读以下内容 go语言的struct go语言的interface 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849* 简单工厂模式package mainimport ( "fmt")type Operater interface &#123; Operate(int, int) int&#125;type AddOperate struct &#123;&#125;func (this *AddOperate) Operate(rhs int, lhs int) int &#123; return rhs + lhs&#125;type MultipleOperate struct &#123;&#125;func (this *MultipleOperate) Operate(rhs int, lhs int) int &#123; return rhs * lhs&#125;type OperateFactory struct &#123;&#125;func NewOperateFactory() *OperateFactory &#123; return &amp;OperateFactory&#123;&#125;&#125;func (this *OperateFactory) CreateOperate(operatename string) Operater &#123; switch operatename &#123; case "+": return &amp;AddOperate&#123;&#125; case "*": return &amp;MultipleOperate&#123;&#125; default: panic("无效运算符号") return nil &#125;&#125;func main() &#123; Operator := NewOperateFactory().CreateOperate("+") fmt.Printf("add result is %d\n", Operator.Operate(1, 2))&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697* 工厂方法package mainimport ( "fmt")type Operation struct &#123; a float64 b float64&#125;type OperationI interface &#123; GetResult() float64 SetA(float64) SetB(float64)&#125;func (op *Operation) SetA(a float64) &#123; op.a = a&#125;func (op *Operation) SetB(b float64) &#123; op.b = b&#125;type AddOperation struct &#123; Operation&#125;func (this *AddOperation) GetResult() float64 &#123; return this.a + this.b&#125;type SubOperation struct &#123; Operation&#125;func (this *SubOperation) GetResult() float64 &#123; return this.a - this.b&#125;type MulOperation struct &#123; Operation&#125;func (this *MulOperation) GetResult() float64 &#123; return this.a * this.b&#125;type DivOperation struct &#123; Operation&#125;func (this *DivOperation) GetResult() float64 &#123; return this.a / this.b&#125;type IFactory interface &#123; CreateOperation() Operation&#125;type AddFactory struct &#123;&#125;func (this *AddFactory) CreateOperation() OperationI &#123; return &amp;(AddOperation&#123;&#125;)&#125;type SubFactory struct &#123;&#125;func (this *SubFactory) CreateOperation() OperationI &#123; return &amp;(SubOperation&#123;&#125;)&#125;type MulFactory struct &#123;&#125;func (this *MulFactory) CreateOperation() OperationI &#123; return &amp;(MulOperation&#123;&#125;)&#125;type DivFactory struct &#123;&#125;func (this *DivFactory) CreateOperation() OperationI &#123; return &amp;(DivOperation&#123;&#125;)&#125;func main() &#123; fac := &amp;(AddFactory&#123;&#125;) oper := fac.CreateOperation() oper.SetA(1) oper.SetB(2) fmt.Println(oper.GetResult())&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849* 抽象工厂方法package mainimport "fmt"type GirlFriend struct &#123; nationality string eyesColor string language string&#125;type AbstractFactory interface &#123; CreateMyLove() GirlFriend&#125;type IndianGirlFriendFactory struct &#123;&#125;type KoreanGirlFriendFactory struct &#123;&#125;func (a IndianGirlFriendFactory) CreateMyLove() GirlFriend &#123; return GirlFriend&#123;"Indian", "Black", "Hindi"&#125;&#125;func (a KoreanGirlFriendFactory) CreateMyLove() GirlFriend &#123; return GirlFriend&#123;"Korean", "Brown", "Korean"&#125;&#125;func getGirlFriend(typeGf string) GirlFriend &#123; var gffact AbstractFactory switch typeGf &#123; case "Indian": gffact = IndianGirlFriendFactory&#123;&#125; return gffact.CreateMyLove() case "Korean": gffact = KoreanGirlFriendFactory&#123;&#125; return gffact.CreateMyLove() &#125; return GirlFriend&#123;&#125;&#125;func main() &#123; a := getGirlFriend("Indian") fmt.Println(a.eyesColor)&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac os 环境配置ruby on rails 及其Hello world]]></title>
    <url>%2F2018%2F08%2F26%2FMac-os-%E9%85%8D%E7%BD%AE-ruby-on-rails-md%2F</url>
    <content type="text"><![CDATA[今天在Mac OS环境中倒腾ruby on rails，遇到一些坑并排坑后总结一个搭建过程，供大家参考。 大纲 本着IT届能用最新的就不用前面的版本的宗旨，在进行之前必须将你的Mac升级到最新的macOS High Sierra 安装 XCode Command Line Tools 配置Git 安装Homebrew 安装GPG 安装RVM 安装ruby 升级RubyGems 安装rails 基本MVC探究之Hello world Ruby On rails for mac os High Sierra Mac OS是自带ruby的，但是这些ruby的版本都不是最新的，我们也不要用这些过时的版本 首先，升级你的Mac OS到10.13 查看是否安装xcode command line tool： 1234$:xcode-select -p如果你看到：xcode-select: error: unable to get active developer directory...说明你没有安装xcode command line tool,需要按照下面的步骤安装。 123如果你看到：$:/Applications/Xcode.app/Contents/Developer 或者/Library/Developer/CommandLineTools恭喜你，xcode command line tool你已经安装好了 123But，如果你很不幸运地看到了这句话：$: /Applications/Apple Dev Tools/Xcode.app/Contents/Developer那么你就要卸掉xcode重新安装了，具体原因看 这里 安装xcode 1xcode-select --install 一路确认之后，就可以安好xcode，但是如果你的网速不好，等待时间过长，你可以从这里输入你的APPID下载。 确认一下是否安好 12$ xcode-select -p/Library/Developer/CommandLineTools 配置Git 在安装ruby on rails 之前，你应该配置你的Git。Git在Mac OS上使自动安装的软件 检查Git版本并确认已经安装让你放心 12$ git versiongit version 2.4.9 (Apple Git-60) 配置Git之前，你应该到GitHub上注册你的账号并记住密码和邮箱。并使用下面的命令配置： 1234567$ git config -l --globalfatal: unable to read config file '/Users/.../.gitconfig': No such file or directory$ git config --global user.name "Your Real Name"$ git config --global user.email me@example.com$ git config -l --globaluser.name=Your Real Nameuser.email=me@example.com Git配置完成，在你想用Git的时候，它就会蹦出来了。 安装Homebrow 检查homebrow是否已经安装 12$ brew-bash: brew: command not found RVM需要Homebrow,其实一个Mac OS额安装包管理工具，用来下载一些软件，类似于Ubuntu的apt-get和centos的yum install.为避免安装RM出现问题，我们必须安装homebrow： 1$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 安装过程中可能会出现一些warning并让你输入密码： 123WARNING: Improper use of the sudo command could lead to data loss...To proceed, enter your password...Password: 尽管输入密码，忽略warning。 我们这里是使用了Mac OS内置的ruby来安装homebrow。 安装GPG gpg是一个用来检查RVM下载包的安全性的程序，我们使用homebrew来安装gpg: 1$ brew install gpg gpg安装之后，为RVM安装key: 1$ command curl -sSL https://rvm.io/mpapis.asc | gpg --import - 安装RVM RVM，是Ruby version manager的简写，用来安装ruby或者管理rails版本。这个网站详细说明了安装ruby的方式，但是我们有一种最简便的方式： 1$ \curl -L https://get.rvm.io | bash -s stable “curl”前面的“\”用来避免ruby版本的冲突，不要漏掉。 安装过程中你可能会看到 123mkdir: /etc/openssl: Permission deniedmkdir -p "/etc/openssl" failed, retrying with sudoyour password required for 'mkdir -p /etc/openssl': 请输入密码并继续。 如果你已经安装过RVM，使用下面的命令update： 1$ rvm get stable --autolibs=enable 重启terminal窗口或者使用：使RVM生效 1$ source ~/.rvm/scripts/rvm 安装ruby 在安装RVM之后，我们安装最新版本的ruby。ruby 2.5.1是写此博客时当前最新的ruby版本，还请查看ruby官网查看最新版本的ruby。必须指定ruby的版本： 1$ rvm install ruby-2.5.1 安装后检查是否安装成功： 12$ ruby -vruby 2.5.1... 升级rubyGemset RubyGems是一个ruby的包管理工具，用来安装ruby的工具或者额外功能的包。 查看gem版本： 1$ gem -v 将gem升级到最新版本 1$ gem update --system 显示RVM gemsets的最初两个设置 1234$ rvm gemset listgemsets for ruby-2.5.0=&gt; (default) global 一般使用global： 1$ rvm gemset use global 安装bundle,Bundle是一个管理gem的必须的工具 1$ gem install Bundler 安装Nokogiri，Nokogiri需要编译成指定的系统，在上面的配置下，号称最难安装的包，也将安装好 1$ gem install nokogiri 如果你真的不幸运在安装时遇到问题，Stack Overflow能帮到你。 安装rails 这里是ruby On rail最新的版本，5.1是最新稳定版本，5.2是release版本，我们安装5.1. 1$ gem install rails --version=5.1 如果你喜欢尝鲜，可以使用 1$ gem install rails --pre 安装release版本。 检查一下rails是否装好： 12$ rails -vRails 5.2.0 到此为止，ruby on rails 以及其环境配置都已妥当，可以开始你的ruby之旅了。 ruby on rails 的Hello world 123456$ cd /$ mkdir worlspace$ cd workspace$ rails _5.1.0_ new hello_app$ cd hello_app$ rails server 将http://localhost:3000输入浏览器，就能看到ruby on rails的欢迎界面。]]></content>
      <categories>
        <category>ruby</category>
      </categories>
      <tags>
        <tag>ruby on rails</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go实现UNIX command]]></title>
    <url>%2F2018%2F08%2F22%2Fgo-unix-cmd-md%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( "bufio" "errors" "fmt" "os" "os/exec" "strings")func main() &#123; reader := bufio.NewReader(os.Stdin) for &#123; fmt.Print("&gt; ") // 读取键盘的输入. input, err := reader.ReadString('\n') if err != nil &#123; fmt.Fprintln(os.Stderr, err) &#125; // 执行并解析command. err = execInput(input) if err != nil &#123; fmt.Fprintln(os.Stderr, err) &#125; &#125;&#125;// 如果cd命令没有路径的话，就报下面的错误var ErrNoPath = errors.New("path required")func execInput(input string) error &#123; // 移除换行符. input = strings.TrimSuffix(input, "\n") // 将输入分割成参数. args := strings.Split(input, " ") // 对cd命令的情况进行区分. switch args[0] &#123; case "cd": // 暂时不支持cd加空格进入home目录. if len(args) &lt; 2 &#123; return ErrNoPath &#125; err := os.Chdir(args[1]) if err != nil &#123; return err &#125; // Stop further processing. return nil case "exit": os.Exit(0) &#125; // Prepare the command to execute. cmd := exec.Command(args[0], args[1:]...) // Set the correct output device. cmd.Stderr = os.Stderr cmd.Stdout = os.Stdout // Execute the command and save it's output. err := cmd.Run() if err != nil &#123; return err &#125; return nil&#125; 12//执行并测试go run main.go 暂时不支持tab键自动补全命令，只是提供一种简单的思路。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iterm2 突然报很奇怪的错误-Error No user exists for uid 501]]></title>
    <url>%2F2018%2F08%2F21%2Fiterm2-strange-err-md-md%2F</url>
    <content type="text"><![CDATA[123No user exists for uid 501fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 上午还好好的，刚刚连接GitHub报这个错误，排查后了解到是iterm2的神坑。 重启iterm终端就好 系统有更新的话 需要重启终端 更新。]]></content>
      <categories>
        <category>生活中奇怪的坑</category>
      </categories>
      <tags>
        <tag>日常的坑系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang中interface的通用设计方法]]></title>
    <url>%2F2018%2F08%2F21%2Fgolang%E9%80%9A%E7%94%A8%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[golang中接口设计的通用方法 123456789101112131415161718192021222324251. 接口定义type XxxManager interface &#123; Create(args argsType) (*XxxStruct, error) Get(args argsType) (**XxxStruct, error) Update(args argsType) (*XxxStruct, error) Delete(name string, options *DeleleOptions) error&#125;2. 结构体定义 type XxxManagerImpl struct &#123; Name string Namespace string kubeCli *kubernetes.Clientset&#125;3，构造函数func NewXxxManagerImpl (namespace, name string, kubeCli *kubernetes.Clientset) XxxManager &#123; return &amp;XxxManagerImpl&#123; Name name, Namespace namespace, kubeCli: kubeCli, &#125;&#125;4. 方法具体实现func (xm *XxxManagerImpl) Create(args argsType) (*XxxStruct, error) &#123; //具体的方法实现&#125; golang通用接口设计 根据以上设计cdosapi封装接口：]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3中遇到'TypeError Unicode-objects must be encoded before hashing']]></title>
    <url>%2F2018%2F08%2F20%2Fpython-md5-err-md%2F</url>
    <content type="text"><![CDATA[Python3中进行MD5加密，遇到编码问题 12345678910111213141516171819202122232425262728293031323334353637383940import hashlibfrom urllib.parse import urlencode, quote_plusimport urllibdef verfy_ac(private_key): item = &#123; "Action" : "CreateUHostInstance", "CPU" : 2, "ChargeType" : "Month", "DiskSpace" : 10, "ImageId" : "f43736e1-65a5-4bea-ad2e-8a46e18883c2", "LoginMode" : "Password", "Memory" : 2048, "Name" : "Host01", "Password" : "VUNsb3VkLmNu", "PublicKey" : "ucloudsomeone%40example.com1296235120854146120", "Quantity" : 1, "Region" : "cn-bj2", "Zone" : "cn-bj2-04" &#125; # 将参数串排序 params_data = "" import pdb;pdb.set_trace() for key, value in item.items(): params_data = params_data + str(key) + str(value) params_data = params_data + private_key params_data_en = quote_plus(params_data) sign = hashlib.sha1() sign.update(params_data_en.encode('utf8')) signature = sign.hexdigest() return signatureprint(verfy_ac("46f09bb9fab4f12dfc160dae12273d5332b5debe")) 这是ucloud官方的API教程，想根据此教程生成签名，教程中的代码是基于Python2.7编写，我将其改成了Python3.但是在执行时报错： 1TypeError: Unicode-objects must be encoded before hashing 排错后发现python3中字符对象是unicode对象，不能直接加密，需要编码后才能进行update。 就是改成如下即可： 1sign.update(params_data_en.encode('utf8'))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>md5编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F08%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
